diff -rbNu linux-2.4.25-kdb/Documentation/Configure.help linux-2.4.25-kdb-trace/Documentation/Configure.help
--- linux-2.4.25-kdb/Documentation/Configure.help	2005-01-05 13:39:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/Documentation/Configure.help	2005-01-05 16:09:40.000000000 +0100
@@ -22108,6 +22108,11 @@
   this option. See "man kallsyms" for the data format, it adds 10-20%
   to the size of the kernel and the loaded modules. If unsure, say N.
 
+Trace kernel function calls
+CONFIG_INSTRUMENT_FUNC
+ Compile kernel with -finstrument-functions. This allows a function
+ level trace of kernel code.
+
 ISDN support
 CONFIG_ISDN
   ISDN ("Integrated Services Digital Networks", called RNIS in France)
diff -rbNu linux-2.4.25-kdb/Makefile linux-2.4.25-kdb-trace/Makefile
--- linux-2.4.25-kdb/Makefile	2005-01-05 13:49:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/Makefile	2005-01-05 16:09:40.000000000 +0100
@@ -98,6 +98,9 @@
 ifndef CONFIG_FRAME_POINTER
 CFLAGS += -fomit-frame-pointer
 endif
+ifeq ($(CONFIG_INSTRUMENT_FUNC),y)
+CFLAGS += -finstrument-functions -fno-inline
+endif
 AFLAGS := -D__ASSEMBLY__ $(CPPFLAGS)
 
 #
diff -rbNu linux-2.4.25-kdb/arch/cris/kernel/signal.c linux-2.4.25-kdb-trace/arch/cris/kernel/signal.c
--- linux-2.4.25-kdb/arch/cris/kernel/signal.c	2003-08-25 13:44:39.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/cris/kernel/signal.c	2005-01-05 16:46:15.000000000 +0100
@@ -517,7 +517,7 @@
  * OK, we're invoking a handler
  */	
 
-extern inline void
+static inline void
 handle_signal(int canrestart, unsigned long sig, struct k_sigaction *ka,
 	      siginfo_t *info, sigset_t *oldset, struct pt_regs * regs)
 {
diff -rbNu linux-2.4.25-kdb/arch/cris/mm/ioremap.c linux-2.4.25-kdb-trace/arch/cris/mm/ioremap.c
--- linux-2.4.25-kdb/arch/cris/mm/ioremap.c	2003-08-25 13:44:39.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/cris/mm/ioremap.c	2005-01-05 16:46:15.000000000 +0100
@@ -13,7 +13,7 @@
 #include <asm/io.h>
 #include <asm/pgalloc.h>
 
-extern inline void remap_area_pte(pte_t * pte, unsigned long address, unsigned long size,
+static inline void remap_area_pte(pte_t * pte, unsigned long address, unsigned long size,
 	unsigned long phys_addr, unsigned long flags)
 {
 	unsigned long end;
diff -rbNu linux-2.4.25-kdb/arch/i386/boot/compressed/misc.c linux-2.4.25-kdb-trace/arch/i386/boot/compressed/misc.c
--- linux-2.4.25-kdb/arch/i386/boot/compressed/misc.c	2003-08-25 13:44:39.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/i386/boot/compressed/misc.c	2005-01-05 16:09:40.000000000 +0100
@@ -375,3 +375,18 @@
 	if (high_loaded) close_output_buffer_if_we_run_high(mv);
 	return high_loaded;
 }
+
+#ifdef CONFIG_INSTRUMENT_FUNC
+void __cyg_profile_func_enter(void *, void *)
+ __attribute__ ((no_instrument_function));
+void __cyg_profile_func_exit(void *, void *)
+ __attribute__ ((no_instrument_function));
+
+void __cyg_profile_func_enter(void *a1, void *a2)
+{
+}
+
+void __cyg_profile_func_exit(void *a1, void *a2)
+{
+}
+#endif
diff -rbNu linux-2.4.25-kdb/arch/i386/config.in linux-2.4.25-kdb-trace/arch/i386/config.in
--- linux-2.4.25-kdb/arch/i386/config.in	2005-01-05 13:39:28.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/i386/config.in	2005-01-05 16:09:40.000000000 +0100
@@ -489,6 +489,7 @@
       fi
       comment '  Load all symbols for debugging is required for KDB'
       define_bool CONFIG_KALLSYMS y
+ bool ' Trace kernel function calls' CONFIG_INSTRUMENT_FUNC
    else
       bool '  Load all symbols for debugging' CONFIG_KALLSYMS
    fi
diff -rbNu linux-2.4.25-kdb/arch/i386/kdb/kdbasupport.c linux-2.4.25-kdb-trace/arch/i386/kdb/kdbasupport.c
--- linux-2.4.25-kdb/arch/i386/kdb/kdbasupport.c	2005-01-05 13:39:28.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/i386/kdb/kdbasupport.c	2005-01-05 16:09:40.000000000 +0100
@@ -1109,6 +1109,8 @@
 }
 
 #ifdef KDB_HAVE_LONGJMP
+int kdba_setjmp(kdb_jmp_buf *jb)
+ __attribute__ ((no_instrument_function));
 int
 kdba_setjmp(kdb_jmp_buf *jb)
 {
@@ -1137,6 +1139,8 @@
 	return 0;
 }
 
+void kdba_longjmp(kdb_jmp_buf *jb, int reason)
+ __attribute__ ((no_instrument_function));
 void
 kdba_longjmp(kdb_jmp_buf *jb, int reason)
 {
diff -rbNu linux-2.4.25-kdb/arch/mips64/kernel/signal_n32.c linux-2.4.25-kdb-trace/arch/mips64/kernel/signal_n32.c
--- linux-2.4.25-kdb/arch/mips64/kernel/signal_n32.c	2004-02-18 14:36:30.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/mips64/kernel/signal_n32.c	2005-01-05 16:46:12.000000000 +0100
@@ -68,7 +68,7 @@
 };
 
 extern asmlinkage int restore_sigcontext(struct pt_regs *regs, struct sigcontext *sc);
-extern int inline setup_sigcontext(struct pt_regs *regs, struct sigcontext *sc);
+extern int setup_sigcontext(struct pt_regs *regs, struct sigcontext *sc);
 
 asmlinkage void sysn32_rt_sigreturn(abi64_no_regargs, struct pt_regs regs)
 {
diff -rbNu linux-2.4.25-kdb/arch/parisc/kernel/ioctl32.c linux-2.4.25-kdb-trace/arch/parisc/kernel/ioctl32.c
--- linux-2.4.25-kdb/arch/parisc/kernel/ioctl32.c	2003-08-25 13:44:40.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/parisc/kernel/ioctl32.c	2005-01-05 16:46:14.000000000 +0100
@@ -3624,7 +3624,7 @@
 
 unsigned int ioctl32_hash_table[1024];
 
-extern inline unsigned long ioctl32_hash(unsigned long cmd)
+static inline unsigned long ioctl32_hash(unsigned long cmd)
 {
 	return ((cmd >> 6) ^ (cmd >> 4) ^ cmd) & 0x3ff;
 }
diff -rbNu linux-2.4.25-kdb/arch/parisc/kernel/sys_parisc32.c linux-2.4.25-kdb-trace/arch/parisc/kernel/sys_parisc32.c
--- linux-2.4.25-kdb/arch/parisc/kernel/sys_parisc32.c	2003-06-13 16:51:31.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/parisc/kernel/sys_parisc32.c	2005-01-05 16:46:14.000000000 +0100
@@ -1779,7 +1779,7 @@
 extern struct socket *sockfd_lookup(int fd, int *err);
 
 /* XXX This as well... */
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/arch/ppc/boot/include/of1275.h linux-2.4.25-kdb-trace/arch/ppc/boot/include/of1275.h
--- linux-2.4.25-kdb/arch/ppc/boot/include/of1275.h	2004-02-18 14:36:30.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/ppc/boot/include/of1275.h	2005-01-05 16:46:09.000000000 +0100
@@ -36,7 +36,7 @@
 
 /* inlines */
 
-extern inline void pause(void)
+static inline void pause(void)
 {
 	enter();
 }
diff -rbNu linux-2.4.25-kdb/arch/ppc/platforms/pal4.h linux-2.4.25-kdb-trace/arch/ppc/platforms/pal4.h
--- linux-2.4.25-kdb/arch/ppc/platforms/pal4.h	2003-08-25 13:44:40.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/ppc/platforms/pal4.h	2005-01-05 16:46:08.000000000 +0100
@@ -30,7 +30,7 @@
 #define CPC700_MB4SA            0x48
 #define CPC700_MB4EA            0x68
 
-extern inline long
+static inline long
 cpc700_read_memreg(int reg)
 {
 	out_be32((volatile unsigned int *) CPC700_MEM_CFGADDR, reg);
diff -rbNu linux-2.4.25-kdb/arch/ppc/xmon/xmon.c linux-2.4.25-kdb-trace/arch/ppc/xmon/xmon.c
--- linux-2.4.25-kdb/arch/ppc/xmon/xmon.c	2003-08-25 13:44:40.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/ppc/xmon/xmon.c	2005-01-05 16:46:09.000000000 +0100
@@ -154,12 +154,12 @@
 
 static struct pt_regs *xmon_regs[NR_CPUS];
 
-extern inline void sync(void)
+static inline void sync(void)
 {
 	asm volatile("sync; isync");
 }
 
-extern inline void __delay(unsigned int loops)
+static inline void __delay(unsigned int loops)
 {
 	if (loops != 0)
 		__asm__ __volatile__("mtctr %0; 1: bdnz 1b" : :
diff -rbNu linux-2.4.25-kdb/arch/ppc64/kernel/ioctl32.c linux-2.4.25-kdb-trace/arch/ppc64/kernel/ioctl32.c
--- linux-2.4.25-kdb/arch/ppc64/kernel/ioctl32.c	2004-02-18 14:36:30.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/ppc64/kernel/ioctl32.c	2005-01-05 16:46:04.000000000 +0100
@@ -830,7 +830,7 @@
 
 extern struct socket *sockfd_lookup(int fd, int *err);
 
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/arch/ppc64/kernel/sys_ppc32.c linux-2.4.25-kdb-trace/arch/ppc64/kernel/sys_ppc32.c
--- linux-2.4.25-kdb/arch/ppc64/kernel/sys_ppc32.c	2004-02-18 14:36:30.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/ppc64/kernel/sys_ppc32.c	2005-01-05 16:46:04.000000000 +0100
@@ -3313,12 +3313,12 @@
 			       __cmsg, __cmsg_len);
 }
 
-extern __inline__ struct socket *socki_lookup(struct inode *inode)
+static __inline__ struct socket *socki_lookup(struct inode *inode)
 {
 	return &inode->u.socket_i;
 }
 
-extern __inline__ struct socket *sockfd_lookup(int fd, int *err)
+static __inline__ struct socket *sockfd_lookup(int fd, int *err)
 {
 	struct file *file;
 	struct inode *inode;
@@ -3340,7 +3340,7 @@
 	return socki_lookup(inode);
 }
 
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/arch/ppc64/xmon/xmon.c linux-2.4.25-kdb-trace/arch/ppc64/xmon/xmon.c
--- linux-2.4.25-kdb/arch/ppc64/xmon/xmon.c	2003-08-25 13:44:40.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/ppc64/xmon/xmon.c	2005-01-05 16:46:04.000000000 +0100
@@ -188,7 +188,7 @@
 /*
  * Stuff for reading and writing memory safely
  */
-extern inline void sync(void)
+static inline void sync(void)
 {
 	asm volatile("sync; isync");
 }
diff -rbNu linux-2.4.25-kdb/arch/s390/kernel/debug.c linux-2.4.25-kdb-trace/arch/s390/kernel/debug.c
--- linux-2.4.25-kdb/arch/s390/kernel/debug.c	2003-08-25 13:44:40.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/s390/kernel/debug.c	2005-01-05 16:46:14.000000000 +0100
@@ -409,7 +409,7 @@
  * - goto next entry in p_info
  */
 
-extern inline int debug_next_entry(file_private_info_t *p_info)
+static inline int debug_next_entry(file_private_info_t *p_info)
 {
 	debug_info_t *id = p_info->debug_info_snap;
 	if(p_info->act_entry == DEBUG_PROLOG_ENTRY){
@@ -758,7 +758,7 @@
  * - set active entry to next in the ring buffer
  */
 
-extern inline void proceed_active_entry(debug_info_t * id)
+static inline void proceed_active_entry(debug_info_t * id)
 {
 	if ((id->active_entry[id->active_area] += id->entry_size)
 	    > ((PAGE_SIZE << (id->page_order)) - id->entry_size))
@@ -770,7 +770,7 @@
  * - set active area to next in the ring buffer
  */
 
-extern inline void proceed_active_area(debug_info_t * id)
+static inline void proceed_active_area(debug_info_t * id)
 {
 	id->active_area++;
 	id->active_area = id->active_area % id->nr_areas;
@@ -780,7 +780,7 @@
  * get_active_entry:
  */
 
-extern inline debug_entry_t *get_active_entry(debug_info_t * id)
+static inline debug_entry_t *get_active_entry(debug_info_t * id)
 {
 	return (debug_entry_t *) ((char *) id->areas[id->active_area] +
 				  id->active_entry[id->active_area]);
@@ -791,7 +791,7 @@
  * - set timestamp, caller address, cpu number etc.
  */
 
-extern inline debug_entry_t *debug_common(debug_info_t * id, int level, 
+static inline debug_entry_t *debug_common(debug_info_t * id, int level, 
                                     const void *buf, int len, int exception)
 {
 	unsigned long flags;
@@ -840,7 +840,7 @@
  * counts arguments in format string for sprintf view
  */
 
-extern inline int debug_count_numargs(char *string)
+static inline int debug_count_numargs(char *string)
 {
 	int numargs=0;
 
diff -rbNu linux-2.4.25-kdb/arch/s390/mm/fault.c linux-2.4.25-kdb-trace/arch/s390/mm/fault.c
--- linux-2.4.25-kdb/arch/s390/mm/fault.c	2002-11-29 00:53:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/s390/mm/fault.c	2005-01-05 16:46:14.000000000 +0100
@@ -145,7 +145,7 @@
  *   10       Segment translation  ->  Not present       (nullification)
  *   11       Page translation     ->  Not present       (nullification)
  */
-extern inline void do_exception(struct pt_regs *regs, unsigned long error_code)
+static inline void do_exception(struct pt_regs *regs, unsigned long error_code)
 {
         struct task_struct *tsk;
         struct mm_struct *mm;
diff -rbNu linux-2.4.25-kdb/arch/s390x/kernel/debug.c linux-2.4.25-kdb-trace/arch/s390x/kernel/debug.c
--- linux-2.4.25-kdb/arch/s390x/kernel/debug.c	2003-08-25 13:44:40.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/s390x/kernel/debug.c	2005-01-05 16:46:15.000000000 +0100
@@ -409,7 +409,7 @@
  * - goto next entry in p_info
  */
 
-extern inline int debug_next_entry(file_private_info_t *p_info)
+static inline int debug_next_entry(file_private_info_t *p_info)
 {
 	debug_info_t *id = p_info->debug_info_snap;
 	if(p_info->act_entry == DEBUG_PROLOG_ENTRY){
@@ -758,7 +758,7 @@
  * - set active entry to next in the ring buffer
  */
 
-extern inline void proceed_active_entry(debug_info_t * id)
+static inline void proceed_active_entry(debug_info_t * id)
 {
 	if ((id->active_entry[id->active_area] += id->entry_size)
 	    > ((PAGE_SIZE << (id->page_order)) - id->entry_size))
@@ -770,7 +770,7 @@
  * - set active area to next in the ring buffer
  */
 
-extern inline void proceed_active_area(debug_info_t * id)
+static inline void proceed_active_area(debug_info_t * id)
 {
 	id->active_area++;
 	id->active_area = id->active_area % id->nr_areas;
@@ -780,7 +780,7 @@
  * get_active_entry:
  */
 
-extern inline debug_entry_t *get_active_entry(debug_info_t * id)
+static inline debug_entry_t *get_active_entry(debug_info_t * id)
 {
 	return (debug_entry_t *) ((char *) id->areas[id->active_area] +
 				  id->active_entry[id->active_area]);
@@ -791,7 +791,7 @@
  * - set timestamp, caller address, cpu number etc.
  */
 
-extern inline debug_entry_t *debug_common(debug_info_t * id, int level, 
+static inline debug_entry_t *debug_common(debug_info_t * id, int level, 
                                     const void *buf, int len, int exception)
 {
 	unsigned long flags;
@@ -840,7 +840,7 @@
  * counts arguments in format string for sprintf view
  */
 
-extern inline int debug_count_numargs(char *string)
+static inline int debug_count_numargs(char *string)
 {
 	int numargs=0;
 
diff -rbNu linux-2.4.25-kdb/arch/s390x/kernel/linux32.c linux-2.4.25-kdb-trace/arch/s390x/kernel/linux32.c
--- linux-2.4.25-kdb/arch/s390x/kernel/linux32.c	2004-02-18 14:36:30.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/s390x/kernel/linux32.c	2005-01-05 16:46:15.000000000 +0100
@@ -2271,7 +2271,7 @@
 extern struct socket *sockfd_lookup(int fd, int *err);
 
 /* XXX This as well... */
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/arch/s390x/mm/fault.c linux-2.4.25-kdb-trace/arch/s390x/mm/fault.c
--- linux-2.4.25-kdb/arch/s390x/mm/fault.c	2002-11-29 00:53:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/s390x/mm/fault.c	2005-01-05 16:46:15.000000000 +0100
@@ -145,7 +145,7 @@
  *   11       Page translation     ->  Not present       (nullification)
  *   3b       Region third trans.  ->  Not present       (nullification)
  */
-extern inline void do_exception(struct pt_regs *regs, unsigned long error_code)
+static inline void do_exception(struct pt_regs *regs, unsigned long error_code)
 {
         struct task_struct *tsk;
         struct mm_struct *mm;
diff -rbNu linux-2.4.25-kdb/arch/sparc/kernel/time.c linux-2.4.25-kdb-trace/arch/sparc/kernel/time.c
--- linux-2.4.25-kdb/arch/sparc/kernel/time.c	2003-06-13 16:51:32.000000000 +0200
+++ linux-2.4.25-kdb-trace/arch/sparc/kernel/time.c	2005-01-05 16:46:05.000000000 +0100
@@ -450,7 +450,7 @@
 	sbus_time_init();
 }
 
-extern __inline__ unsigned long do_gettimeoffset(void)
+static __inline__ unsigned long do_gettimeoffset(void)
 {
 	struct tasklet_struct *t;
 	unsigned long offset = 0;
diff -rbNu linux-2.4.25-kdb/arch/sparc/mm/srmmu.c linux-2.4.25-kdb-trace/arch/sparc/mm/srmmu.c
--- linux-2.4.25-kdb/arch/sparc/mm/srmmu.c	2003-11-28 19:26:19.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/sparc/mm/srmmu.c	2005-01-05 16:46:05.000000000 +0100
@@ -236,7 +236,7 @@
 { return __pte((pte_val(pte) & SRMMU_CHG_MASK) | pgprot_val(newprot)); }
 
 /* to find an entry in a top-level page table... */
-extern inline pgd_t *srmmu_pgd_offset(struct mm_struct * mm, unsigned long address)
+static inline pgd_t *srmmu_pgd_offset(struct mm_struct * mm, unsigned long address)
 { return mm->pgd + (address >> SRMMU_PGDIR_SHIFT); }
 
 /* Find an entry in the second-level page table.. */
diff -rbNu linux-2.4.25-kdb/arch/sparc64/kernel/ioctl32.c linux-2.4.25-kdb-trace/arch/sparc64/kernel/ioctl32.c
--- linux-2.4.25-kdb/arch/sparc64/kernel/ioctl32.c	2004-02-18 14:36:31.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/sparc64/kernel/ioctl32.c	2005-01-05 16:46:09.000000000 +0100
@@ -760,7 +760,7 @@
 
 extern struct socket *sockfd_lookup(int fd, int *err);
 
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/arch/sparc64/kernel/sys_sparc32.c linux-2.4.25-kdb-trace/arch/sparc64/kernel/sys_sparc32.c
--- linux-2.4.25-kdb/arch/sparc64/kernel/sys_sparc32.c	2004-02-18 14:36:31.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/sparc64/kernel/sys_sparc32.c	2005-01-05 16:46:09.000000000 +0100
@@ -2320,7 +2320,7 @@
 extern struct socket *sockfd_lookup(int fd, int *err);
 
 /* XXX This as well... */
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/arch/sparc64/solaris/socket.c linux-2.4.25-kdb-trace/arch/sparc64/solaris/socket.c
--- linux-2.4.25-kdb/arch/sparc64/solaris/socket.c	2001-02-19 04:49:54.000000000 +0100
+++ linux-2.4.25-kdb-trace/arch/sparc64/solaris/socket.c	2005-01-05 16:46:10.000000000 +0100
@@ -249,12 +249,12 @@
 					   about 80 for AX.25 */
 
 /* XXX These as well... */
-extern __inline__ struct socket *socki_lookup(struct inode *inode)
+static __inline__ struct socket *socki_lookup(struct inode *inode)
 {
 	return &inode->u.socket_i;
 }
 
-extern __inline__ struct socket *sockfd_lookup(int fd, int *err)
+static __inline__ struct socket *sockfd_lookup(int fd, int *err)
 {
 	struct file *file;
 	struct inode *inode;
@@ -274,7 +274,7 @@
 	return socki_lookup(inode);
 }
 
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/drivers/isdn/sc/command.c linux-2.4.25-kdb-trace/drivers/isdn/sc/command.c
--- linux-2.4.25-kdb/drivers/isdn/sc/command.c	2001-12-21 18:41:54.000000000 +0100
+++ linux-2.4.25-kdb-trace/drivers/isdn/sc/command.c	2005-01-05 16:45:59.000000000 +0100
@@ -51,7 +51,7 @@
                 RspMessage *, int);
 extern int sendmessage(int, unsigned int, unsigned int, unsigned int,
                 unsigned int, unsigned int, unsigned int, unsigned int *);
-extern inline void pullphone(char *, char *);
+extern void pullphone(char *, char *);
 
 #ifdef DEBUG
 /*
diff -rbNu linux-2.4.25-kdb/drivers/net/aironet4500.h linux-2.4.25-kdb-trace/drivers/net/aironet4500.h
--- linux-2.4.25-kdb/drivers/net/aironet4500.h	2005-01-05 13:54:42.000000000 +0100
+++ linux-2.4.25-kdb-trace/drivers/net/aironet4500.h	2005-01-05 17:00:19.000000000 +0100
@@ -450,7 +450,7 @@
 };
 
 
-extern  __inline__ void
+static  __inline__ void
 awc_fid_queue_init(struct awc_fid_queue * queue){
 
 	unsigned long flags;
diff -rbNu linux-2.4.25-kdb/drivers/net/au1000_eth.c linux-2.4.25-kdb-trace/drivers/net/au1000_eth.c
--- linux-2.4.25-kdb/drivers/net/au1000_eth.c	2004-02-18 14:36:31.000000000 +0100
+++ linux-2.4.25-kdb-trace/drivers/net/au1000_eth.c	2005-01-05 16:45:53.000000000 +0100
@@ -94,8 +94,8 @@
 // externs
 extern  void ack_rise_edge_irq(unsigned int);
 extern int get_ethernet_addr(char *ethernet_addr);
-extern inline void str2eaddr(unsigned char *ea, unsigned char *str);
-extern inline unsigned char str2hexnum(unsigned char c);
+extern void str2eaddr(unsigned char *ea, unsigned char *str);
+extern unsigned char str2hexnum(unsigned char c);
 extern char * __init prom_getcmdline(void);
 
 /*
diff -rbNu linux-2.4.25-kdb/drivers/net/bonding/bonding.h linux-2.4.25-kdb-trace/drivers/net/bonding/bonding.h
--- linux-2.4.25-kdb/drivers/net/bonding/bonding.h	2005-01-05 13:55:30.000000000 +0100
+++ linux-2.4.25-kdb-trace/drivers/net/bonding/bonding.h	2005-01-05 17:01:28.000000000 +0100
@@ -121,7 +121,7 @@
  * (which is circular)
  * Caller must hold bond lock for read
  */
-extern inline struct slave*
+static inline struct slave*
 bond_get_first_slave(struct bonding *bond)
 {
 	/* if there are no slaves return NULL */
@@ -134,7 +134,7 @@
 /**
  * Caller must hold bond lock for read
  */
-extern inline struct slave*
+static inline struct slave*
 bond_get_next_slave(struct bonding *bond, struct slave *slave)
 {
 	/* If we have reached the last slave return NULL */
@@ -149,7 +149,7 @@
  *
  * Caller must hold bond lock for read
  */
-extern inline struct slave*
+static inline struct slave*
 bond_get_slave_by_dev(struct bonding *bond, struct net_device *slave_dev)
 {
 	struct slave *our_slave = bond->next;
@@ -167,7 +167,7 @@
 	return our_slave;
 }
 
-extern inline struct bonding*
+static inline struct bonding*
 bond_get_bond_by_slave(struct slave *slave)
 {
 	if (!slave || !slave->dev->master) {
diff -rbNu linux-2.4.25-kdb/drivers/net/hamradio/soundmodem/sm.h linux-2.4.25-kdb-trace/drivers/net/hamradio/soundmodem/sm.h
--- linux-2.4.25-kdb/drivers/net/hamradio/soundmodem/sm.h	2002-08-03 02:39:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/drivers/net/hamradio/soundmodem/sm.h	2005-01-05 16:45:54.000000000 +0100
@@ -363,7 +363,7 @@
 
 /* --------------------------------------------------------------------- */
 
-extern void inline sm_int_freq(struct sm_state *sm)
+static void inline sm_int_freq(struct sm_state *sm)
 {
 #ifdef SM_DEBUG
 	unsigned long cur_jiffies = jiffies;
diff -rbNu linux-2.4.25-kdb/drivers/net/hamradio/soundmodem/sm_wss.c linux-2.4.25-kdb-trace/drivers/net/hamradio/soundmodem/sm_wss.c
--- linux-2.4.25-kdb/drivers/net/hamradio/soundmodem/sm_wss.c	2002-11-29 00:53:13.000000000 +0100
+++ linux-2.4.25-kdb-trace/drivers/net/hamradio/soundmodem/sm_wss.c	2005-01-05 16:45:54.000000000 +0100
@@ -100,7 +100,7 @@
 
 /* --------------------------------------------------------------------- */
 
-extern void inline wss_ack_int(struct net_device *dev)
+static void inline wss_ack_int(struct net_device *dev)
 {
 	outb(0, WSS_CODEC_STATUS(dev->base_addr));
 }
diff -rbNu linux-2.4.25-kdb/drivers/net/wireless/orinoco.h linux-2.4.25-kdb-trace/drivers/net/wireless/orinoco.h
--- linux-2.4.25-kdb/drivers/net/wireless/orinoco.h	2005-01-05 13:57:04.000000000 +0100
+++ linux-2.4.25-kdb-trace/drivers/net/wireless/orinoco.h	2005-01-05 17:04:27.000000000 +0100
@@ -135,7 +135,7 @@
  * SPARC, due to its weird semantics for save/restore flags. extern
  * inline should prevent the kernel from linking or module from
  * loading if they are not inlined. */
-extern inline int orinoco_lock(struct orinoco_private *priv,
+static inline int orinoco_lock(struct orinoco_private *priv,
 			       unsigned long *flags)
 {
 	spin_lock_irqsave(&priv->lock, *flags);
@@ -148,7 +148,7 @@
 	return 0;
 }
 
-extern inline void orinoco_unlock(struct orinoco_private *priv,
+static inline void orinoco_unlock(struct orinoco_private *priv,
 				  unsigned long *flags)
 {
 	spin_unlock_irqrestore(&priv->lock, *flags);
diff -rbNu linux-2.4.25-kdb/drivers/parport/parport_pc.c linux-2.4.25-kdb-trace/drivers/parport/parport_pc.c
--- linux-2.4.25-kdb/drivers/parport/parport_pc.c	2003-06-13 16:51:35.000000000 +0200
+++ linux-2.4.25-kdb-trace/drivers/parport/parport_pc.c	2005-01-05 16:09:40.000000000 +0100
@@ -266,6 +266,11 @@
 	parport_generic_irq(irq, (struct parport *) dev_id, regs);
 }
 
+/*
+ * Actually it cause problems to have both static inline and a
+ * global version.
+ */
+#if 0
 void parport_pc_write_data(struct parport *p, unsigned char d)
 {
 	outb (d, DATA (p));
@@ -354,6 +359,7 @@
 {
 	__parport_pc_frob_control (p, 0x20, 0x20);
 }
+#endif
 
 void parport_pc_init_state(struct pardevice *dev, struct parport_state *s)
 {
diff -rbNu linux-2.4.25-kdb/drivers/sound/au1000.c linux-2.4.25-kdb-trace/drivers/sound/au1000.c
--- linux-2.4.25-kdb/drivers/sound/au1000.c	2004-02-18 14:36:31.000000000 +0100
+++ linux-2.4.25-kdb-trace/drivers/sound/au1000.c	2005-01-05 16:45:57.000000000 +0100
@@ -595,7 +595,7 @@
 #define DMABUF_DEFAULTORDER (17-PAGE_SHIFT)
 #define DMABUF_MINORDER 1
 
-extern inline void dealloc_dmabuf(struct au1000_state *s, struct dmabuf *db)
+static inline void dealloc_dmabuf(struct au1000_state *s, struct dmabuf *db)
 {
 	struct page    *page, *pend;
 
@@ -694,14 +694,14 @@
 	return 0;
 }
 
-extern inline int prog_dmabuf_adc(struct au1000_state *s)
+static inline int prog_dmabuf_adc(struct au1000_state *s)
 {
 	stop_adc(s);
 	return prog_dmabuf(s, &s->dma_adc);
 
 }
 
-extern inline int prog_dmabuf_dac(struct au1000_state *s)
+static inline int prog_dmabuf_dac(struct au1000_state *s)
 {
 	stop_dac(s);
 	return prog_dmabuf(s, &s->dma_dac);
diff -rbNu linux-2.4.25-kdb/drivers/video/riva/fbdev.c linux-2.4.25-kdb-trace/drivers/video/riva/fbdev.c
--- linux-2.4.25-kdb/drivers/video/riva/fbdev.c	2003-06-13 16:51:37.000000000 +0200
+++ linux-2.4.25-kdb-trace/drivers/video/riva/fbdev.c	2005-01-05 16:46:00.000000000 +0100
@@ -117,7 +117,7 @@
 static void rivafb_blank(int blank, struct fb_info *info);
 
 extern void riva_setup_accel(struct rivafb_info *rinfo);
-extern inline void wait_for_idle(struct rivafb_info *rinfo);
+extern void wait_for_idle(struct rivafb_info *rinfo);
 
 
 
diff -rbNu linux-2.4.25-kdb/fs/adfs/adfs.h linux-2.4.25-kdb-trace/fs/adfs/adfs.h
--- linux-2.4.25-kdb/fs/adfs/adfs.h	2000-09-19 00:14:06.000000000 +0200
+++ linux-2.4.25-kdb-trace/fs/adfs/adfs.h	2005-01-05 16:45:34.000000000 +0100
@@ -107,7 +107,7 @@
 extern struct inode_operations adfs_file_inode_operations;
 extern struct file_operations adfs_file_operations;
 
-extern inline __u32 signed_asl(__u32 val, signed int shift)
+static inline __u32 signed_asl(__u32 val, signed int shift)
 {
 	if (shift >= 0)
 		val <<= shift;
@@ -122,7 +122,7 @@
  *
  * The root directory ID should always be looked up in the map [3.4]
  */
-extern inline int
+static inline int
 __adfs_block_map(struct super_block *sb, unsigned int object_id,
 		 unsigned int block)
 {
diff -rbNu linux-2.4.25-kdb/fs/devpts/devpts_i.h linux-2.4.25-kdb-trace/fs/devpts/devpts_i.h
--- linux-2.4.25-kdb/fs/devpts/devpts_i.h	2005-01-05 14:09:00.000000000 +0100
+++ linux-2.4.25-kdb-trace/fs/devpts/devpts_i.h	2005-01-05 17:18:57.000000000 +0100
@@ -32,7 +32,7 @@
 #define DEVPTS_SUPER_MAGIC 0x1cd1
 #define DEVPTS_SBI_MAGIC   0x01da1d02
 
-extern inline struct devpts_sb_info *SBI(struct super_block *sb)
+static inline struct devpts_sb_info *SBI(struct super_block *sb)
 {
 	return (struct devpts_sb_info *)(sb->u.generic_sbp);
 }
diff -rbNu linux-2.4.25-kdb/fs/freevxfs/vxfs_extern.h linux-2.4.25-kdb-trace/fs/freevxfs/vxfs_extern.h
--- linux-2.4.25-kdb/fs/freevxfs/vxfs_extern.h	2002-02-25 20:38:08.000000000 +0100
+++ linux-2.4.25-kdb-trace/fs/freevxfs/vxfs_extern.h	2005-01-05 16:45:34.000000000 +0100
@@ -72,7 +72,7 @@
 
 /* vxfs_subr.c */
 extern struct page *		vxfs_get_page(struct address_space *, u_long);
-extern __inline__ void		vxfs_put_page(struct page *);
+extern void		vxfs_put_page(struct page *);
 extern struct buffer_head *	vxfs_bread(struct inode *, int);
 
 #endif /* _VXFS_EXTERN_H_ */
diff -rbNu linux-2.4.25-kdb/fs/hfs/hfs_btree.h linux-2.4.25-kdb-trace/fs/hfs/hfs_btree.h
--- linux-2.4.25-kdb/fs/hfs/hfs_btree.h	2005-01-05 14:01:58.000000000 +0100
+++ linux-2.4.25-kdb-trace/fs/hfs/hfs_btree.h	2005-01-05 17:10:45.000000000 +0100
@@ -213,48 +213,48 @@
 
 /* Convert a (struct hfs_bnode *) and an index to the value of the
    n-th offset in the bnode (N >= 1) to the offset */
-extern inline hfs_u16 bnode_offset(const struct hfs_bnode *bnode, int n)
+static inline hfs_u16 bnode_offset(const struct hfs_bnode *bnode, int n)
 { return hfs_get_hs(RECTBL(bnode,n)); }
 
 /* Convert a (struct hfs_bnode *) and an index to the size of the
    n-th record in the bnode (N >= 1) */
-extern inline hfs_u16 bnode_rsize(const struct hfs_bnode *bnode, int n)
+static inline hfs_u16 bnode_rsize(const struct hfs_bnode *bnode, int n)
 { return bnode_offset(bnode, n+1) - bnode_offset(bnode, n); }
 
 /* Convert a (struct hfs_bnode *) to the offset of the empty part */
-extern inline hfs_u16 bnode_end(const struct hfs_bnode *bnode)
+static inline hfs_u16 bnode_end(const struct hfs_bnode *bnode)
 { return bnode_offset(bnode, bnode->ndNRecs + 1); }
 
 /* Convert a (struct hfs_bnode *) to the number of free bytes it contains */
-extern inline hfs_u16 bnode_freespace(const struct hfs_bnode *bnode)
+static inline hfs_u16 bnode_freespace(const struct hfs_bnode *bnode)
 { return HFS_SECTOR_SIZE - bnode_end(bnode)
 	  - (bnode->ndNRecs + 1)*sizeof(hfs_u16); }
 
 /* Convert a (struct hfs_bnode *) X and an index N to
    the address of the record N in the bnode (N >= 1) */
-extern inline void *bnode_datastart(const struct hfs_bnode *bnode)
+static inline void *bnode_datastart(const struct hfs_bnode *bnode)
 { return (void *)(hfs_buffer_data(bnode->buf)+sizeof(struct NodeDescriptor)); }
 
 /* Convert a (struct hfs_bnode *) to the address of the empty part */
-extern inline void *bnode_dataend(const struct hfs_bnode *bnode)
+static inline void *bnode_dataend(const struct hfs_bnode *bnode)
 { return (void *)(hfs_buffer_data(bnode->buf) + bnode_end(bnode)); }
 
 /* Convert various pointers to address of record's key */
-extern inline void *bnode_key(const struct hfs_bnode *bnode, int n)
+static inline void *bnode_key(const struct hfs_bnode *bnode, int n)
 { return (void *)(hfs_buffer_data(bnode->buf) + bnode_offset(bnode, n)); }
-extern inline void *belem_key(const struct hfs_belem *elem)
+static inline void *belem_key(const struct hfs_belem *elem)
 { return bnode_key(elem->bnr.bn, elem->record); }
-extern inline void *brec_key(const struct hfs_brec *brec)
+static inline void *brec_key(const struct hfs_brec *brec)
 { return belem_key(brec->bottom); }
 
 /* Convert various pointers to the address of a record */
-extern inline void *bkey_record(const struct hfs_bkey *key)
+static inline void *bkey_record(const struct hfs_bkey *key)
 { return (void *)key + ROUND(key->KeyLen + 1); }
-extern inline void *bnode_record(const struct hfs_bnode *bnode, int n)
+static inline void *bnode_record(const struct hfs_bnode *bnode, int n)
 { return bkey_record(bnode_key(bnode, n)); }
-extern inline void *belem_record(const struct hfs_belem *elem)
+static inline void *belem_record(const struct hfs_belem *elem)
 { return bkey_record(belem_key(elem)); }
-extern inline void *brec_record(const struct hfs_brec *brec)
+static inline void *brec_record(const struct hfs_brec *brec)
 { return bkey_record(brec_key(brec)); }
 
 /*================ Function Prototypes ================*/
diff -rbNu linux-2.4.25-kdb/fs/hpfs/hpfs_fn.h linux-2.4.25-kdb-trace/fs/hpfs/hpfs_fn.h
--- linux-2.4.25-kdb/fs/hpfs/hpfs_fn.h	2005-01-05 14:02:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/fs/hpfs/hpfs_fn.h	2005-01-05 17:11:01.000000000 +0100
@@ -61,13 +61,13 @@
  * local time (HPFS) to GMT (Unix)
  */
 
-extern inline time_t local_to_gmt(struct super_block *s, time_t t)
+static inline time_t local_to_gmt(struct super_block *s, time_t t)
 {
 	extern struct timezone sys_tz;
 	return t + sys_tz.tz_minuteswest * 60 + s->s_hpfs_timeshift;
 }
 
-extern inline time_t gmt_to_local(struct super_block *s, time_t t)
+static inline time_t gmt_to_local(struct super_block *s, time_t t)
 {
 	extern struct timezone sys_tz;
 	return t - sys_tz.tz_minuteswest * 60 - s->s_hpfs_timeshift;
@@ -90,7 +90,7 @@
 
 /* The b-tree down pointer from a dir entry */
 
-extern inline dnode_secno de_down_pointer (struct hpfs_dirent *de)
+static inline dnode_secno de_down_pointer (struct hpfs_dirent *de)
 {
   CHKCOND(de->down,("HPFS: de_down_pointer: !de->down\n"));
   return *(dnode_secno *) ((void *) de + de->length - 4);
@@ -98,14 +98,14 @@
 
 /* The first dir entry in a dnode */
 
-extern inline struct hpfs_dirent *dnode_first_de (struct dnode *dnode)
+static inline struct hpfs_dirent *dnode_first_de (struct dnode *dnode)
 {
   return (void *) dnode->dirent;
 }
 
 /* The end+1 of the dir entries */
 
-extern inline struct hpfs_dirent *dnode_end_de (struct dnode *dnode)
+static inline struct hpfs_dirent *dnode_end_de (struct dnode *dnode)
 {
   CHKCOND(dnode->first_free>=0x14 && dnode->first_free<=0xa00,("HPFS: dnode_end_de: dnode->first_free = %d\n",(int)dnode->first_free));
   return (void *) dnode + dnode->first_free;
@@ -113,48 +113,48 @@
 
 /* The dir entry after dir entry de */
 
-extern inline struct hpfs_dirent *de_next_de (struct hpfs_dirent *de)
+static inline struct hpfs_dirent *de_next_de (struct hpfs_dirent *de)
 {
   CHKCOND(de->length>=0x20 && de->length<0x800,("HPFS: de_next_de: de->length = %d\n",(int)de->length));
   return (void *) de + de->length;
 }
 
-extern inline struct extended_attribute *fnode_ea(struct fnode *fnode)
+static inline struct extended_attribute *fnode_ea(struct fnode *fnode)
 {
 	return (struct extended_attribute *)((char *)fnode + fnode->ea_offs);
 }
 
-extern inline struct extended_attribute *fnode_end_ea(struct fnode *fnode)
+static inline struct extended_attribute *fnode_end_ea(struct fnode *fnode)
 {
 	return (struct extended_attribute *)((char *)fnode + fnode->ea_offs + fnode->ea_size_s);
 }
 
-extern inline struct extended_attribute *next_ea(struct extended_attribute *ea)
+static inline struct extended_attribute *next_ea(struct extended_attribute *ea)
 {
 	return (struct extended_attribute *)((char *)ea + 5 + ea->namelen + ea->valuelen);
 }
 
-extern inline secno ea_sec(struct extended_attribute *ea)
+static inline secno ea_sec(struct extended_attribute *ea)
 {
 	return *(secno *)((char *)ea + 9 + ea->namelen);
 }
 
-extern inline secno ea_len(struct extended_attribute *ea)
+static inline secno ea_len(struct extended_attribute *ea)
 {
 	return *(secno *)((char *)ea + 5 + ea->namelen);
 }
 
-extern inline char *ea_data(struct extended_attribute *ea)
+static inline char *ea_data(struct extended_attribute *ea)
 {
 	return (char *)((char *)ea + 5 + ea->namelen);
 }
 
-extern inline unsigned de_size(int namelen, secno down_ptr)
+static inline unsigned de_size(int namelen, secno down_ptr)
 {
 	return ((0x1f + namelen + 3) & ~3) + (down_ptr ? 4 : 0);
 }
 
-extern inline void copy_de(struct hpfs_dirent *dst, struct hpfs_dirent *src)
+static inline void copy_de(struct hpfs_dirent *dst, struct hpfs_dirent *src)
 {
 	int a;
 	int n;
@@ -166,7 +166,7 @@
 	dst->not_8x3 = n;
 }
 
-extern inline unsigned tstbits(unsigned *bmp, unsigned b, unsigned n)
+static inline unsigned tstbits(unsigned *bmp, unsigned b, unsigned n)
 {
 	int i;
 	if ((b >= 0x4000) || (b + n - 1 >= 0x4000)) return n;
diff -rbNu linux-2.4.25-kdb/fs/intermezzo/ext_attr.c linux-2.4.25-kdb-trace/fs/intermezzo/ext_attr.c
--- linux-2.4.25-kdb/fs/intermezzo/ext_attr.c	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/fs/intermezzo/ext_attr.c	2005-01-05 16:45:34.000000000 +0100
@@ -52,7 +52,7 @@
 #ifdef CONFIG_FS_EXT_ATTR
 #include <linux/ext_attr.h>
 
-extern inline void presto_debug_fail_blkdev(struct presto_file_set *fset,
+extern void presto_debug_fail_blkdev(struct presto_file_set *fset,
                                             unsigned long value);
 
 
diff -rbNu linux-2.4.25-kdb/fs/udf/balloc.c linux-2.4.25-kdb-trace/fs/udf/balloc.c
--- linux-2.4.25-kdb/fs/udf/balloc.c	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/fs/udf/balloc.c	2005-01-05 16:45:34.000000000 +0100
@@ -46,7 +46,7 @@
 #define uint(x) xuint(x)
 #define xuint(x) uint ## x ## _t
 
-extern inline int find_next_one_bit (void * addr, int size, int offset)
+static inline int find_next_one_bit (void * addr, int size, int offset)
 {
 	uintBPL_t * p = ((uintBPL_t *) addr) + (offset / BITS_PER_LONG);
 	uintBPL_t result = offset & ~(BITS_PER_LONG-1);
diff -rbNu linux-2.4.25-kdb/fs/xfs/linux/xfs_buf.h linux-2.4.25-kdb-trace/fs/xfs/linux/xfs_buf.h
--- linux-2.4.25-kdb/fs/xfs/linux/xfs_buf.h	2005-01-05 14:04:04.000000000 +0100
+++ linux-2.4.25-kdb-trace/fs/xfs/linux/xfs_buf.h	2005-01-05 17:13:07.000000000 +0100
@@ -509,7 +509,7 @@
 
 #define XFS_BUF_PTR(bp)		(xfs_caddr_t)((bp)->pb_addr)
 
-extern inline xfs_caddr_t xfs_buf_offset(page_buf_t *bp, size_t offset)
+static inline xfs_caddr_t xfs_buf_offset(page_buf_t *bp, size_t offset)
 {
 	if (bp->pb_flags & PBF_MAPPED)
 		return XFS_BUF_PTR(bp) + offset;
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/mmu_context.h linux-2.4.25-kdb-trace/include/asm-alpha/mmu_context.h
--- linux-2.4.25-kdb/include/asm-alpha/mmu_context.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/mmu_context.h	2005-01-05 16:45:36.000000000 +0100
@@ -21,7 +21,7 @@
 #include <asm/io.h>
 #endif
 
-extern inline unsigned long
+static inline unsigned long
 __reload_thread(struct thread_struct *pcb)
 {
 	register unsigned long a0 __asm__("$16");
@@ -221,7 +221,7 @@
 # endif
 #endif
 
-extern inline int
+static inline int
 init_new_context(struct task_struct *tsk, struct mm_struct *mm)
 {
 	int i;
@@ -232,7 +232,7 @@
 	return 0;
 }
 
-extern inline void
+static inline void
 destroy_context(struct mm_struct *mm)
 {
 	/* Nothing to do.  */
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/page.h linux-2.4.25-kdb-trace/include/asm-alpha/page.h
--- linux-2.4.25-kdb/include/asm-alpha/page.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/page.h	2005-01-05 16:45:36.000000000 +0100
@@ -67,7 +67,7 @@
 #define PAGE_BUG(page)	BUG()
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
 	int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/pci.h linux-2.4.25-kdb-trace/include/asm-alpha/pci.h
--- linux-2.4.25-kdb/include/asm-alpha/pci.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-alpha/pci.h	2005-01-05 16:45:36.000000000 +0100
@@ -57,7 +57,7 @@
 
 extern void pcibios_set_master(struct pci_dev *dev);
 
-extern inline void pcibios_penalize_isa_irq(int irq)
+static inline void pcibios_penalize_isa_irq(int irq)
 {
 	/* We don't do dynamic PCI IRQ allocation */
 }
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/pgtable.h linux-2.4.25-kdb-trace/include/asm-alpha/pgtable.h
--- linux-2.4.25-kdb/include/asm-alpha/pgtable.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/pgtable.h	2005-01-05 16:45:36.000000000 +0100
@@ -221,16 +221,16 @@
 })
 #endif
 
-extern inline pte_t mk_pte_phys(unsigned long physpage, pgprot_t pgprot)
+static inline pte_t mk_pte_phys(unsigned long physpage, pgprot_t pgprot)
 { pte_t pte; pte_val(pte) = (PHYS_TWIDDLE(physpage) << (32-PAGE_SHIFT)) | pgprot_val(pgprot); return pte; }
 
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 { pte_val(pte) = (pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot); return pte; }
 
-extern inline void pmd_set(pmd_t * pmdp, pte_t * ptep)
+static inline void pmd_set(pmd_t * pmdp, pte_t * ptep)
 { pmd_val(*pmdp) = _PAGE_TABLE | ((((unsigned long) ptep) - PAGE_OFFSET) << (32-PAGE_SHIFT)); }
 
-extern inline void pgd_set(pgd_t * pgdp, pmd_t * pmdp)
+static inline void pgd_set(pgd_t * pgdp, pmd_t * pmdp)
 { pgd_val(*pgdp) = _PAGE_TABLE | ((((unsigned long) pmdp) - PAGE_OFFSET) << (32-PAGE_SHIFT)); }
 
 #ifndef CONFIG_DISCONTIGMEM
@@ -248,46 +248,46 @@
 })
 #endif
 
-extern inline unsigned long pmd_page(pmd_t pmd)
+static inline unsigned long pmd_page(pmd_t pmd)
 { return PAGE_OFFSET + ((pmd_val(pmd) & _PFN_MASK) >> (32-PAGE_SHIFT)); }
 
-extern inline unsigned long pgd_page(pgd_t pgd)
+static inline unsigned long pgd_page(pgd_t pgd)
 { return PAGE_OFFSET + ((pgd_val(pgd) & _PFN_MASK) >> (32-PAGE_SHIFT)); }
 
-extern inline int pte_none(pte_t pte)		{ return !pte_val(pte); }
-extern inline int pte_present(pte_t pte)	{ return pte_val(pte) & _PAGE_VALID; }
-extern inline void pte_clear(pte_t *ptep)	{ pte_val(*ptep) = 0; }
-
-extern inline int pmd_none(pmd_t pmd)		{ return !pmd_val(pmd); }
-extern inline int pmd_bad(pmd_t pmd)		{ return (pmd_val(pmd) & ~_PFN_MASK) != _PAGE_TABLE; }
-extern inline int pmd_present(pmd_t pmd)	{ return pmd_val(pmd) & _PAGE_VALID; }
-extern inline void pmd_clear(pmd_t * pmdp)	{ pmd_val(*pmdp) = 0; }
-
-extern inline int pgd_none(pgd_t pgd)		{ return !pgd_val(pgd); }
-extern inline int pgd_bad(pgd_t pgd)		{ return (pgd_val(pgd) & ~_PFN_MASK) != _PAGE_TABLE; }
-extern inline int pgd_present(pgd_t pgd)	{ return pgd_val(pgd) & _PAGE_VALID; }
-extern inline void pgd_clear(pgd_t * pgdp)	{ pgd_val(*pgdp) = 0; }
+static inline int pte_none(pte_t pte)		{ return !pte_val(pte); }
+static inline int pte_present(pte_t pte)	{ return pte_val(pte) & _PAGE_VALID; }
+static inline void pte_clear(pte_t *ptep)	{ pte_val(*ptep) = 0; }
+
+static inline int pmd_none(pmd_t pmd)		{ return !pmd_val(pmd); }
+static inline int pmd_bad(pmd_t pmd)		{ return (pmd_val(pmd) & ~_PFN_MASK) != _PAGE_TABLE; }
+static inline int pmd_present(pmd_t pmd)	{ return pmd_val(pmd) & _PAGE_VALID; }
+static inline void pmd_clear(pmd_t * pmdp)	{ pmd_val(*pmdp) = 0; }
+
+static inline int pgd_none(pgd_t pgd)		{ return !pgd_val(pgd); }
+static inline int pgd_bad(pgd_t pgd)		{ return (pgd_val(pgd) & ~_PFN_MASK) != _PAGE_TABLE; }
+static inline int pgd_present(pgd_t pgd)	{ return pgd_val(pgd) & _PAGE_VALID; }
+static inline void pgd_clear(pgd_t * pgdp)	{ pgd_val(*pgdp) = 0; }
 
 /*
  * The following only work if pte_present() is true.
  * Undefined behaviour if not..
  */
-extern inline int pte_read(pte_t pte)		{ return !(pte_val(pte) & _PAGE_FOR); }
-extern inline int pte_write(pte_t pte)		{ return !(pte_val(pte) & _PAGE_FOW); }
-extern inline int pte_exec(pte_t pte)		{ return !(pte_val(pte) & _PAGE_FOE); }
-extern inline int pte_dirty(pte_t pte)		{ return pte_val(pte) & _PAGE_DIRTY; }
-extern inline int pte_young(pte_t pte)		{ return pte_val(pte) & _PAGE_ACCESSED; }
-
-extern inline pte_t pte_wrprotect(pte_t pte)	{ pte_val(pte) |= _PAGE_FOW; return pte; }
-extern inline pte_t pte_rdprotect(pte_t pte)	{ pte_val(pte) |= _PAGE_FOR; return pte; }
-extern inline pte_t pte_exprotect(pte_t pte)	{ pte_val(pte) |= _PAGE_FOE; return pte; }
-extern inline pte_t pte_mkclean(pte_t pte)	{ pte_val(pte) &= ~(__DIRTY_BITS); return pte; }
-extern inline pte_t pte_mkold(pte_t pte)	{ pte_val(pte) &= ~(__ACCESS_BITS); return pte; }
-extern inline pte_t pte_mkwrite(pte_t pte)	{ pte_val(pte) &= ~_PAGE_FOW; return pte; }
-extern inline pte_t pte_mkread(pte_t pte)	{ pte_val(pte) &= ~_PAGE_FOR; return pte; }
-extern inline pte_t pte_mkexec(pte_t pte)	{ pte_val(pte) &= ~_PAGE_FOE; return pte; }
-extern inline pte_t pte_mkdirty(pte_t pte)	{ pte_val(pte) |= __DIRTY_BITS; return pte; }
-extern inline pte_t pte_mkyoung(pte_t pte)	{ pte_val(pte) |= __ACCESS_BITS; return pte; }
+static inline int pte_read(pte_t pte)		{ return !(pte_val(pte) & _PAGE_FOR); }
+static inline int pte_write(pte_t pte)		{ return !(pte_val(pte) & _PAGE_FOW); }
+static inline int pte_exec(pte_t pte)		{ return !(pte_val(pte) & _PAGE_FOE); }
+static inline int pte_dirty(pte_t pte)		{ return pte_val(pte) & _PAGE_DIRTY; }
+static inline int pte_young(pte_t pte)		{ return pte_val(pte) & _PAGE_ACCESSED; }
+
+static inline pte_t pte_wrprotect(pte_t pte)	{ pte_val(pte) |= _PAGE_FOW; return pte; }
+static inline pte_t pte_rdprotect(pte_t pte)	{ pte_val(pte) |= _PAGE_FOR; return pte; }
+static inline pte_t pte_exprotect(pte_t pte)	{ pte_val(pte) |= _PAGE_FOE; return pte; }
+static inline pte_t pte_mkclean(pte_t pte)	{ pte_val(pte) &= ~(__DIRTY_BITS); return pte; }
+static inline pte_t pte_mkold(pte_t pte)	{ pte_val(pte) &= ~(__ACCESS_BITS); return pte; }
+static inline pte_t pte_mkwrite(pte_t pte)	{ pte_val(pte) &= ~_PAGE_FOW; return pte; }
+static inline pte_t pte_mkread(pte_t pte)	{ pte_val(pte) &= ~_PAGE_FOR; return pte; }
+static inline pte_t pte_mkexec(pte_t pte)	{ pte_val(pte) &= ~_PAGE_FOE; return pte; }
+static inline pte_t pte_mkdirty(pte_t pte)	{ pte_val(pte) |= __DIRTY_BITS; return pte; }
+static inline pte_t pte_mkyoung(pte_t pte)	{ pte_val(pte) |= __ACCESS_BITS; return pte; }
 
 #define PAGE_DIR_OFFSET(tsk,address) pgd_offset((tsk),(address))
 
@@ -300,13 +300,13 @@
 #define pgd_offset(mm, address)	((mm)->pgd+pgd_index(address))
 
 /* Find an entry in the second-level page table.. */
-extern inline pmd_t * pmd_offset(pgd_t * dir, unsigned long address)
+static inline pmd_t * pmd_offset(pgd_t * dir, unsigned long address)
 {
 	return (pmd_t *) pgd_page(*dir) + ((address >> PMD_SHIFT) & (PTRS_PER_PAGE - 1));
 }
 
 /* Find an entry in the third-level page table.. */
-extern inline pte_t * pte_offset(pmd_t * dir, unsigned long address)
+static inline pte_t * pte_offset(pmd_t * dir, unsigned long address)
 {
 	return (pte_t *) pmd_page(*dir) + ((address >> PAGE_SHIFT) & (PTRS_PER_PAGE - 1));
 }
@@ -317,7 +317,7 @@
  * The Alpha doesn't have any external MMU info:  the kernel page
  * tables contain all the necessary information.
  */
-extern inline void update_mmu_cache(struct vm_area_struct * vma,
+static inline void update_mmu_cache(struct vm_area_struct * vma,
 	unsigned long address, pte_t pte)
 {
 }
@@ -326,7 +326,7 @@
  * Non-present pages:  high 24 bits are offset, next 8 bits type,
  * low 32 bits zero.
  */
-extern inline pte_t mk_swap_pte(unsigned long type, unsigned long offset)
+static inline pte_t mk_swap_pte(unsigned long type, unsigned long offset)
 { pte_t pte; pte_val(pte) = (type << 32) | (offset << 40); return pte; }
 
 #define SWP_TYPE(x)			(((x).val >> 32) & 0xff)
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/processor.h linux-2.4.25-kdb-trace/include/asm-alpha/processor.h
--- linux-2.4.25-kdb/include/asm-alpha/processor.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-alpha/processor.h	2005-01-05 16:45:36.000000000 +0100
@@ -97,7 +97,7 @@
  * to be in so that we can fail gracefully.  This is just for ps after
  * all.  -- r~
  */
-extern inline unsigned long thread_saved_pc(struct thread_struct *t)
+static inline unsigned long thread_saved_pc(struct thread_struct *t)
 {
 	unsigned long fp, sp = t->ksp, base = (unsigned long)t;
  
@@ -154,17 +154,17 @@
 #define ARCH_HAS_PREFETCHW
 #define ARCH_HAS_SPINLOCK_PREFETCH
 
-extern inline void prefetch(const void *ptr)  
+static inline void prefetch(const void *ptr)  
 { 
 	__asm__ ("ldl $31,%0" : : "m"(*(char *)ptr)); 
 }
 
-extern inline void prefetchw(const void *ptr)  
+static inline void prefetchw(const void *ptr)  
 {
 	__asm__ ("ldl $31,%0" : : "m"(*(char *)ptr)); 
 }
 
-extern inline void spin_lock_prefetch(const void *ptr)  
+static inline void spin_lock_prefetch(const void *ptr)  
 {
 	__asm__ ("ldl $31,%0" : : "m"(*(char *)ptr)); 
 }
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/semaphore.h linux-2.4.25-kdb-trace/include/asm-alpha/semaphore.h
--- linux-2.4.25-kdb/include/asm-alpha/semaphore.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-alpha/semaphore.h	2005-01-05 16:45:36.000000000 +0100
@@ -208,19 +208,19 @@
 }
 
 #if !WAITQUEUE_DEBUG && !defined(CONFIG_DEBUG_SEMAPHORE)
-extern inline void down(struct semaphore *sem)
+static inline void down(struct semaphore *sem)
 {
 	__down(sem);
 }
-extern inline int down_interruptible(struct semaphore *sem)
+static inline int down_interruptible(struct semaphore *sem)
 {
 	return __down_interruptible(sem);
 }
-extern inline int down_trylock(struct semaphore *sem)
+static inline int down_trylock(struct semaphore *sem)
 {
 	return __down_trylock(sem);
 }
-extern inline void up(struct semaphore *sem)
+static inline void up(struct semaphore *sem)
 {
 	__up(sem);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/siginfo.h linux-2.4.25-kdb-trace/include/asm-alpha/siginfo.h
--- linux-2.4.25-kdb/include/asm-alpha/siginfo.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/siginfo.h	2005-01-05 16:45:36.000000000 +0100
@@ -217,7 +217,7 @@
 #ifdef __KERNEL__
 #include <linux/string.h>
 
-extern inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
+static inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
 {
 	if (from->si_code < 0)
 		memcpy(to, from, sizeof(siginfo_t));
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/softirq.h linux-2.4.25-kdb-trace/include/asm-alpha/softirq.h
--- linux-2.4.25-kdb/include/asm-alpha/softirq.h	2001-09-08 21:02:31.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/softirq.h	2005-01-05 16:45:36.000000000 +0100
@@ -5,13 +5,13 @@
 #include <asm/atomic.h>
 #include <asm/hardirq.h>
 
-extern inline void cpu_bh_disable(int cpu)
+static inline void cpu_bh_disable(int cpu)
 {
 	local_bh_count(cpu)++;
 	barrier();
 }
 
-extern inline void __cpu_bh_enable(int cpu)
+static inline void __cpu_bh_enable(int cpu)
 {
 	barrier();
 	local_bh_count(cpu)--;
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/system.h linux-2.4.25-kdb-trace/include/asm-alpha/system.h
--- linux-2.4.25-kdb/include/asm-alpha/system.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-alpha/system.h	2005-01-05 16:45:36.000000000 +0100
@@ -373,7 +373,7 @@
  * it must clobber "memory" (also for interrupts in UP).
  */
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __xchg_u32(volatile int *m, unsigned long val)
 {
 	unsigned long dummy;
@@ -395,7 +395,7 @@
 	return val;
 }
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __xchg_u64(volatile long *m, unsigned long val)
 {
 	unsigned long dummy;
@@ -456,7 +456,7 @@
 
 #define __HAVE_ARCH_CMPXCHG 1
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __cmpxchg_u32(volatile int *m, int old, int new)
 {
 	unsigned long prev, cmp;
@@ -481,7 +481,7 @@
 	return prev;
 }
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __cmpxchg_u64(volatile long *m, unsigned long old, unsigned long new)
 {
 	unsigned long prev, cmp;
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/uaccess.h linux-2.4.25-kdb-trace/include/asm-alpha/uaccess.h
--- linux-2.4.25-kdb/include/asm-alpha/uaccess.h	2000-08-29 23:09:15.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/uaccess.h	2005-01-05 16:45:36.000000000 +0100
@@ -46,7 +46,7 @@
 #define access_ok(type,addr,size) \
 	__access_ok(((unsigned long)(addr)),(size),get_fs())
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
 	return access_ok(type,addr,size) ? 0 : -EFAULT;
 }
@@ -342,7 +342,7 @@
 
 extern void __copy_user(void);
 
-extern inline long
+static inline long
 __copy_tofrom_user_nocheck(void *to, const void *from, long len)
 {
 	/* This little bit of silliness is to get the GP loaded for
@@ -364,7 +364,7 @@
 	return __cu_len;
 }
 
-extern inline long
+static inline long
 __copy_tofrom_user(void *to, const void *from, long len, const void *validate)
 {
 	if (__access_ok((long)validate, len, get_fs())) {
@@ -387,13 +387,13 @@
 #define __copy_to_user(to,from,n)   __copy_tofrom_user_nocheck((to),(from),(n))
 #define __copy_from_user(to,from,n) __copy_tofrom_user_nocheck((to),(from),(n))
 
-extern inline long
+static inline long
 copy_to_user(void *to, const void *from, long n)
 {
 	return __copy_tofrom_user(to, from, n, to);
 }
 
-extern inline long
+static inline long
 copy_from_user(void *to, const void *from, long n)
 {
 	return __copy_tofrom_user(to, from, n, from);
@@ -401,7 +401,7 @@
 
 extern void __do_clear_user(void);
 
-extern inline long
+static inline long
 __clear_user(void *to, long len)
 {
 	/* This little bit of silliness is to get the GP loaded for
@@ -420,7 +420,7 @@
 	return __cl_len;
 }
 
-extern inline long
+static inline long
 clear_user(void *to, long len)
 {
 	if (__access_ok((long)to, len, get_fs())) {
@@ -442,7 +442,7 @@
 
 extern long __strncpy_from_user(char *__to, const char *__from, long __to_len);
 
-extern inline long
+static inline long
 strncpy_from_user(char *to, const char *from, long n)
 {
 	long ret = -EFAULT;
@@ -454,7 +454,7 @@
 /* Returns: 0 if bad, string length+1 (memory size) of string if ok */
 extern long __strlen_user(const char *);
 
-extern inline long strlen_user(const char *str)
+static inline long strlen_user(const char *str)
 {
 	return access_ok(VERIFY_READ,str,0) ? __strlen_user(str) : 0;
 }
@@ -463,7 +463,7 @@
  * a value greater than N if the limit would be exceeded, else strlen.  */
 extern long __strnlen_user(const char *, long);
 
-extern inline long strnlen_user(const char *str, long n)
+static inline long strnlen_user(const char *str, long n)
 {
 	return access_ok(VERIFY_READ,str,0) ? __strnlen_user(str, n) : 0;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/unaligned.h linux-2.4.25-kdb-trace/include/asm-alpha/unaligned.h
--- linux-2.4.25-kdb/include/asm-alpha/unaligned.h	2000-10-26 22:55:10.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/unaligned.h	2005-01-05 16:45:36.000000000 +0100
@@ -29,19 +29,19 @@
  * Elemental unaligned loads 
  */
 
-extern inline unsigned long __uldq(const unsigned long * r11)
+static inline unsigned long __uldq(const unsigned long * r11)
 {
 	const struct __una_u64 *ptr = (const struct __una_u64 *) r11;
 	return ptr->x;
 }
 
-extern inline unsigned long __uldl(const unsigned int * r11)
+static inline unsigned long __uldl(const unsigned int * r11)
 {
 	const struct __una_u32 *ptr = (const struct __una_u32 *) r11;
 	return ptr->x;
 }
 
-extern inline unsigned long __uldw(const unsigned short * r11)
+static inline unsigned long __uldw(const unsigned short * r11)
 {
 	const struct __una_u16 *ptr = (const struct __una_u16 *) r11;
 	return ptr->x;
@@ -51,25 +51,25 @@
  * Elemental unaligned stores 
  */
 
-extern inline void __ustq(unsigned long r5, unsigned long * r11)
+static inline void __ustq(unsigned long r5, unsigned long * r11)
 {
 	struct __una_u64 *ptr = (struct __una_u64 *) r11;
 	ptr->x = r5;
 }
 
-extern inline void __ustl(unsigned long r5, unsigned int * r11)
+static inline void __ustl(unsigned long r5, unsigned int * r11)
 {
 	struct __una_u32 *ptr = (struct __una_u32 *) r11;
 	ptr->x = r5;
 }
 
-extern inline void __ustw(unsigned long r5, unsigned short * r11)
+static inline void __ustw(unsigned long r5, unsigned short * r11)
 {
 	struct __una_u16 *ptr = (struct __una_u16 *) r11;
 	ptr->x = r5;
 }
 
-extern inline unsigned long __get_unaligned(const void *ptr, size_t size)
+static inline unsigned long __get_unaligned(const void *ptr, size_t size)
 {
 	unsigned long val;
 	switch (size) {
@@ -91,7 +91,7 @@
 	return val;
 }
 
-extern inline void __put_unaligned(unsigned long val, void *ptr, size_t size)
+static inline void __put_unaligned(unsigned long val, void *ptr, size_t size)
 {
 	switch (size) {
 	      case 1:
diff -rbNu linux-2.4.25-kdb/include/asm-alpha/vga.h linux-2.4.25-kdb-trace/include/asm-alpha/vga.h
--- linux-2.4.25-kdb/include/asm-alpha/vga.h	2001-10-15 22:47:28.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-alpha/vga.h	2005-01-05 16:45:36.000000000 +0100
@@ -13,7 +13,7 @@
 #define VT_BUF_HAVE_MEMSETW
 #define VT_BUF_HAVE_MEMCPYW
 
-extern inline void scr_writew(u16 val, volatile u16 *addr)
+static inline void scr_writew(u16 val, volatile u16 *addr)
 {
 	if (__is_ioaddr((unsigned long) addr))
 		__raw_writew(val, (unsigned long) addr);
@@ -21,7 +21,7 @@
 		*addr = val;
 }
 
-extern inline u16 scr_readw(volatile const u16 *addr)
+static inline u16 scr_readw(volatile const u16 *addr)
 {
 	if (__is_ioaddr((unsigned long) addr))
 		return __raw_readw((unsigned long) addr);
@@ -29,7 +29,7 @@
 		return *addr;
 }
 
-extern inline void scr_memsetw(u16 *s, u16 c, unsigned int count)
+static inline void scr_memsetw(u16 *s, u16 c, unsigned int count)
 {
 	if (__is_ioaddr((unsigned long) s))
 		memsetw_io(s, c, count);
diff -rbNu linux-2.4.25-kdb/include/asm-arm/arch-epxa/system.h linux-2.4.25-kdb-trace/include/asm-arm/arch-epxa/system.h
--- linux-2.4.25-kdb/include/asm-arm/arch-epxa/system.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-arm/arch-epxa/system.h	2005-01-05 16:45:37.000000000 +0100
@@ -36,7 +36,7 @@
 	cpu_do_idle();
 }
 
-extern __inline__ void arch_reset(char mode)
+static __inline__ void arch_reset(char mode)
 {
 
 	/* Force the watchdog to generate a reset */
diff -rbNu linux-2.4.25-kdb/include/asm-arm/arch-epxa/time.h linux-2.4.25-kdb-trace/include/asm-arm/arch-epxa/time.h
--- linux-2.4.25-kdb/include/asm-arm/arch-epxa/time.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-arm/arch-epxa/time.h	2005-01-05 16:45:37.000000000 +0100
@@ -42,7 +42,7 @@
 /*
  * Set up timer interrupt, and return the current time in seconds.
  */
-extern __inline__ void setup_timer(void)
+static __inline__ void setup_timer(void)
 {
 
 
diff -rbNu linux-2.4.25-kdb/include/asm-cris/atomic.h linux-2.4.25-kdb-trace/include/asm-cris/atomic.h
--- linux-2.4.25-kdb/include/asm-cris/atomic.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/atomic.h	2005-01-05 16:45:40.000000000 +0100
@@ -25,7 +25,7 @@
 
 /* These should be written in asm but we do it in C for now. */
 
-extern __inline__ void atomic_add(int i, volatile atomic_t *v)
+static __inline__ void atomic_add(int i, volatile atomic_t *v)
 {
 	unsigned long flags;
 	save_flags(flags);
@@ -34,7 +34,7 @@
 	restore_flags(flags);
 }
 
-extern __inline__ void atomic_sub(int i, volatile atomic_t *v)
+static __inline__ void atomic_sub(int i, volatile atomic_t *v)
 {
 	unsigned long flags;
 	save_flags(flags);
@@ -43,7 +43,7 @@
 	restore_flags(flags);
 }
 
-extern __inline__ int atomic_add_return(int i, volatile atomic_t *v)
+static __inline__ int atomic_add_return(int i, volatile atomic_t *v)
 {
 	unsigned long flags;
 	int retval;
@@ -54,7 +54,7 @@
 	return retval;
 }
 
-extern __inline__ int atomic_sub_return(int i, volatile atomic_t *v)
+static __inline__ int atomic_sub_return(int i, volatile atomic_t *v)
 {
 	unsigned long flags;
 	int retval;
@@ -65,7 +65,7 @@
 	return retval;
 }
 
-extern __inline__ int atomic_sub_and_test(int i, volatile atomic_t *v)
+static __inline__ int atomic_sub_and_test(int i, volatile atomic_t *v)
 {
 	int retval;
 	unsigned long flags;
@@ -76,7 +76,7 @@
 	return retval;
 }
 
-extern __inline__ void atomic_inc(volatile atomic_t *v)
+static __inline__ void atomic_inc(volatile atomic_t *v)
 {
 	unsigned long flags;
 	save_flags(flags);
@@ -85,7 +85,7 @@
 	restore_flags(flags);
 }
 
-extern __inline__ void atomic_dec(volatile atomic_t *v)
+static __inline__ void atomic_dec(volatile atomic_t *v)
 {
 	unsigned long flags;
 	save_flags(flags);
@@ -94,7 +94,7 @@
 	restore_flags(flags);
 }
 
-extern __inline__ int atomic_inc_return(volatile atomic_t *v)
+static __inline__ int atomic_inc_return(volatile atomic_t *v)
 {
 	unsigned long flags;
 	int retval;
@@ -105,7 +105,7 @@
 	return retval;
 }
 
-extern __inline__ int atomic_dec_return(volatile atomic_t *v)
+static __inline__ int atomic_dec_return(volatile atomic_t *v)
 {
 	unsigned long flags;
 	int retval;
@@ -115,7 +115,7 @@
 	restore_flags(flags);
 	return retval;
 }
-extern __inline__ int atomic_dec_and_test(volatile atomic_t *v)
+static __inline__ int atomic_dec_and_test(volatile atomic_t *v)
 {
 	int retval;
 	unsigned long flags;
@@ -126,7 +126,7 @@
 	return retval;
 }
 
-extern __inline__ int atomic_inc_and_test(volatile atomic_t *v)
+static __inline__ int atomic_inc_and_test(volatile atomic_t *v)
 {
 	int retval;
 	unsigned long flags;
diff -rbNu linux-2.4.25-kdb/include/asm-cris/bitops.h linux-2.4.25-kdb-trace/include/asm-cris/bitops.h
--- linux-2.4.25-kdb/include/asm-cris/bitops.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-cris/bitops.h	2005-01-05 16:45:40.000000000 +0100
@@ -91,7 +91,7 @@
  * It also implies a memory barrier.
  */
 
-extern __inline__ int test_and_set_bit(int nr, void *addr)
+static __inline__ int test_and_set_bit(int nr, void *addr)
 {
 	unsigned int mask, retval;
 	unsigned long flags;
@@ -107,7 +107,7 @@
 	return retval;
 }
 
-extern inline int __test_and_set_bit(int nr, void *addr)
+static inline int __test_and_set_bit(int nr, void *addr)
 {
 	unsigned int mask, retval;
 	unsigned int *adr = (unsigned int *)addr;
@@ -134,7 +134,7 @@
  * It also implies a memory barrier.
  */
 
-extern __inline__ int test_and_clear_bit(int nr, void *addr)
+static __inline__ int test_and_clear_bit(int nr, void *addr)
 {
 	unsigned int mask, retval;
 	unsigned long flags;
@@ -160,7 +160,7 @@
  * but actually fail.  You must protect multiple accesses with a lock.
  */
 
-extern __inline__ int __test_and_clear_bit(int nr, void *addr)
+static __inline__ int __test_and_clear_bit(int nr, void *addr)
 {
 	unsigned int mask, retval;
 	unsigned int *adr = (unsigned int *)addr;
@@ -180,7 +180,7 @@
  * It also implies a memory barrier.
  */
 
-extern __inline__ int test_and_change_bit(int nr, void *addr)
+static __inline__ int test_and_change_bit(int nr, void *addr)
 {
 	unsigned int mask, retval;
 	unsigned long flags;
@@ -197,7 +197,7 @@
 
 /* WARNING: non atomic and it can be reordered! */
 
-extern __inline__ int __test_and_change_bit(int nr, void *addr)
+static __inline__ int __test_and_change_bit(int nr, void *addr)
 {
 	unsigned int mask, retval;
 	unsigned int *adr = (unsigned int *)addr;
@@ -218,7 +218,7 @@
  * This routine doesn't need to be atomic.
  */
 
-extern __inline__ int test_bit(int nr, const void *addr)
+static __inline__ int test_bit(int nr, const void *addr)
 {
 	unsigned int mask;
 	unsigned int *adr = (unsigned int *)addr;
@@ -239,7 +239,7 @@
  * number.  They differ in that the first function also inverts all bits
  * in the input.
  */
-extern __inline__ unsigned long cris_swapnwbrlz(unsigned long w)
+static __inline__ unsigned long cris_swapnwbrlz(unsigned long w)
 {
 	/* Let's just say we return the result in the same register as the
 	   input.  Saying we clobber the input but can return the result
@@ -255,7 +255,7 @@
 	return res;
 }
 
-extern __inline__ unsigned long cris_swapwbrlz(unsigned long w)
+static __inline__ unsigned long cris_swapwbrlz(unsigned long w)
 {
 	unsigned res;
 	__asm__ ("swapwbr %0 \n\t"
@@ -269,7 +269,7 @@
  * ffz = Find First Zero in word. Undefined if no zero exists,
  * so code should check against ~0UL first..
  */
-extern __inline__ unsigned long ffz(unsigned long w)
+static __inline__ unsigned long ffz(unsigned long w)
 {
 	/* The generic_ffs function is used to avoid the asm when the
 	   argument is a constant.  */
@@ -282,7 +282,7 @@
  * Somewhat like ffz but the equivalent of generic_ffs: in contrast to
  * ffz we return the first one-bit *plus one*.
  */
-extern __inline__ unsigned long kernel_ffs(unsigned long w)
+static __inline__ unsigned long kernel_ffs(unsigned long w)
 {
 	/* The generic_ffs function is used to avoid the asm when the
 	   argument is a constant.  */
@@ -304,7 +304,7 @@
  * @offset: The bitnumber to start searching at
  * @size: The maximum size to search
  */
-extern __inline__ int find_next_zero_bit (void * addr, int size, int offset)
+static __inline__ int find_next_zero_bit (void * addr, int size, int offset)
 {
 	unsigned long *p = ((unsigned long *) addr) + (offset >> 5);
 	unsigned long result = offset & ~31UL;
diff -rbNu linux-2.4.25-kdb/include/asm-cris/byteorder.h linux-2.4.25-kdb-trace/include/asm-cris/byteorder.h
--- linux-2.4.25-kdb/include/asm-cris/byteorder.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/byteorder.h	2005-01-05 16:45:40.000000000 +0100
@@ -10,14 +10,14 @@
  * them together into ntohl etc.
  */
 
-extern __inline__ __const__ __u32 ___arch__swab32(__u32 x)
+static __inline__ __const__ __u32 ___arch__swab32(__u32 x)
 {
 	__asm__ ("swapwb %0" : "=r" (x) : "0" (x));
 
 	return(x);
 }
 
-extern __inline__ __const__ __u16 ___arch__swab16(__u16 x)
+static __inline__ __const__ __u16 ___arch__swab16(__u16 x)
 {
 	__asm__ ("swapb %0" : "=r" (x) : "0" (x));
 
diff -rbNu linux-2.4.25-kdb/include/asm-cris/checksum.h linux-2.4.25-kdb-trace/include/asm-cris/checksum.h
--- linux-2.4.25-kdb/include/asm-cris/checksum.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/checksum.h	2005-01-05 16:45:41.000000000 +0100
@@ -32,7 +32,7 @@
  *	Fold a partial checksum into a word
  */
 
-extern inline unsigned int csum_fold(unsigned int sum)
+static inline unsigned int csum_fold(unsigned int sum)
 {
 	/* the while loop is unnecessary really, it's always enough with two
 	   iterations */
@@ -50,7 +50,7 @@
  * to split all of those into 16-bit components, then add.
  */
 
-extern inline unsigned int
+static inline unsigned int
 csum_tcpudp_nofold(unsigned long saddr, unsigned long daddr, unsigned short len,
 		   unsigned short proto, unsigned int sum)
 {
@@ -78,7 +78,7 @@
  *
  */
 
-extern inline unsigned short ip_fast_csum(unsigned char * iph,
+static inline unsigned short ip_fast_csum(unsigned char * iph,
 					  unsigned int ihl)
 {
 	return csum_fold(csum_partial(iph, ihl * 4, 0));
@@ -89,7 +89,7 @@
  * returns a 16-bit checksum, already complemented
  */
 
-extern inline unsigned short int csum_tcpudp_magic(unsigned long saddr,
+static inline unsigned short int csum_tcpudp_magic(unsigned long saddr,
 						   unsigned long daddr,
 						   unsigned short len,
 						   unsigned short proto,
@@ -103,7 +103,7 @@
  * in icmp.c
  */
 
-extern inline unsigned short ip_compute_csum(unsigned char * buff, int len) {
+static inline unsigned short ip_compute_csum(unsigned char * buff, int len) {
 	return csum_fold (csum_partial(buff, len, 0));
 }
 
diff -rbNu linux-2.4.25-kdb/include/asm-cris/current.h linux-2.4.25-kdb-trace/include/asm-cris/current.h
--- linux-2.4.25-kdb/include/asm-cris/current.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/current.h	2005-01-05 16:45:41.000000000 +0100
@@ -3,7 +3,7 @@
 
 struct task_struct;
 
-extern inline struct task_struct * get_current(void)
+static inline struct task_struct * get_current(void)
 {
         struct task_struct *current;
         __asm__("and.d $sp,%0; ":"=r" (current) : "0" (~8191UL));
diff -rbNu linux-2.4.25-kdb/include/asm-cris/delay.h linux-2.4.25-kdb-trace/include/asm-cris/delay.h
--- linux-2.4.25-kdb/include/asm-cris/delay.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/delay.h	2005-01-05 16:45:40.000000000 +0100
@@ -16,7 +16,7 @@
 
 extern void __do_delay(void);	/* Special register call calling convention */
 
-extern __inline__ void __delay(int loops)
+static __inline__ void __delay(int loops)
 {
 	__asm__ __volatile__ (
 			      "move.d %0,$r9\n\t"
@@ -34,14 +34,14 @@
 
 extern unsigned long loops_per_usec; /* arch/cris/mm/init.c */
 
-extern __inline__ void udelay(unsigned long usecs)
+static __inline__ void udelay(unsigned long usecs)
 {
 	__delay(usecs * loops_per_usec);
 }
 
 /* ETRAX 100 is really too slow to sleep for nanosecs. */
 /* Divide with 1024 to avoid a real division that would take >1 us... */
-extern __inline__ void ndelay(unsigned long nsecs)
+static __inline__ void ndelay(unsigned long nsecs)
 {
 	__delay(1 + nsecs * loops_per_usec / 1024);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-cris/fasttimer.h linux-2.4.25-kdb-trace/include/asm-cris/fasttimer.h
--- linux-2.4.25-kdb/include/asm-cris/fasttimer.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/fasttimer.h	2005-01-05 16:45:40.000000000 +0100
@@ -41,7 +41,7 @@
 int del_fast_timer(struct fast_timer * t);
 /* return 1 if deleted */
 
-extern inline int fast_timer_pending (const struct fast_timer * t)
+static inline int fast_timer_pending (const struct fast_timer * t)
 {
   return (t->next != NULL) || (t->prev != NULL) || (t == fast_timer_list);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-cris/ide.h linux-2.4.25-kdb-trace/include/asm-cris/ide.h
--- linux-2.4.25-kdb/include/asm-cris/ide.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/ide.h	2005-01-05 16:45:40.000000000 +0100
@@ -25,7 +25,7 @@
 
 #define MAX_HWIFS	4
 
-extern __inline__ int ide_default_irq(ide_ioreg_t base)
+static __inline__ int ide_default_irq(ide_ioreg_t base)
 {
 	/* all IDE busses share the same IRQ, number 4.
 	 * this has the side-effect that ide-probe.c will cluster our 4 interfaces
@@ -35,7 +35,7 @@
 	return 4; 
 }
 
-extern __inline__ ide_ioreg_t ide_default_io_base(int index)
+static __inline__ ide_ioreg_t ide_default_io_base(int index)
 {
 	/* we have no real I/O base address per interface, since all go through the
 	 * same register. but in a bitfield in that register, we have the i/f number.
@@ -54,7 +54,7 @@
  * of the ide_default_io_base call above. ctrl_port will be 0, but that is don't care for us.
  */
 
-extern __inline__ void ide_init_hwif_ports(hw_regs_t *hw, ide_ioreg_t data_port, ide_ioreg_t ctrl_port, int *irq)
+static __inline__ void ide_init_hwif_ports(hw_regs_t *hw, ide_ioreg_t data_port, ide_ioreg_t ctrl_port, int *irq)
 {
 	int i;
 
@@ -77,7 +77,7 @@
 	hw->io_ports[IDE_IRQ_OFFSET] = 0;
 }
 
-extern __inline__ void ide_init_default_hwifs(void)
+static __inline__ void ide_init_default_hwifs(void)
 {
 	hw_regs_t hw;
 	int index;
diff -rbNu linux-2.4.25-kdb/include/asm-cris/io.h linux-2.4.25-kdb-trace/include/asm-cris/io.h
--- linux-2.4.25-kdb/include/asm-cris/io.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/io.h	2005-01-05 16:45:40.000000000 +0100
@@ -201,12 +201,12 @@
  * Change virtual addresses to physical addresses and vv.
  */
 
-extern inline unsigned long virt_to_phys(volatile void * address)
+static inline unsigned long virt_to_phys(volatile void * address)
 {
 	return __pa(address);
 }
 
-extern inline void * phys_to_virt(unsigned long address)
+static inline void * phys_to_virt(unsigned long address)
 {
 	return __va(address);
 }
@@ -215,7 +215,7 @@
 
 extern void * __ioremap(unsigned long offset, unsigned long size, unsigned long flags);
 
-extern inline void * ioremap (unsigned long offset, unsigned long size)
+static inline void * ioremap (unsigned long offset, unsigned long size)
 {
 	return __ioremap(offset, size, 0);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-cris/locks.h linux-2.4.25-kdb-trace/include/asm-cris/locks.h
--- linux-2.4.25-kdb/include/asm-cris/locks.h	2001-02-09 01:32:44.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-cris/locks.h	2005-01-05 16:45:41.000000000 +0100
@@ -10,7 +10,7 @@
  *	to borrow for other processors if it was just assembler.
  */
 
-extern __inline__ void prim_spin_lock(struct spinlock *sp)
+static __inline__ void prim_spin_lock(struct spinlock *sp)
 {
 	int processor=smp_processor_id();
 	
@@ -56,7 +56,7 @@
  *	Release a spin lock
  */
  
-extern __inline__ int prim_spin_unlock(struct spinlock *sp)
+static __inline__ int prim_spin_unlock(struct spinlock *sp)
 {
 	/* This is safe. The decrement is still guarded by the lock. A multilock would
 	   not be safe this way */
@@ -73,7 +73,7 @@
  *	Non blocking lock grab
  */
  
-extern __inline__ int prim_spin_lock_nb(struct spinlock *sp)
+static __inline__ int prim_spin_lock_nb(struct spinlock *sp)
 {
 	if(lock_set_bit(0,&sp->lock))
 		return 0;		/* Locked already */
@@ -86,7 +86,7 @@
  *	These wrap the locking primitives up for usage
  */
  
-extern __inline__ void spinlock(struct spinlock *sp)
+static __inline__ void spinlock(struct spinlock *sp)
 {
 	if(sp->priority<current->lock_order)
 		panic("lock order violation: %s (%d)\n", sp->name, current->lock_order);
@@ -100,7 +100,7 @@
 	}
 }
 
-extern __inline__ void spinunlock(struct spinlock *sp)
+static __inline__ void spinunlock(struct spinlock *sp)
 {
 	if(current->lock_order!=sp->priority)
 		panic("lock release order violation %s (%d)\n", sp->name, current->lock_order);
@@ -114,7 +114,7 @@
 	}	
 }
 
-extern __inline__ void spintestlock(struct spinlock *sp)
+static __inline__ void spintestlock(struct spinlock *sp)
 {
 	/*
 	 *	We do no sanity checks, it's legal to optimistically
@@ -123,7 +123,7 @@
 	prim_spin_lock_nb(sp);
 }
 
-extern __inline__ void spintestunlock(struct spinlock *sp)
+static __inline__ void spintestunlock(struct spinlock *sp)
 {
 	/*
 	 *	A testlock doesn't update the lock chain so we
diff -rbNu linux-2.4.25-kdb/include/asm-cris/mmu_context.h linux-2.4.25-kdb-trace/include/asm-cris/mmu_context.h
--- linux-2.4.25-kdb/include/asm-cris/mmu_context.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/mmu_context.h	2005-01-05 16:45:41.000000000 +0100
@@ -15,7 +15,7 @@
 
 extern volatile pgd_t *current_pgd;   /* defined in arch/cris/mm/fault.c */
 
-extern inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk, unsigned cpu)
+static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk, unsigned cpu)
 {
 }
 
diff -rbNu linux-2.4.25-kdb/include/asm-cris/pgalloc.h linux-2.4.25-kdb-trace/include/asm-cris/pgalloc.h
--- linux-2.4.25-kdb/include/asm-cris/pgalloc.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/pgalloc.h	2005-01-05 16:45:41.000000000 +0100
@@ -21,7 +21,7 @@
  * Allocate and free page tables.
  */
 
-extern __inline__ pgd_t *get_pgd_slow(void)
+static __inline__ pgd_t *get_pgd_slow(void)
 {
         pgd_t *ret = (pgd_t *)__get_free_page(GFP_KERNEL);
 
@@ -33,12 +33,12 @@
         return ret;
 }
 
-extern __inline__ void free_pgd_slow(pgd_t *pgd)
+static __inline__ void free_pgd_slow(pgd_t *pgd)
 {
         free_page((unsigned long)pgd);
 }
 
-extern __inline__ pgd_t *get_pgd_fast(void)
+static __inline__ pgd_t *get_pgd_fast(void)
 {
         unsigned long *ret;
 
@@ -51,14 +51,14 @@
         return (pgd_t *)ret;
 }
 
-extern __inline__ void free_pgd_fast(pgd_t *pgd)
+static __inline__ void free_pgd_fast(pgd_t *pgd)
 {
         *(unsigned long *)pgd = (unsigned long) pgd_quicklist;
         pgd_quicklist = (unsigned long *) pgd;
         pgtable_cache_size++;
 }
 
-extern inline pte_t *pte_alloc_one(struct mm_struct *mm, unsigned long address)
+static inline pte_t *pte_alloc_one(struct mm_struct *mm, unsigned long address)
 {
         pte_t *pte;
 
@@ -68,7 +68,7 @@
         return pte;
 }
 
-extern inline pte_t *pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
+static inline pte_t *pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
 {
         unsigned long *ret;
 
@@ -80,14 +80,14 @@
         return (pte_t *)ret;
 }
 
-extern __inline__ void pte_free_fast(pte_t *pte)
+static __inline__ void pte_free_fast(pte_t *pte)
 {
         *(unsigned long *)pte = (unsigned long) pte_quicklist;
         pte_quicklist = (unsigned long *) pte;
         pgtable_cache_size++;
 }
 
-extern __inline__ void pte_free_slow(pte_t *pte)
+static __inline__ void pte_free_slow(pte_t *pte)
 {
         free_page((unsigned long)pte);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-cris/pgtable.h linux-2.4.25-kdb-trace/include/asm-cris/pgtable.h
--- linux-2.4.25-kdb/include/asm-cris/pgtable.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/pgtable.h	2005-01-05 16:45:41.000000000 +0100
@@ -155,14 +155,14 @@
 			    unsigned long start,
 			    unsigned long end);
 
-extern inline void flush_tlb_pgtables(struct mm_struct *mm,
+static inline void flush_tlb_pgtables(struct mm_struct *mm,
                                       unsigned long start, unsigned long end)
 {
         /* CRIS does not keep any page table caches in TLB */
 }
 
 
-extern inline void flush_tlb(void) 
+static inline void flush_tlb(void) 
 {
 	flush_tlb_mm(current->mm);
 }
@@ -311,53 +311,53 @@
  * setup: the pgd is never bad, and a pmd always exists (as it's folded
  * into the pgd entry)
  */
-extern inline int pgd_none(pgd_t pgd)		{ return 0; }
-extern inline int pgd_bad(pgd_t pgd)		{ return 0; }
-extern inline int pgd_present(pgd_t pgd)	{ return 1; }
-extern inline void pgd_clear(pgd_t * pgdp)	{ }
+static inline int pgd_none(pgd_t pgd)		{ return 0; }
+static inline int pgd_bad(pgd_t pgd)		{ return 0; }
+static inline int pgd_present(pgd_t pgd)	{ return 1; }
+static inline void pgd_clear(pgd_t * pgdp)	{ }
 
 /*
  * The following only work if pte_present() is true.
  * Undefined behaviour if not..
  */
 
-extern inline int pte_read(pte_t pte)           { return pte_val(pte) & _PAGE_READ; }
-extern inline int pte_write(pte_t pte)          { return pte_val(pte) & _PAGE_WRITE; }
-extern inline int pte_exec(pte_t pte)           { return pte_val(pte) & _PAGE_READ; }
-extern inline int pte_dirty(pte_t pte)          { return pte_val(pte) & _PAGE_MODIFIED; }
-extern inline int pte_young(pte_t pte)          { return pte_val(pte) & _PAGE_ACCESSED; }
+static inline int pte_read(pte_t pte)           { return pte_val(pte) & _PAGE_READ; }
+static inline int pte_write(pte_t pte)          { return pte_val(pte) & _PAGE_WRITE; }
+static inline int pte_exec(pte_t pte)           { return pte_val(pte) & _PAGE_READ; }
+static inline int pte_dirty(pte_t pte)          { return pte_val(pte) & _PAGE_MODIFIED; }
+static inline int pte_young(pte_t pte)          { return pte_val(pte) & _PAGE_ACCESSED; }
 
-extern inline pte_t pte_wrprotect(pte_t pte)
+static inline pte_t pte_wrprotect(pte_t pte)
 {
         pte_val(pte) &= ~(_PAGE_WRITE | _PAGE_SILENT_WRITE);
         return pte;
 }
 
-extern inline pte_t pte_rdprotect(pte_t pte)
+static inline pte_t pte_rdprotect(pte_t pte)
 {
         pte_val(pte) &= ~(_PAGE_READ | _PAGE_SILENT_READ);
 	return pte;
 }
 
-extern inline pte_t pte_exprotect(pte_t pte)
+static inline pte_t pte_exprotect(pte_t pte)
 {
         pte_val(pte) &= ~(_PAGE_READ | _PAGE_SILENT_READ);
 	return pte;
 }
 
-extern inline pte_t pte_mkclean(pte_t pte)
+static inline pte_t pte_mkclean(pte_t pte)
 {
 	pte_val(pte) &= ~(_PAGE_MODIFIED | _PAGE_SILENT_WRITE); 
 	return pte; 
 }
 
-extern inline pte_t pte_mkold(pte_t pte)
+static inline pte_t pte_mkold(pte_t pte)
 {
 	pte_val(pte) &= ~(_PAGE_ACCESSED | _PAGE_SILENT_READ);
 	return pte;
 }
 
-extern inline pte_t pte_mkwrite(pte_t pte)
+static inline pte_t pte_mkwrite(pte_t pte)
 {
         pte_val(pte) |= _PAGE_WRITE;
         if (pte_val(pte) & _PAGE_MODIFIED)
@@ -365,7 +365,7 @@
         return pte;
 }
 
-extern inline pte_t pte_mkread(pte_t pte)
+static inline pte_t pte_mkread(pte_t pte)
 {
         pte_val(pte) |= _PAGE_READ;
         if (pte_val(pte) & _PAGE_ACCESSED)
@@ -373,7 +373,7 @@
         return pte;
 }
 
-extern inline pte_t pte_mkexec(pte_t pte)
+static inline pte_t pte_mkexec(pte_t pte)
 {
         pte_val(pte) |= _PAGE_READ;
         if (pte_val(pte) & _PAGE_ACCESSED)
@@ -381,7 +381,7 @@
         return pte;
 }
 
-extern inline pte_t pte_mkdirty(pte_t pte)
+static inline pte_t pte_mkdirty(pte_t pte)
 {
         pte_val(pte) |= _PAGE_MODIFIED;
         if (pte_val(pte) & _PAGE_WRITE)
@@ -389,7 +389,7 @@
         return pte;
 }
 
-extern inline pte_t pte_mkyoung(pte_t pte)
+static inline pte_t pte_mkyoung(pte_t pte)
 {
         pte_val(pte) |= _PAGE_ACCESSED;
         if (pte_val(pte) & _PAGE_READ)
@@ -413,7 +413,7 @@
  * addresses (the 0xc0xxxxxx's) goes as void *'s.
  */
 
-extern inline pte_t __mk_pte(void * page, pgprot_t pgprot)
+static inline pte_t __mk_pte(void * page, pgprot_t pgprot)
 {
 	pte_t pte;
 	/* the PTE needs a physical address */
@@ -431,7 +431,7 @@
         __pte;                                                          \
 })
 
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 { pte_val(pte) = (pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot); return pte; }
 
 
@@ -440,7 +440,7 @@
  * pte_pagenr refers to the page-number counted starting from the virtual DRAM start
  */
 
-extern inline unsigned long __pte_page(pte_t pte)
+static inline unsigned long __pte_page(pte_t pte)
 {
 	/* the PTE contains a physical address */
 	return (unsigned long)__va(pte_val(pte) & PAGE_MASK);
@@ -458,17 +458,17 @@
  * don't need the __pa and __va transformations.
  */
 
-extern inline unsigned long pmd_page(pmd_t pmd)
+static inline unsigned long pmd_page(pmd_t pmd)
 { return pmd_val(pmd) & PAGE_MASK; }
 
-extern inline void pmd_set(pmd_t * pmdp, pte_t * ptep)
+static inline void pmd_set(pmd_t * pmdp, pte_t * ptep)
 { pmd_val(*pmdp) = _PAGE_TABLE | (unsigned long) ptep; }
 
 /* to find an entry in a page-table-directory. */
 #define pgd_index(address) ((address >> PGDIR_SHIFT) & (PTRS_PER_PGD-1))
 
 /* to find an entry in a page-table-directory */
-extern inline pgd_t * pgd_offset(struct mm_struct * mm, unsigned long address)
+static inline pgd_t * pgd_offset(struct mm_struct * mm, unsigned long address)
 {
 	return mm->pgd + pgd_index(address);
 }
@@ -477,13 +477,13 @@
 #define pgd_offset_k(address) pgd_offset(&init_mm, address)
 
 /* Find an entry in the second-level page table.. */
-extern inline pmd_t * pmd_offset(pgd_t * dir, unsigned long address)
+static inline pmd_t * pmd_offset(pgd_t * dir, unsigned long address)
 {
 	return (pmd_t *) dir;
 }
 
 /* Find an entry in the third-level page table.. */ 
-extern inline pte_t * pte_offset(pmd_t * dir, unsigned long address)
+static inline pte_t * pte_offset(pmd_t * dir, unsigned long address)
 {
 	return (pte_t *) pmd_page(*dir) + ((address >> PAGE_SHIFT) & (PTRS_PER_PTE - 1));
 }
@@ -503,7 +503,7 @@
  * 
  * Actually I am not sure on what this could be used for.
  */
-extern inline void update_mmu_cache(struct vm_area_struct * vma,
+static inline void update_mmu_cache(struct vm_area_struct * vma,
 	unsigned long address, pte_t pte)
 {
 }
diff -rbNu linux-2.4.25-kdb/include/asm-cris/processor.h linux-2.4.25-kdb-trace/include/asm-cris/processor.h
--- linux-2.4.25-kdb/include/asm-cris/processor.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/processor.h	2005-01-05 16:45:40.000000000 +0100
@@ -116,13 +116,13 @@
  * Free current thread data structures etc..
  */
 
-extern inline void exit_thread(void)
+static inline void exit_thread(void)
 {
         /* Nothing needs to be done.  */
 }
 
 /* Free all resources held by a thread. */
-extern inline void release_thread(struct task_struct *dead_task)
+static inline void release_thread(struct task_struct *dead_task)
 {
         /* Nothing needs to be done.  */
 }
@@ -130,7 +130,7 @@
 /*
  * Return saved PC of a blocked thread.
  */
-extern inline unsigned long thread_saved_pc(struct thread_struct *t)
+static inline unsigned long thread_saved_pc(struct thread_struct *t)
 {
 	return (unsigned long)user_regs(t)->irp;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-cris/semaphore-helper.h linux-2.4.25-kdb-trace/include/asm-cris/semaphore-helper.h
--- linux-2.4.25-kdb/include/asm-cris/semaphore-helper.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/semaphore-helper.h	2005-01-05 16:45:40.000000000 +0100
@@ -18,12 +18,12 @@
 /*
  * These two _must_ execute atomically wrt each other.
  */
-extern inline void wake_one_more(struct semaphore * sem)
+static inline void wake_one_more(struct semaphore * sem)
 {
 	atomic_inc(&sem->waking);
 }
 
-extern inline int waking_non_zero(struct semaphore *sem)
+static inline int waking_non_zero(struct semaphore *sem)
 {
 	unsigned long flags;
 	int ret = 0;
@@ -37,7 +37,7 @@
 	return ret;
 }
 
-extern inline int waking_non_zero_interruptible(struct semaphore *sem,
+static inline int waking_non_zero_interruptible(struct semaphore *sem,
 						struct task_struct *tsk)
 {
 	int ret = 0;
@@ -55,7 +55,7 @@
 	return ret;
 }
 
-extern inline int waking_non_zero_trylock(struct semaphore *sem)
+static inline int waking_non_zero_trylock(struct semaphore *sem)
 {
         int ret = 1;
 	unsigned long flags;
diff -rbNu linux-2.4.25-kdb/include/asm-cris/semaphore.h linux-2.4.25-kdb-trace/include/asm-cris/semaphore.h
--- linux-2.4.25-kdb/include/asm-cris/semaphore.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/semaphore.h	2005-01-05 16:45:40.000000000 +0100
@@ -47,17 +47,17 @@
 #define DECLARE_MUTEX(name) __DECLARE_SEMAPHORE_GENERIC(name,1)
 #define DECLARE_MUTEX_LOCKED(name) __DECLARE_SEMAPHORE_GENERIC(name,0)
 
-extern inline void sema_init(struct semaphore *sem, int val)
+static inline void sema_init(struct semaphore *sem, int val)
 {
 	*sem = (struct semaphore)__SEMAPHORE_INITIALIZER((*sem),val);
 }
 
-extern inline void init_MUTEX (struct semaphore *sem)
+static inline void init_MUTEX (struct semaphore *sem)
 {
         sema_init(sem, 1);
 }
 
-extern inline void init_MUTEX_LOCKED (struct semaphore *sem)
+static inline void init_MUTEX_LOCKED (struct semaphore *sem)
 {
         sema_init(sem, 0);
 }
@@ -69,7 +69,7 @@
 
 /* notice - we probably can do cli/sti here instead of saving */
 
-extern inline void down(struct semaphore * sem)
+static inline void down(struct semaphore * sem)
 {
 	unsigned long flags;
 	int failed;
@@ -94,7 +94,7 @@
  * returns negative for signalled and zero for semaphore acquired.
  */
 
-extern inline int down_interruptible(struct semaphore * sem)
+static inline int down_interruptible(struct semaphore * sem)
 {
 	unsigned long flags;
 	int failed;
@@ -113,7 +113,7 @@
 	return(failed);
 }
 
-extern inline int down_trylock(struct semaphore * sem)
+static inline int down_trylock(struct semaphore * sem)
 {
 	unsigned long flags;
 	int failed;
@@ -137,7 +137,7 @@
  * The default case (no contention) will result in NO
  * jumps for both down() and up().
  */
-extern inline void up(struct semaphore * sem)
+static inline void up(struct semaphore * sem)
 {
 	unsigned long flags;
 	int wakeup;
diff -rbNu linux-2.4.25-kdb/include/asm-cris/siginfo.h linux-2.4.25-kdb-trace/include/asm-cris/siginfo.h
--- linux-2.4.25-kdb/include/asm-cris/siginfo.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/siginfo.h	2005-01-05 16:45:41.000000000 +0100
@@ -217,7 +217,7 @@
 #ifdef __KERNEL__
 #include <linux/string.h>
 
-extern inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
+static inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
 {
 	if (from->si_code < 0)
 		memcpy(to, from, sizeof(siginfo_t));
diff -rbNu linux-2.4.25-kdb/include/asm-cris/smp_lock.h linux-2.4.25-kdb-trace/include/asm-cris/smp_lock.h
--- linux-2.4.25-kdb/include/asm-cris/smp_lock.h	2001-02-09 01:32:44.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-cris/smp_lock.h	2005-01-05 16:45:41.000000000 +0100
@@ -11,7 +11,7 @@
  *	Locking the kernel 
  */
  
-extern __inline void lock_kernel(void)
+static __inline void lock_kernel(void)
 {
 	unsigned long flags;
 	int proc = smp_processor_id();
@@ -49,7 +49,7 @@
 	restore_flags(flags);
 }
 
-extern __inline void unlock_kernel(void)
+static __inline void unlock_kernel(void)
 {
 	unsigned long flags;
 	save_flags(flags);
diff -rbNu linux-2.4.25-kdb/include/asm-cris/system.h linux-2.4.25-kdb-trace/include/asm-cris/system.h
--- linux-2.4.25-kdb/include/asm-cris/system.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/system.h	2005-01-05 16:45:40.000000000 +0100
@@ -16,7 +16,7 @@
 
 /* read the CPU PC register */
 
-extern inline unsigned long rdpc(void)
+static inline unsigned long rdpc(void)
 { 
 	unsigned long pc;
 	__asm__ volatile ("move.d $pc,%0" : "=rm" (pc));
@@ -25,7 +25,7 @@
 
 /* read the CPU version register */
 
-extern inline unsigned long rdvr(void) { 
+static inline unsigned long rdvr(void) { 
 	unsigned char vr;
 	__asm__ volatile ("move $vr,%0" : "=rm" (vr));
 	return vr;
@@ -33,7 +33,7 @@
 
 /* read/write the user-mode stackpointer */
 
-extern inline unsigned long rdusp(void) {
+static inline unsigned long rdusp(void) {
 	unsigned long usp;
 	__asm__ __volatile__("move $usp,%0" : "=rm" (usp));
 	return usp;
@@ -44,13 +44,13 @@
 
 /* read the current stackpointer */
 
-extern inline unsigned long rdsp(void) {
+static inline unsigned long rdsp(void) {
 	unsigned long sp;
 	__asm__ __volatile__("move.d $sp,%0" : "=rm" (sp));
 	return sp;
 }
 
-extern inline unsigned long _get_base(char * addr)
+static inline unsigned long _get_base(char * addr)
 {
   return 0;
 }
@@ -91,7 +91,7 @@
 
 #define __save_flags(x) __asm__ __volatile__ ("move $ccr,%0" : "=rm" (x) : : "memory");
 
-extern inline void __cli(void)
+static inline void __cli(void)
 {
   unsigned long pc = rdpc();  
   unsigned long curr_ccr; __save_flags(curr_ccr); 
@@ -100,7 +100,7 @@
 }
 
 
-extern inline void __sti(void)
+static inline void __sti(void)
 {
   unsigned long pc = rdpc();  
   unsigned long curr_ccr; __save_flags(curr_ccr); 
@@ -108,7 +108,7 @@
   __asm__ __volatile__ ( "ei" : : :"memory");
 }
 
-extern inline void __restore_flags(unsigned long x)
+static inline void __restore_flags(unsigned long x)
 {
   unsigned long pc = rdpc();
   unsigned long curr_ccr; __save_flags(curr_ccr);
@@ -148,7 +148,7 @@
 #define save_and_cli(x) do { save_flags(x); cli(); } while(0)
 #define save_and_sti(x) do { save_flags(x); sti(); } while(0)
 
-extern inline unsigned long __xchg(unsigned long x, void * ptr, int size)
+static inline unsigned long __xchg(unsigned long x, void * ptr, int size)
 {
   /* since Etrax doesn't have any atomic xchg instructions, we need to disable
      irq's (if enabled) and do it with move.d's */
diff -rbNu linux-2.4.25-kdb/include/asm-cris/timex.h linux-2.4.25-kdb-trace/include/asm-cris/timex.h
--- linux-2.4.25-kdb/include/asm-cris/timex.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/timex.h	2005-01-05 16:45:40.000000000 +0100
@@ -28,7 +28,7 @@
 
 unsigned long timer_data_to_ns(unsigned long timer_data);
 
-extern inline unsigned long get_us_in_jiffie_highres(void)
+static inline unsigned long get_us_in_jiffie_highres(void)
 {
 	return get_ns_in_jiffie()/1000;
 }
@@ -39,7 +39,7 @@
 
 typedef unsigned int cycles_t;
 
-extern inline cycles_t get_cycles(void)
+static inline cycles_t get_cycles(void)
 {
         return 0;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-cris/uaccess.h linux-2.4.25-kdb-trace/include/asm-cris/uaccess.h
--- linux-2.4.25-kdb/include/asm-cris/uaccess.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/uaccess.h	2005-01-05 16:45:40.000000000 +0100
@@ -103,7 +103,7 @@
 #define __access_ok(addr,size) (__kernel_ok || __user_ok((addr),(size)))
 #define access_ok(type,addr,size) __access_ok((unsigned long)(addr),(size))
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
 	return access_ok(type,addr,size) ? 0 : -EFAULT;
 }
@@ -314,7 +314,7 @@
  * (without the null byte)
  */
 
-extern inline long         
+static inline long         
 __do_strncpy_from_user(char *dst, const char *src, long count)
 {
 	long res;
@@ -374,7 +374,7 @@
 	return res;
 }
 
-extern inline unsigned long
+static inline unsigned long
 __generic_copy_to_user(void *to, const void *from, unsigned long n)
 {
 	if (access_ok(VERIFY_WRITE, to, n))
@@ -382,7 +382,7 @@
 	return n;
 }
 
-extern inline unsigned long
+static inline unsigned long
 __generic_copy_from_user(void *to, const void *from, unsigned long n)
 {
 	if (access_ok(VERIFY_READ, from, n))
@@ -390,7 +390,7 @@
 	return n;
 }
 
-extern inline unsigned long
+static inline unsigned long
 __generic_clear_user(void *to, unsigned long n)
 {
 	if (access_ok(VERIFY_WRITE, to, n))
@@ -398,13 +398,13 @@
 	return n;
 }
 
-extern inline long
+static inline long
 __strncpy_from_user(char *dst, const char *src, long count)
 {
 	return __do_strncpy_from_user(dst, src, count);
 }
 
-extern inline long
+static inline long
 strncpy_from_user(char *dst, const char *src, long count)
 {
 	long res = -EFAULT;
@@ -864,7 +864,7 @@
 /* Note that if these expand awfully if made into switch constructs, so
    don't do that.  */
 
-extern inline unsigned long
+static inline unsigned long
 __constant_copy_from_user(void *to, const void *from, unsigned long n)
 {
 	unsigned long ret = 0;
@@ -914,7 +914,7 @@
 
 /* Ditto, don't make a switch out of this.  */
 
-extern inline unsigned long
+static inline unsigned long
 __constant_copy_to_user(void *to, const void *from, unsigned long n)
 {
 	unsigned long ret = 0;
@@ -964,7 +964,7 @@
 
 /* No switch, please.  */
 
-extern inline unsigned long
+static inline unsigned long
 __constant_clear_user(void *to, unsigned long n)
 {
 	unsigned long ret = 0;
@@ -1014,19 +1014,19 @@
  * used in fast paths and have only a small space overhead.
  */
 
-extern inline unsigned long
+static inline unsigned long
 __generic_copy_from_user_nocheck(void *to, const void *from, unsigned long n)
 {
 	return __copy_user_zeroing(to,from,n);
 }
 
-extern inline unsigned long
+static inline unsigned long
 __generic_copy_to_user_nocheck(void *to, const void *from, unsigned long n)
 {
 	return __copy_user(to,from,n);
 }
 
-extern inline unsigned long
+static inline unsigned long
 __generic_clear_user_nocheck(void *to, unsigned long n)
 {
 	return __do_clear_user(to,n);
@@ -1045,7 +1045,7 @@
  * or 0 for error.  Return a value greater than N if too long.
  */
 
-extern inline long
+static inline long
 strnlen_user(const char *s, long n)
 {
 	long res, tmp1;
diff -rbNu linux-2.4.25-kdb/include/asm-cris/unistd.h linux-2.4.25-kdb-trace/include/asm-cris/unistd.h
--- linux-2.4.25-kdb/include/asm-cris/unistd.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-cris/unistd.h	2005-01-05 16:45:40.000000000 +0100
@@ -426,7 +426,6 @@
 extern inline _syscall0(pid_t,setsid)
 extern inline _syscall3(int,write,int,fd,const char *,buf,off_t,count)
 extern inline _syscall1(int,dup,int,fd)
-extern inline _syscall3(int,execve,const char *,file,char **,argv,char **,envp)
 extern inline _syscall3(int,open,const char *,file,int,flag,int,mode)
 extern inline _syscall1(int,close,int,fd)
 
@@ -436,7 +435,6 @@
  * complaints.  We don't want to use -fno-builtin, so just use a
  * different name when in the kernel.
  */
-#ifdef __KERNEL__
 #define _exit kernel_syscall_exit
 #endif
 extern inline _syscall1(int,_exit,int,exitcode)
@@ -448,9 +446,8 @@
 extern inline _syscall3(int,read,int,fd,char *,buf,off_t,count)
 extern inline _syscall2(int,socketcall,int,call,unsigned long *,args)
 extern inline _syscall3(int,ioctl,unsigned int,fd,unsigned int,cmd,unsigned long,arg)
-extern inline _syscall5(int,mount,const char *,a,const char *,b,const char *,c,unsigned long,rwflag,const void *,data)
 
-extern inline pid_t wait(int * wait_stat)
+static inline pid_t wait(int * wait_stat)
 {
 	return waitpid(-1,wait_stat,0);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-generic/bitops.h linux-2.4.25-kdb-trace/include/asm-generic/bitops.h
--- linux-2.4.25-kdb/include/asm-generic/bitops.h	2000-11-28 02:47:38.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-generic/bitops.h	2005-01-05 16:45:35.000000000 +0100
@@ -16,7 +16,7 @@
  * C language equivalents written by Theodore Ts'o, 9/26/92
  */
 
-extern __inline__ int set_bit(int nr,long * addr)
+static __inline__ int set_bit(int nr,long * addr)
 {
 	int	mask, retval;
 
@@ -29,7 +29,7 @@
 	return retval;
 }
 
-extern __inline__ int clear_bit(int nr, long * addr)
+static __inline__ int clear_bit(int nr, long * addr)
 {
 	int	mask, retval;
 
@@ -42,7 +42,7 @@
 	return retval;
 }
 
-extern __inline__ int test_bit(int nr, long * addr)
+static __inline__ int test_bit(int nr, long * addr)
 {
 	int	mask;
 
diff -rbNu linux-2.4.25-kdb/include/asm-generic/smplock.h linux-2.4.25-kdb-trace/include/asm-generic/smplock.h
--- linux-2.4.25-kdb/include/asm-generic/smplock.h	2000-03-23 21:50:09.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-generic/smplock.h	2005-01-05 16:45:35.000000000 +0100
@@ -38,13 +38,13 @@
  * so we only need to worry about other
  * CPU's.
  */
-extern __inline__ void lock_kernel(void)
+static __inline__ void lock_kernel(void)
 {
 	if (!++current->lock_depth)
 		spin_lock(&kernel_flag);
 }
 
-extern __inline__ void unlock_kernel(void)
+static __inline__ void unlock_kernel(void)
 {
 	if (--current->lock_depth < 0)
 		spin_unlock(&kernel_flag);
diff -rbNu linux-2.4.25-kdb/include/asm-i386/apic.h linux-2.4.25-kdb-trace/include/asm-i386/apic.h
--- linux-2.4.25-kdb/include/asm-i386/apic.h	2005-01-05 13:49:57.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-i386/apic.h	2005-01-05 16:54:56.000000000 +0100
@@ -77,7 +77,7 @@
 extern void smp_local_timer_interrupt (struct pt_regs * regs);
 extern void setup_APIC_clocks (void);
 extern void setup_apic_nmi_watchdog (void);
-extern inline void nmi_watchdog_tick (struct pt_regs * regs);
+extern void nmi_watchdog_tick (struct pt_regs * regs);
 extern int APIC_init_uniprocessor (void);
 extern void disable_APIC_timer(void);
 extern void enable_APIC_timer(void);
diff -rbNu linux-2.4.25-kdb/include/asm-i386/current.h linux-2.4.25-kdb-trace/include/asm-i386/current.h
--- linux-2.4.25-kdb/include/asm-i386/current.h	1998-08-15 01:35:22.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-i386/current.h	2005-01-05 16:09:40.000000000 +0100
@@ -4,6 +4,8 @@
 struct task_struct;
 
 static inline struct task_struct * get_current(void)
+ __attribute__ ((no_instrument_function));
+static inline struct task_struct * get_current(void)
 {
 	struct task_struct *current;
 	__asm__("andl %%esp,%0; ":"=r" (current) : "0" (~8191UL));
diff -rbNu linux-2.4.25-kdb/include/asm-i386/processor.h linux-2.4.25-kdb-trace/include/asm-i386/processor.h
--- linux-2.4.25-kdb/include/asm-i386/processor.h	2005-01-05 13:49:57.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-i386/processor.h	2005-01-05 16:54:55.000000000 +0100
@@ -502,7 +502,7 @@
 #if defined(CONFIG_MPENTIUMIII) || defined (CONFIG_MPENTIUM4)
 
 #define ARCH_HAS_PREFETCH
-extern inline void prefetch(const void *x)
+static inline void prefetch(const void *x)
 {
 	__asm__ __volatile__ ("prefetchnta (%0)" : : "r"(x));
 }
@@ -513,12 +513,12 @@
 #define ARCH_HAS_PREFETCHW
 #define ARCH_HAS_SPINLOCK_PREFETCH
 
-extern inline void prefetch(const void *x)
+static inline void prefetch(const void *x)
 {
 	 __asm__ __volatile__ ("prefetch (%0)" : : "r"(x));
 }
 
-extern inline void prefetchw(const void *x)
+static inline void prefetchw(const void *x)
 {
 	 __asm__ __volatile__ ("prefetchw (%0)" : : "r"(x));
 }
diff -rbNu linux-2.4.25-kdb/include/asm-ia64/processor.h linux-2.4.25-kdb-trace/include/asm-ia64/processor.h
--- linux-2.4.25-kdb/include/asm-ia64/processor.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ia64/processor.h	2005-01-05 16:45:39.000000000 +0100
@@ -979,13 +979,13 @@
 #define ARCH_HAS_SPINLOCK_PREFETCH
 #define PREFETCH_STRIDE 256
 
-extern inline void
+static inline void
 prefetch (const void *x)
 {
          __asm__ __volatile__ ("lfetch [%0]" : : "r"(x));
 }
 
-extern inline void
+static inline void
 prefetchw (const void *x)
 {
 	__asm__ __volatile__ ("lfetch.excl [%0]" : : "r"(x));
diff -rbNu linux-2.4.25-kdb/include/asm-ia64/sn/rw_mmr.h linux-2.4.25-kdb-trace/include/asm-ia64/sn/rw_mmr.h
--- linux-2.4.25-kdb/include/asm-ia64/sn/rw_mmr.h	2003-08-25 13:44:43.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ia64/sn/rw_mmr.h	2005-01-05 16:45:39.000000000 +0100
@@ -22,7 +22,7 @@
  */
 
 
-extern inline long
+static inline long
 pio_phys_read_mmr(volatile long *mmr) 
 {
 	long val;
@@ -41,7 +41,7 @@
 
 
 
-extern inline void
+static inline void
 pio_phys_write_mmr(volatile long *mmr, long val) 
 {
         asm volatile
@@ -55,7 +55,7 @@
              : "r2", "memory");
 }            
 
-extern inline void
+static inline void
 pio_atomic_phys_write_mmrs(volatile long *mmr1, long val1, volatile long *mmr2, long val2) 
 {
         asm volatile
diff -rbNu linux-2.4.25-kdb/include/asm-ia64/vga.h linux-2.4.25-kdb-trace/include/asm-ia64/vga.h
--- linux-2.4.25-kdb/include/asm-ia64/vga.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ia64/vga.h	2005-01-05 16:45:39.000000000 +0100
@@ -22,14 +22,14 @@
 #define vga_readb	__raw_readb
 #define vga_writeb	__raw_writeb
 
-extern inline void
+static inline void
 scr_writew (u16 val, volatile u16 *addr)
 {
 	/* Note: ADDR may point to normal memory.  That's OK on ia64.  */
 	__raw_writew(val, (unsigned long) addr);
 }
 
-extern inline u16
+static inline u16
 scr_readw (volatile const u16 *addr)
 {
 	/* Note: ADDR may point to normal memory.  That's OK on ia64.  */
diff -rbNu linux-2.4.25-kdb/include/asm-m68k/pgalloc.h linux-2.4.25-kdb-trace/include/asm-m68k/pgalloc.h
--- linux-2.4.25-kdb/include/asm-m68k/pgalloc.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-m68k/pgalloc.h	2005-01-05 16:45:36.000000000 +0100
@@ -130,7 +130,7 @@
 
 /* Push n pages at kernel virtual address and clear the icache */
 /* RZ: use cpush %bc instead of cpush %dc, cinv %ic */
-extern inline void flush_icache_range (unsigned long address,
+static inline void flush_icache_range (unsigned long address,
 				       unsigned long endaddr)
 {
 	if (CPU_IS_040_OR_060) {
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/bitops.h linux-2.4.25-kdb-trace/include/asm-parisc/bitops.h
--- linux-2.4.25-kdb/include/asm-parisc/bitops.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-parisc/bitops.h	2005-01-05 16:45:40.000000000 +0100
@@ -193,7 +193,7 @@
 	return !!(*addr & mask);
 }
 
-extern __inline__ unsigned long ffz(unsigned long word)
+static __inline__ unsigned long ffz(unsigned long word)
 {
 	unsigned long result;
 
@@ -301,7 +301,7 @@
 #define ext2_find_first_zero_bit(addr, size) \
         ext2_find_next_zero_bit((addr), (size), 0)
 
-extern __inline__ unsigned long ext2_find_next_zero_bit(void *addr,
+static __inline__ unsigned long ext2_find_next_zero_bit(void *addr,
 	unsigned long size, unsigned long offset)
 {
 	unsigned int *p = ((unsigned int *) addr) + (offset >> 5);
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/checksum.h linux-2.4.25-kdb-trace/include/asm-parisc/checksum.h
--- linux-2.4.25-kdb/include/asm-parisc/checksum.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-parisc/checksum.h	2005-01-05 16:45:40.000000000 +0100
@@ -44,7 +44,7 @@
  *	If you use these functions directly please don't forget the 
  *	verify_area().
  */
-extern __inline__
+static __inline__
 unsigned int csum_partial_copy_nocheck (const char *src, char *dst,
 					int len, int sum)
 {
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/io.h linux-2.4.25-kdb-trace/include/asm-parisc/io.h
--- linux-2.4.25-kdb/include/asm-parisc/io.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-parisc/io.h	2005-01-05 16:45:40.000000000 +0100
@@ -22,7 +22,7 @@
 
 extern void * __ioremap(unsigned long offset, unsigned long size, unsigned long flags);
 
-extern inline void * ioremap(unsigned long offset, unsigned long size)
+static inline void * ioremap(unsigned long offset, unsigned long size)
 {
 	return __ioremap(offset, size, 0);
 }
@@ -32,7 +32,7 @@
  * it's useful if some control registers are in such an area and write combining
  * or read caching is not desirable:
  */
-extern inline void * ioremap_nocache (unsigned long offset, unsigned long size)
+static inline void * ioremap_nocache (unsigned long offset, unsigned long size)
 {
         return __ioremap(offset, size, _PAGE_NO_CACHE /* _PAGE_PCD */);
 }
@@ -44,7 +44,7 @@
  * too lazy to ioremap first'.  kind of like isa_, except that there's
  * no additional base address to add on.
  */
-extern __inline__ unsigned char __raw_readb(unsigned long addr)
+static __inline__ unsigned char __raw_readb(unsigned long addr)
 {
 	long flags;
 	unsigned char ret;
@@ -58,7 +58,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned short __raw_readw(unsigned long addr)
+static __inline__ unsigned short __raw_readw(unsigned long addr)
 {
 	long flags;
 	unsigned short ret;
@@ -72,7 +72,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned int __raw_readl(unsigned long addr)
+static __inline__ unsigned int __raw_readl(unsigned long addr)
 {
 	u32 ret;
 
@@ -83,7 +83,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned long long __raw_readq(unsigned long addr)
+static __inline__ unsigned long long __raw_readq(unsigned long addr)
 {
 	unsigned long long ret;
 #ifdef __LP64__
@@ -98,7 +98,7 @@
 	return ret;
 }
 
-extern __inline__ void __raw_writeb(unsigned char val, unsigned long addr)
+static __inline__ void __raw_writeb(unsigned char val, unsigned long addr)
 {
 	long flags;
 	__asm__ __volatile__(
@@ -108,7 +108,7 @@
 	: "=&r" (flags) :  "r" (val), "r" (addr) );
 }
 
-extern __inline__ void __raw_writew(unsigned short val, unsigned long addr)
+static __inline__ void __raw_writew(unsigned short val, unsigned long addr)
 {
 	long flags;
 	__asm__ __volatile__(
@@ -118,14 +118,14 @@
 	: "=&r" (flags) :  "r" (val), "r" (addr) );
 }
 
-extern __inline__ void __raw_writel(unsigned int val, unsigned long addr)
+static __inline__ void __raw_writel(unsigned int val, unsigned long addr)
 {
 	__asm__ __volatile__(
 	"	stwa,ma	%0,0(%1)\n"
 	: :  "r" (val), "r" (addr) );
 }
 
-extern __inline__ void __raw_writeq(unsigned long long val, unsigned long addr)
+static __inline__ void __raw_writeq(unsigned long long val, unsigned long addr)
 {
 #ifdef __LP64__
 	__asm__ __volatile__(
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/page.h linux-2.4.25-kdb-trace/include/asm-parisc/page.h
--- linux-2.4.25-kdb/include/asm-parisc/page.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-parisc/page.h	2005-01-05 16:45:40.000000000 +0100
@@ -51,7 +51,7 @@
 #define __pgprot(x)	((pgprot_t) { (x) } )
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
 	int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/parport_gsc.h linux-2.4.25-kdb-trace/include/asm-parisc/parport_gsc.h
--- linux-2.4.25-kdb/include/asm-parisc/parport_gsc.h	2000-12-05 21:29:39.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-parisc/parport_gsc.h	2005-01-05 16:45:40.000000000 +0100
@@ -52,7 +52,7 @@
 	struct pci_dev *dev;
 };
 
-extern __inline__ void parport_gsc_write_data(struct parport *p, unsigned char d)
+static __inline__ void parport_gsc_write_data(struct parport *p, unsigned char d)
 {
 #ifdef DEBUG_PARPORT
 	printk (KERN_DEBUG "parport_gsc_write_data(%p,0x%02x)\n", p, d);
@@ -60,7 +60,7 @@
 	parport_writeb(d, DATA(p));
 }
 
-extern __inline__ unsigned char parport_gsc_read_data(struct parport *p)
+static __inline__ unsigned char parport_gsc_read_data(struct parport *p)
 {
 	unsigned char val = parport_readb (DATA (p));
 #ifdef DEBUG_PARPORT
@@ -90,17 +90,17 @@
 	return ctr;
 }
 
-extern __inline__ void parport_gsc_data_reverse (struct parport *p)
+static __inline__ void parport_gsc_data_reverse (struct parport *p)
 {
 	__parport_gsc_frob_control (p, 0x20, 0x20);
 }
 
-extern __inline__ void parport_gsc_data_forward (struct parport *p)
+static __inline__ void parport_gsc_data_forward (struct parport *p)
 {
 	__parport_gsc_frob_control (p, 0x20, 0x00);
 }
 
-extern __inline__ void parport_gsc_write_control (struct parport *p,
+static __inline__ void parport_gsc_write_control (struct parport *p,
 						 unsigned char d)
 {
 	const unsigned char wm = (PARPORT_CONTROL_STROBE |
@@ -118,7 +118,7 @@
 	__parport_gsc_frob_control (p, wm, d & wm);
 }
 
-extern __inline__ unsigned char parport_gsc_read_control(struct parport *p)
+static __inline__ unsigned char parport_gsc_read_control(struct parport *p)
 {
 	const unsigned char rm = (PARPORT_CONTROL_STROBE |
 				  PARPORT_CONTROL_AUTOFD |
@@ -128,7 +128,7 @@
 	return priv->ctr & rm; /* Use soft copy */
 }
 
-extern __inline__ unsigned char parport_gsc_frob_control (struct parport *p,
+static __inline__ unsigned char parport_gsc_frob_control (struct parport *p,
 							 unsigned char mask,
 							 unsigned char val)
 {
@@ -155,18 +155,18 @@
 	return __parport_gsc_frob_control (p, mask, val);
 }
 
-extern __inline__ unsigned char parport_gsc_read_status(struct parport *p)
+static __inline__ unsigned char parport_gsc_read_status(struct parport *p)
 {
 	return parport_readb (STATUS(p));
 }
 
 
-extern __inline__ void parport_gsc_disable_irq(struct parport *p)
+static __inline__ void parport_gsc_disable_irq(struct parport *p)
 {
 	__parport_gsc_frob_control (p, 0x10, 0x00);
 }
 
-extern __inline__ void parport_gsc_enable_irq(struct parport *p)
+static __inline__ void parport_gsc_enable_irq(struct parport *p)
 {
 	__parport_gsc_frob_control (p, 0x10, 0x10);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/pci.h linux-2.4.25-kdb-trace/include/asm-parisc/pci.h
--- linux-2.4.25-kdb/include/asm-parisc/pci.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-parisc/pci.h	2005-01-05 16:45:40.000000000 +0100
@@ -244,7 +244,7 @@
 extern void pcibios_set_master(struct pci_dev *);
 extern void pcibios_assign_unassigned_resources(struct pci_bus *);
 #else
-extern inline void pcibios_register_hba(struct pci_hba_data *x)
+static inline void pcibios_register_hba(struct pci_hba_data *x)
 {
 }
 #endif
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/pgalloc.h linux-2.4.25-kdb-trace/include/asm-parisc/pgalloc.h
--- linux-2.4.25-kdb/include/asm-parisc/pgalloc.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-parisc/pgalloc.h	2005-01-05 16:45:40.000000000 +0100
@@ -176,7 +176,7 @@
 #endif
 }
 
-extern __inline__ void flush_tlb_pgtables(struct mm_struct *mm, unsigned long start, unsigned long end)
+static __inline__ void flush_tlb_pgtables(struct mm_struct *mm, unsigned long start, unsigned long end)
 {
 }
  
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/pgtable.h linux-2.4.25-kdb-trace/include/asm-parisc/pgtable.h
--- linux-2.4.25-kdb/include/asm-parisc/pgtable.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-parisc/pgtable.h	2005-01-05 16:45:40.000000000 +0100
@@ -244,29 +244,29 @@
  * setup: the pgd is never bad, and a pmd always exists (as it's folded
  * into the pgd entry)
  */
-extern inline int pgd_none(pgd_t pgd)		{ return 0; }
-extern inline int pgd_bad(pgd_t pgd)		{ return 0; }
-extern inline int pgd_present(pgd_t pgd)	{ return 1; }
-extern inline void pgd_clear(pgd_t * pgdp)	{ }
+static inline int pgd_none(pgd_t pgd)		{ return 0; }
+static inline int pgd_bad(pgd_t pgd)		{ return 0; }
+static inline int pgd_present(pgd_t pgd)	{ return 1; }
+static inline void pgd_clear(pgd_t * pgdp)	{ }
 #endif
 
 /*
  * The following only work if pte_present() is true.
  * Undefined behaviour if not..
  */
-extern inline int pte_read(pte_t pte)		{ return pte_val(pte) & _PAGE_READ; }
-extern inline int pte_dirty(pte_t pte)		{ return pte_val(pte) & _PAGE_DIRTY; }
-extern inline int pte_young(pte_t pte)		{ return pte_val(pte) & _PAGE_ACCESSED; }
-extern inline int pte_write(pte_t pte)		{ return pte_val(pte) & _PAGE_WRITE; }
-
-extern inline pte_t pte_rdprotect(pte_t pte)	{ pte_val(pte) &= ~_PAGE_READ; return pte; }
-extern inline pte_t pte_mkclean(pte_t pte)	{ pte_val(pte) &= ~_PAGE_DIRTY; return pte; }
-extern inline pte_t pte_mkold(pte_t pte)	{ pte_val(pte) &= ~_PAGE_ACCESSED; return pte; }
-extern inline pte_t pte_wrprotect(pte_t pte)	{ pte_val(pte) &= ~_PAGE_WRITE; return pte; }
-extern inline pte_t pte_mkread(pte_t pte)	{ pte_val(pte) |= _PAGE_READ; return pte; }
-extern inline pte_t pte_mkdirty(pte_t pte)	{ pte_val(pte) |= _PAGE_DIRTY; return pte; }
-extern inline pte_t pte_mkyoung(pte_t pte)	{ pte_val(pte) |= _PAGE_ACCESSED; return pte; }
-extern inline pte_t pte_mkwrite(pte_t pte)	{ pte_val(pte) |= _PAGE_WRITE; return pte; }
+static inline int pte_read(pte_t pte)		{ return pte_val(pte) & _PAGE_READ; }
+static inline int pte_dirty(pte_t pte)		{ return pte_val(pte) & _PAGE_DIRTY; }
+static inline int pte_young(pte_t pte)		{ return pte_val(pte) & _PAGE_ACCESSED; }
+static inline int pte_write(pte_t pte)		{ return pte_val(pte) & _PAGE_WRITE; }
+
+static inline pte_t pte_rdprotect(pte_t pte)	{ pte_val(pte) &= ~_PAGE_READ; return pte; }
+static inline pte_t pte_mkclean(pte_t pte)	{ pte_val(pte) &= ~_PAGE_DIRTY; return pte; }
+static inline pte_t pte_mkold(pte_t pte)	{ pte_val(pte) &= ~_PAGE_ACCESSED; return pte; }
+static inline pte_t pte_wrprotect(pte_t pte)	{ pte_val(pte) &= ~_PAGE_WRITE; return pte; }
+static inline pte_t pte_mkread(pte_t pte)	{ pte_val(pte) |= _PAGE_READ; return pte; }
+static inline pte_t pte_mkdirty(pte_t pte)	{ pte_val(pte) |= _PAGE_DIRTY; return pte; }
+static inline pte_t pte_mkyoung(pte_t pte)	{ pte_val(pte) |= _PAGE_ACCESSED; return pte; }
+static inline pte_t pte_mkwrite(pte_t pte)	{ pte_val(pte) |= _PAGE_WRITE; return pte; }
 
 /*
  * Conversion functions: convert a page and protection to a page entry,
@@ -308,7 +308,7 @@
 #define mk_pte_phys(physpage, pgprot) \
 ({ pte_t __pte; pte_val(__pte) = physpage + pgprot_val(pgprot); __pte; })
 
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 { pte_val(pte) = (pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot); return pte; }
 
 /* Permanent address of a page.  On parisc we don't have highmem. */
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/processor.h linux-2.4.25-kdb-trace/include/asm-parisc/processor.h
--- linux-2.4.25-kdb/include/asm-parisc/processor.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-parisc/processor.h	2005-01-05 16:45:40.000000000 +0100
@@ -314,13 +314,13 @@
 
 #ifdef  CONFIG_PA20
 #define ARCH_HAS_PREFETCH
-extern inline void prefetch(const void *addr)
+static inline void prefetch(const void *addr)
 {
 	__asm__("ldw 0(%0), %%r0" : : "r" (addr));
 }
 
 #define ARCH_HAS_PREFETCHW
-extern inline void prefetchw(const void *addr)
+static inline void prefetchw(const void *addr)
 {
 	__asm__("ldd 0(%0), %%r0" : : "r" (addr));
 }
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/semaphore.h linux-2.4.25-kdb-trace/include/asm-parisc/semaphore.h
--- linux-2.4.25-kdb/include/asm-parisc/semaphore.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-parisc/semaphore.h	2005-01-05 16:45:40.000000000 +0100
@@ -51,7 +51,7 @@
 #define DECLARE_MUTEX(name) __DECLARE_SEMAPHORE_GENERIC(name,1)
 #define DECLARE_MUTEX_LOCKED(name) __DECLARE_SEMAPHORE_GENERIC(name,0)
 
-extern inline void sema_init (struct semaphore *sem, int val)
+static inline void sema_init (struct semaphore *sem, int val)
 {
 	*sem = (struct semaphore)__SEMAPHORE_INITIALIZER((*sem),val);
 }
@@ -79,7 +79,7 @@
  * interrupts while we're messing with the semaphore.  Sorry.
  */
 
-extern __inline__ void down(struct semaphore * sem)
+static __inline__ void down(struct semaphore * sem)
 {
 #if WAITQUEUE_DEBUG
 	CHECK_MAGIC(sem->__magic);
@@ -94,7 +94,7 @@
 	spin_unlock_irq(&sem->sentry);
 }
 
-extern __inline__ int down_interruptible(struct semaphore * sem)
+static __inline__ int down_interruptible(struct semaphore * sem)
 {
 	int ret = 0;
 #if WAITQUEUE_DEBUG
@@ -115,7 +115,7 @@
  * down_trylock returns 0 on success, 1 if we failed to get the lock.
  * May not sleep, but must preserve irq state
  */
-extern __inline__ int down_trylock(struct semaphore * sem)
+static __inline__ int down_trylock(struct semaphore * sem)
 {
 	int flags, count;
 #if WAITQUEUE_DEBUG
@@ -134,7 +134,7 @@
  * Note! This is subtle. We jump to wake people up only if
  * the semaphore was negative (== somebody was waiting on it).
  */
-extern __inline__ void up(struct semaphore * sem)
+static __inline__ void up(struct semaphore * sem)
 {
 	int flags;
 #if WAITQUEUE_DEBUG
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/siginfo.h linux-2.4.25-kdb-trace/include/asm-parisc/siginfo.h
--- linux-2.4.25-kdb/include/asm-parisc/siginfo.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-parisc/siginfo.h	2005-01-05 16:45:40.000000000 +0100
@@ -219,7 +219,7 @@
 #ifdef __KERNEL__
 #include <linux/string.h>
 
-extern inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
+static inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
 {
 	if (from->si_code < 0)
 		memcpy(to, from, sizeof(siginfo_t));
diff -rbNu linux-2.4.25-kdb/include/asm-parisc/smplock.h linux-2.4.25-kdb-trace/include/asm-parisc/smplock.h
--- linux-2.4.25-kdb/include/asm-parisc/smplock.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-parisc/smplock.h	2005-01-05 16:45:40.000000000 +0100
@@ -38,13 +38,13 @@
  * so we only need to worry about other
  * CPU's.
  */
-extern __inline__ void lock_kernel(void)
+static __inline__ void lock_kernel(void)
 {
 	if (!++current->lock_depth)
 		spin_lock(&kernel_flag);
 }
 
-extern __inline__ void unlock_kernel(void)
+static __inline__ void unlock_kernel(void)
 {
 	if (--current->lock_depth < 0)
 		spin_unlock(&kernel_flag);
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/byteorder.h linux-2.4.25-kdb-trace/include/asm-ppc/byteorder.h
--- linux-2.4.25-kdb/include/asm-ppc/byteorder.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/byteorder.h	2005-01-05 16:45:37.000000000 +0100
@@ -6,7 +6,7 @@
 #ifdef __GNUC__
 #ifdef __KERNEL__
 
-extern __inline__ unsigned ld_le16(const volatile unsigned short *addr)
+static __inline__ unsigned ld_le16(const volatile unsigned short *addr)
 {
 	unsigned val;
 
@@ -14,12 +14,12 @@
 	return val;
 }
 
-extern __inline__ void st_le16(volatile unsigned short *addr, const unsigned val)
+static __inline__ void st_le16(volatile unsigned short *addr, const unsigned val)
 {
 	__asm__ __volatile__ ("sthbrx %1,0,%2" : "=m" (*addr) : "r" (val), "r" (addr));
 }
 
-extern __inline__ unsigned ld_le32(const volatile unsigned *addr)
+static __inline__ unsigned ld_le32(const volatile unsigned *addr)
 {
 	unsigned val;
 
@@ -27,12 +27,12 @@
 	return val;
 }
 
-extern __inline__ void st_le32(volatile unsigned *addr, const unsigned val)
+static __inline__ void st_le32(volatile unsigned *addr, const unsigned val)
 {
 	__asm__ __volatile__ ("stwbrx %1,0,%2" : "=m" (*addr) : "r" (val), "r" (addr));
 }
 
-extern __inline__ unsigned long long ld_le64(const volatile unsigned long long *addr)
+static __inline__ unsigned long long ld_le64(const volatile unsigned long long *addr)
 {
 	unsigned char *taddr = (unsigned char *) addr;
 	unsigned long long val;
@@ -42,7 +42,7 @@
 	return val;
 }
 
-extern __inline__ void st_le64(volatile unsigned long long *addr, const unsigned long long val)
+static __inline__ void st_le64(volatile unsigned long long *addr, const unsigned long long val)
 {
 	unsigned char *taddr = (unsigned char *) addr;
 
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/delay.h linux-2.4.25-kdb-trace/include/asm-ppc/delay.h
--- linux-2.4.25-kdb/include/asm-ppc/delay.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/delay.h	2005-01-05 16:45:37.000000000 +0100
@@ -33,7 +33,7 @@
 #define __MAX_UDELAY	(226050910UL/HZ)	/* maximum udelay argument */
 #define __MAX_NDELAY	(4294967295UL/HZ)	/* maximum ndelay argument */
 
-extern __inline__ void __udelay(unsigned int x)
+static __inline__ void __udelay(unsigned int x)
 {
 	unsigned int loops;
 
@@ -42,7 +42,7 @@
 	__delay(loops);
 }
 
-extern __inline__ void __ndelay(unsigned int x)
+static __inline__ void __ndelay(unsigned int x)
 {
 	unsigned int loops;
 
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/io.h linux-2.4.25-kdb-trace/include/asm-ppc/io.h
--- linux-2.4.25-kdb/include/asm-ppc/io.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ppc/io.h	2005-01-05 16:45:37.000000000 +0100
@@ -97,7 +97,7 @@
  */
 
 #define __do_in_asm(name, op)				\
-extern __inline__ unsigned int name(unsigned int port)	\
+static __inline__ unsigned int name(unsigned int port)	\
 {							\
 	unsigned int x;					\
 	__asm__ __volatile__(				\
@@ -122,7 +122,7 @@
 }
 
 #define __do_out_asm(name, op)				\
-extern __inline__ void name(unsigned int val, unsigned int port) \
+static __inline__ void name(unsigned int val, unsigned int port) \
 {							\
 	__asm__ __volatile__(				\
 		op " %0,0,%1\n"				\
@@ -213,7 +213,7 @@
  * This makes sure that a value has been returned from a device
  * before any subsequent loads or stores are performed.
  */
-extern inline void io_flush(int value)
+static inline void io_flush(int value)
 {
 	__asm__ __volatile__("twi 0,%0,0; isync" : : "r" (value));
 }
@@ -225,7 +225,7 @@
  * address from the PCI point of view, thus buffer addresses also
  * have to be modified [mapped] appropriately.
  */
-extern inline unsigned long virt_to_bus(volatile void * address)
+static inline unsigned long virt_to_bus(volatile void * address)
 {
 #ifdef CONFIG_APUS
 	return (iopa((unsigned long) address) + PCI_DRAM_OFFSET);
@@ -236,7 +236,7 @@
 #endif
 }
 
-extern inline void * bus_to_virt(unsigned long address)
+static inline void * bus_to_virt(unsigned long address)
 {
 #ifdef CONFIG_APUS
 	return (void*) mm_ptov (address - PCI_DRAM_OFFSET);
@@ -251,7 +251,7 @@
  * Change virtual addresses to physical addresses and vv, for
  * addresses in the area where the kernel has the RAM mapped.
  */
-extern inline unsigned long virt_to_phys(volatile void * address)
+static inline unsigned long virt_to_phys(volatile void * address)
 {
 #ifdef CONFIG_APUS
 	return iopa ((unsigned long) address);
@@ -260,7 +260,7 @@
 #endif
 }
 
-extern inline void * phys_to_virt(unsigned long address)
+static inline void * phys_to_virt(unsigned long address)
 {
 #ifdef CONFIG_APUS
 	return (void*) mm_ptov (address);
@@ -280,7 +280,7 @@
  * Acts as a barrier to ensure all previous I/O accesses have
  * completed before any further ones are issued.
  */
-extern inline void eieio(void)
+static inline void eieio(void)
 {
 	__asm__ __volatile__ ("eieio" : : : "memory");
 }
@@ -299,7 +299,7 @@
  * is actually performed (i.e. the data has come back) before we start
  * executing any following instructions.
  */
-extern inline int in_8(volatile unsigned char *addr)
+static inline int in_8(volatile unsigned char *addr)
 {
 	int ret;
 
@@ -310,12 +310,12 @@
 	return ret;
 }
 
-extern inline void out_8(volatile unsigned char *addr, int val)
+static inline void out_8(volatile unsigned char *addr, int val)
 {
 	__asm__ __volatile__("stb%U0%X0 %1,%0; eieio" : "=m" (*addr) : "r" (val));
 }
 
-extern inline int in_le16(volatile unsigned short *addr)
+static inline int in_le16(volatile unsigned short *addr)
 {
 	int ret;
 
@@ -326,7 +326,7 @@
 	return ret;
 }
 
-extern inline int in_be16(volatile unsigned short *addr)
+static inline int in_be16(volatile unsigned short *addr)
 {
 	int ret;
 
@@ -336,18 +336,18 @@
 	return ret;
 }
 
-extern inline void out_le16(volatile unsigned short *addr, int val)
+static inline void out_le16(volatile unsigned short *addr, int val)
 {
 	__asm__ __volatile__("sthbrx %1,0,%2; eieio" : "=m" (*addr) :
 			      "r" (val), "r" (addr));
 }
 
-extern inline void out_be16(volatile unsigned short *addr, int val)
+static inline void out_be16(volatile unsigned short *addr, int val)
 {
 	__asm__ __volatile__("sth%U0%X0 %1,%0; eieio" : "=m" (*addr) : "r" (val));
 }
 
-extern inline unsigned in_le32(volatile unsigned *addr)
+static inline unsigned in_le32(volatile unsigned *addr)
 {
 	unsigned ret;
 
@@ -358,7 +358,7 @@
 	return ret;
 }
 
-extern inline unsigned in_be32(volatile unsigned *addr)
+static inline unsigned in_be32(volatile unsigned *addr)
 {
 	unsigned ret;
 
@@ -368,13 +368,13 @@
 	return ret;
 }
 
-extern inline void out_le32(volatile unsigned *addr, int val)
+static inline void out_le32(volatile unsigned *addr, int val)
 {
 	__asm__ __volatile__("stwbrx %1,0,%2; eieio" : "=m" (*addr) :
 			     "r" (val), "r" (addr));
 }
 
-extern inline void out_be32(volatile unsigned *addr, int val)
+static inline void out_be32(volatile unsigned *addr, int val)
 {
 	__asm__ __volatile__("stw%U0%X0 %1,%0; eieio" : "=m" (*addr) : "r" (val));
 }
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/open_pic.h linux-2.4.25-kdb-trace/include/asm-ppc/open_pic.h
--- linux-2.4.25-kdb/include/asm-ppc/open_pic.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/open_pic.h	2005-01-05 16:45:37.000000000 +0100
@@ -54,7 +54,7 @@
 extern void smp_openpic_message_pass(int target, int msg, unsigned long data,
 				     int wait);
 
-extern inline int openpic_to_irq(int irq)
+static inline int openpic_to_irq(int irq)
 {
 	/* IRQ 0 usually means 'disabled'.. don't mess with it
 	 * exceptions to this (sandpoint maybe?)
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/page.h linux-2.4.25-kdb-trace/include/asm-ppc/page.h
--- linux-2.4.25-kdb/include/asm-ppc/page.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ppc/page.h	2005-01-05 16:45:37.000000000 +0100
@@ -153,7 +153,7 @@
 extern unsigned long get_zero_page_fast(void);
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
 	int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/pci.h linux-2.4.25-kdb-trace/include/asm-ppc/pci.h
--- linux-2.4.25-kdb/include/asm-ppc/pci.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ppc/pci.h	2005-01-05 16:45:37.000000000 +0100
@@ -29,12 +29,12 @@
 #define PCIBIOS_MIN_IO		0x1000
 #define PCIBIOS_MIN_MEM		0x10000000
 
-extern inline void pcibios_set_master(struct pci_dev *dev)
+static inline void pcibios_set_master(struct pci_dev *dev)
 {
 	/* No special bus mastering setup handling */
 }
 
-extern inline void pcibios_penalize_isa_irq(int irq)
+static inline void pcibios_penalize_isa_irq(int irq)
 {
 	/* We don't do dynamic PCI IRQ allocation */
 }
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/pgalloc.h linux-2.4.25-kdb-trace/include/asm-ppc/pgalloc.h
--- linux-2.4.25-kdb/include/asm-ppc/pgalloc.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ppc/pgalloc.h	2005-01-05 16:45:37.000000000 +0100
@@ -59,7 +59,7 @@
 
 extern void __bad_pte(pmd_t *pmd);
 
-extern __inline__ pgd_t *get_pgd_slow(void)
+static __inline__ pgd_t *get_pgd_slow(void)
 {
 	pgd_t *ret;
 
@@ -68,7 +68,7 @@
 	return ret;
 }
 
-extern __inline__ pgd_t *get_pgd_fast(void)
+static __inline__ pgd_t *get_pgd_fast(void)
 {
         unsigned long *ret;
 
@@ -81,14 +81,14 @@
         return (pgd_t *)ret;
 }
 
-extern __inline__ void free_pgd_fast(pgd_t *pgd)
+static __inline__ void free_pgd_fast(pgd_t *pgd)
 {
         *(unsigned long **)pgd = pgd_quicklist;
         pgd_quicklist = (unsigned long *) pgd;
         pgtable_cache_size++;
 }
 
-extern __inline__ void free_pgd_slow(pgd_t *pgd)
+static __inline__ void free_pgd_slow(pgd_t *pgd)
 {
 	free_page((unsigned long)pgd);
 }
@@ -132,14 +132,14 @@
         return (pte_t *)ret;
 }
 
-extern __inline__ void pte_free_fast(pte_t *pte)
+static __inline__ void pte_free_fast(pte_t *pte)
 {
         *(unsigned long **)pte = pte_quicklist;
         pte_quicklist = (unsigned long *) pte;
         pgtable_cache_size++;
 }
 
-extern __inline__ void pte_free_slow(pte_t *pte)
+static __inline__ void pte_free_slow(pte_t *pte)
 {
 	free_page((unsigned long)pte);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/processor.h linux-2.4.25-kdb-trace/include/asm-ppc/processor.h
--- linux-2.4.25-kdb/include/asm-ppc/processor.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ppc/processor.h	2005-01-05 16:45:37.000000000 +0100
@@ -890,12 +890,12 @@
 #define ARCH_HAS_PREFETCHW
 #define ARCH_HAS_SPINLOCK_PREFETCH
 
-extern inline void prefetch(const void *x)
+static inline void prefetch(const void *x)
 {
 	 __asm__ __volatile__ ("dcbt 0,%0" : : "r" (x));
 }
 
-extern inline void prefetchw(const void *x)
+static inline void prefetchw(const void *x)
 {
 	 __asm__ __volatile__ ("dcbtst 0,%0" : : "r" (x));
 }
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/semaphore.h linux-2.4.25-kdb-trace/include/asm-ppc/semaphore.h
--- linux-2.4.25-kdb/include/asm-ppc/semaphore.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/semaphore.h	2005-01-05 16:45:37.000000000 +0100
@@ -78,7 +78,7 @@
 extern int  __down_interruptible(struct semaphore * sem);
 extern void __up(struct semaphore * sem);
 
-extern inline void down(struct semaphore * sem)
+static inline void down(struct semaphore * sem)
 {
 #if WAITQUEUE_DEBUG
 	CHECK_MAGIC(sem->__magic);
@@ -92,7 +92,7 @@
 	smp_wmb();
 }
 
-extern inline int down_interruptible(struct semaphore * sem)
+static inline int down_interruptible(struct semaphore * sem)
 {
 	int ret = 0;
 
@@ -106,7 +106,7 @@
 	return ret;
 }
 
-extern inline int down_trylock(struct semaphore * sem)
+static inline int down_trylock(struct semaphore * sem)
 {
 	int ret;
 
@@ -119,7 +119,7 @@
 	return ret;
 }
 
-extern inline void up(struct semaphore * sem)
+static inline void up(struct semaphore * sem)
 {
 #if WAITQUEUE_DEBUG
 	CHECK_MAGIC(sem->__magic);
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/siginfo.h linux-2.4.25-kdb-trace/include/asm-ppc/siginfo.h
--- linux-2.4.25-kdb/include/asm-ppc/siginfo.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/siginfo.h	2005-01-05 16:45:37.000000000 +0100
@@ -215,7 +215,7 @@
 #ifdef __KERNEL__
 #include <linux/string.h>
 
-extern inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
+static inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
 {
 	if (from->si_code < 0)
 		memcpy(to, from, sizeof(siginfo_t));
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/system.h linux-2.4.25-kdb-trace/include/asm-ppc/system.h
--- linux-2.4.25-kdb/include/asm-ppc/system.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/system.h	2005-01-05 16:45:37.000000000 +0100
@@ -168,7 +168,7 @@
 
 }
 
-extern inline void * xchg_ptr(void * m, void * val)
+static inline void * xchg_ptr(void * m, void * val)
 {
 	return (void *) xchg_u32(m, (unsigned long) val);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/time.h linux-2.4.25-kdb-trace/include/asm-ppc/time.h
--- linux-2.4.25-kdb/include/asm-ppc/time.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/time.h	2005-01-05 16:45:37.000000000 +0100
@@ -57,39 +57,39 @@
 /* Accessor functions for the timebase (RTC on 601) registers. */
 /* If one day CONFIG_POWER is added just define __USE_RTC as 1 */
 #ifdef CONFIG_6xx
-extern __inline__ int const __USE_RTC(void) {
+static __inline__ int const __USE_RTC(void) {
 	return (mfspr(SPRN_PVR)>>16) == 1;
 }
 #else
 #define __USE_RTC() 0
 #endif
 
-extern __inline__ unsigned long get_tbl(void) {
+static __inline__ unsigned long get_tbl(void) {
 	unsigned long tbl;
 	asm volatile("mftb %0" : "=r" (tbl));
 	return tbl;
 }
 
-extern __inline__ unsigned long get_tbu(void) {
+static __inline__ unsigned long get_tbu(void) {
 	unsigned long tbl;
 	asm volatile("mftbu %0" : "=r" (tbl));
 	return tbl;
 }
 
-extern __inline__ void set_tb(unsigned int upper, unsigned int lower)
+static __inline__ void set_tb(unsigned int upper, unsigned int lower)
 {
 	mtspr(SPRN_TBWL, 0);
 	mtspr(SPRN_TBWU, upper);
 	mtspr(SPRN_TBWL, lower);
 }
 
-extern __inline__ unsigned long get_rtcl(void) {
+static __inline__ unsigned long get_rtcl(void) {
 	unsigned long rtcl;
 	asm volatile("mfrtcl %0" : "=r" (rtcl));
 	return rtcl;
 }
 
-extern __inline__ unsigned get_native_tbl(void) {
+static __inline__ unsigned get_native_tbl(void) {
 	if (__USE_RTC())
 		return get_rtcl();
 	else
@@ -100,7 +100,7 @@
  * after the timestamp and for 1 second. It is only used by gettimeofday
  * however so it should not matter.
  */
-extern __inline__ unsigned tb_ticks_since(unsigned tstamp) {
+static __inline__ unsigned tb_ticks_since(unsigned tstamp) {
 	if (__USE_RTC()) {
 		int delta = get_rtcl() - tstamp;
 		return delta<0 ? delta + 1000000000 : delta;
@@ -110,7 +110,7 @@
 }
 
 #if 0
-extern __inline__ unsigned long get_bin_rtcl(void) {
+static __inline__ unsigned long get_bin_rtcl(void) {
       unsigned long rtcl, rtcu1, rtcu2;
       asm volatile("\
 1:    mfrtcu  %0\n\
@@ -123,7 +123,7 @@
       return rtcu2*1000000000+rtcl;
 }
 
-extern __inline__ unsigned binary_tbl(void) {
+static __inline__ unsigned binary_tbl(void) {
       if (__USE_RTC())
               return get_bin_rtcl();
       else
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/uaccess.h linux-2.4.25-kdb-trace/include/asm-ppc/uaccess.h
--- linux-2.4.25-kdb/include/asm-ppc/uaccess.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ppc/uaccess.h	2005-01-05 16:45:37.000000000 +0100
@@ -32,7 +32,7 @@
 #define __access_ok(addr,size) (__kernel_ok || __user_ok((addr),(size)))
 #define access_ok(type,addr,size) __access_ok((unsigned long)(addr),(size))
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
 	return access_ok(type,addr,size) ? 0 : -EFAULT;
 }
@@ -272,7 +272,7 @@
 
 extern int __copy_tofrom_user(void *to, const void *from, unsigned long size);
 
-extern inline unsigned long
+static inline unsigned long
 copy_from_user(void *to, const void *from, unsigned long n)
 {
 	unsigned long over;
@@ -286,7 +286,7 @@
 	return n;
 }
 
-extern inline unsigned long
+static inline unsigned long
 copy_to_user(void *to, const void *from, unsigned long n)
 {
 	unsigned long over;
@@ -307,7 +307,7 @@
 
 extern unsigned long __clear_user(void *addr, unsigned long size);
 
-extern inline unsigned long
+static inline unsigned long
 clear_user(void *addr, unsigned long size)
 {
 	if (access_ok(VERIFY_WRITE, addr, size))
@@ -321,7 +321,7 @@
 
 extern int __strncpy_from_user(char *dst, const char *src, long count);
 
-extern inline long
+static inline long
 strncpy_from_user(char *dst, const char *src, long count)
 {
 	if (access_ok(VERIFY_READ, src, 1))
@@ -345,7 +345,7 @@
  * The `top' parameter to __strnlen_user is to make sure that
  * we can never overflow from the user area into kernel space.
  */
-extern __inline__ int strnlen_user(const char *str, long len)
+static __inline__ int strnlen_user(const char *str, long len)
 {
 	unsigned long top = __kernel_ok? ~0UL: TASK_SIZE - 1;
 
diff -rbNu linux-2.4.25-kdb/include/asm-ppc/vga.h linux-2.4.25-kdb-trace/include/asm-ppc/vga.h
--- linux-2.4.25-kdb/include/asm-ppc/vga.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-ppc/vga.h	2005-01-05 16:45:37.000000000 +0100
@@ -22,12 +22,12 @@
  *  <linux/vt_buffer.h> has already done the right job for us.
  */
 
-extern inline void scr_writew(u16 val, volatile u16 *addr)
+static inline void scr_writew(u16 val, volatile u16 *addr)
 {
     st_le16(addr, val);
 }
 
-extern inline u16 scr_readw(volatile const u16 *addr)
+static inline u16 scr_readw(volatile const u16 *addr)
 {
     return ld_le16(addr);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-ppc64/irq.h linux-2.4.25-kdb-trace/include/asm-ppc64/irq.h
--- linux-2.4.25-kdb/include/asm-ppc64/irq.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-ppc64/irq.h	2005-01-05 16:45:35.000000000 +0100
@@ -56,17 +56,17 @@
 
 #define NUM_ISA_INTERRUPTS	0x10
 
-extern inline int irq_offset_up(int irq)
+static inline int irq_offset_up(int irq)
 {
 	return(irq + NUM_ISA_INTERRUPTS);
 }
 
-extern inline int irq_offset_down(int irq)
+static inline int irq_offset_down(int irq)
 {
 	return(irq - NUM_ISA_INTERRUPTS);
 }
 
-extern inline int irq_offset_value(void)
+static inline int irq_offset_value(void)
 {
 	return NUM_ISA_INTERRUPTS;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-s390/bitops.h linux-2.4.25-kdb-trace/include/asm-s390/bitops.h
--- linux-2.4.25-kdb/include/asm-s390/bitops.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/bitops.h	2005-01-05 16:45:40.000000000 +0100
@@ -713,7 +713,7 @@
  * differs in spirit from the above ffz (man ffs).
  */
 
-extern int __inline__ ffs (int x)
+static int __inline__ ffs (int x)
 {
         int r;
 
diff -rbNu linux-2.4.25-kdb/include/asm-s390/checksum.h linux-2.4.25-kdb-trace/include/asm-s390/checksum.h
--- linux-2.4.25-kdb/include/asm-s390/checksum.h	2001-07-25 23:12:02.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/checksum.h	2005-01-05 16:45:40.000000000 +0100
@@ -33,7 +33,7 @@
 /*
  * csum_partial as an inline function
  */
-extern inline unsigned int 
+static inline unsigned int 
 csum_partial_inline(const unsigned char * buff, int len, unsigned int sum)
 {
 	register_pair rp;
@@ -55,7 +55,7 @@
  * better 64-bit) boundary
  */
 
-extern inline unsigned int 
+static inline unsigned int 
 csum_partial_copy(const char *src, char *dst, int len,unsigned int sum)
 {
 	memcpy(dst,src,len);
@@ -71,7 +71,7 @@
  * Copy from userspace and compute checksum.  If we catch an exception
  * then zero the rest of the buffer.
  */
-extern inline unsigned int 
+static inline unsigned int 
 csum_partial_copy_from_user (const char *src, char *dst,
                                           int len, unsigned int sum,
                                           int *err_ptr)
@@ -88,7 +88,7 @@
 }
 
 
-extern inline unsigned int
+static inline unsigned int
 csum_partial_copy_nocheck (const char *src, char *dst, int len, unsigned int sum)
 {
         memcpy(dst,src,len);
@@ -101,7 +101,7 @@
 #if 1
 unsigned short csum_fold(unsigned int sum);
 #else
-extern inline unsigned short
+static inline unsigned short
 csum_fold(unsigned int sum)
 {
 	register_pair rp;
@@ -123,7 +123,7 @@
  *	which always checksum on 4 octet boundaries.
  *
  */
-extern inline unsigned short
+static inline unsigned short
 ip_fast_csum(unsigned char *iph, unsigned int ihl)
 {
 	register_pair rp;
@@ -143,7 +143,7 @@
  * computes the checksum of the TCP/UDP pseudo-header
  * returns a 32-bit checksum
  */
-extern inline unsigned int 
+static inline unsigned int 
 csum_tcpudp_nofold(unsigned long saddr, unsigned long daddr,
                    unsigned short len, unsigned short proto,
                    unsigned int sum)
@@ -176,7 +176,7 @@
  * returns a 16-bit checksum, already complemented
  */
 
-extern inline unsigned short int
+static inline unsigned short int
 csum_tcpudp_magic(unsigned long saddr, unsigned long daddr,
                   unsigned short len, unsigned short proto,
                   unsigned int sum)
@@ -189,7 +189,7 @@
  * in icmp.c
  */
 
-extern inline unsigned short
+static inline unsigned short
 ip_compute_csum(unsigned char * buff, int len)
 {
 	return csum_fold(csum_partial(buff, len, 0));
diff -rbNu linux-2.4.25-kdb/include/asm-s390/debug.h linux-2.4.25-kdb-trace/include/asm-s390/debug.h
--- linux-2.4.25-kdb/include/asm-s390/debug.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/debug.h	2005-01-05 16:45:40.000000000 +0100
@@ -129,14 +129,14 @@
 
 void debug_set_level(debug_info_t* id, int new_level);
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_event(debug_info_t* id, int level, void* data, int length)
 {
 	if ((!id) || (level > id->level)) return NULL;
         return debug_event_common(id,level,data,length);
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_int_event(debug_info_t* id, int level, unsigned int tag)
 {
         unsigned int t=tag;
@@ -144,7 +144,7 @@
         return debug_event_common(id,level,&t,sizeof(unsigned int));
 }
 
-extern inline debug_entry_t *
+static inline debug_entry_t *
 debug_long_event (debug_info_t* id, int level, unsigned long tag)
 {
         unsigned long t=tag;
@@ -152,7 +152,7 @@
         return debug_event_common(id,level,&t,sizeof(unsigned long));
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_text_event(debug_info_t* id, int level, const char* txt)
 {
 	if ((!id) || (level > id->level)) return NULL;
@@ -163,14 +163,14 @@
 debug_sprintf_event(debug_info_t* id,int level,char *string,...);
 
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_exception(debug_info_t* id, int level, void* data, int length)
 {
 	if ((!id) || (level > id->level)) return NULL;
         return debug_exception_common(id,level,data,length);
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_int_exception(debug_info_t* id, int level, unsigned int tag)
 {
         unsigned int t=tag;
@@ -178,7 +178,7 @@
         return debug_exception_common(id,level,&t,sizeof(unsigned int));
 }
 
-extern inline debug_entry_t * 
+static inline debug_entry_t * 
 debug_long_exception (debug_info_t* id, int level, unsigned long tag)
 {
         unsigned long t=tag;
@@ -186,7 +186,7 @@
         return debug_exception_common(id,level,&t,sizeof(unsigned long));
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_text_exception(debug_info_t* id, int level, const char* txt)
 {
 	if ((!id) || (level > id->level)) return NULL;
diff -rbNu linux-2.4.25-kdb/include/asm-s390/ebcdic.h linux-2.4.25-kdb-trace/include/asm-s390/ebcdic.h
--- linux-2.4.25-kdb/include/asm-s390/ebcdic.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/ebcdic.h	2005-01-05 16:45:40.000000000 +0100
@@ -21,7 +21,7 @@
 extern __u8 _ebc_tolower[]; /* EBCDIC -> lowercase */
 extern __u8 _ebc_toupper[]; /* EBCDIC -> uppercase */
 
-extern __inline__ 
+static __inline__ 
 void codepage_convert(const __u8 *codepage, volatile __u8 * addr, int nr)
 {
 	if (nr-- <= 0)
diff -rbNu linux-2.4.25-kdb/include/asm-s390/io.h linux-2.4.25-kdb-trace/include/asm-s390/io.h
--- linux-2.4.25-kdb/include/asm-s390/io.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/io.h	2005-01-05 16:45:40.000000000 +0100
@@ -24,7 +24,7 @@
  * Change virtual addresses to physical addresses and vv.
  * These are pretty trivial
  */
-extern inline unsigned long virt_to_phys(volatile void * address)
+static inline unsigned long virt_to_phys(volatile void * address)
 {
 	unsigned long real_address;
 	__asm__ ("   lra    %0,0(%1)\n"
@@ -35,7 +35,7 @@
         return real_address;
 }
 
-extern inline void * phys_to_virt(unsigned long address)
+static inline void * phys_to_virt(unsigned long address)
 {
         return __io_virt(address);
 }
@@ -47,7 +47,7 @@
 
 extern void * __ioremap(unsigned long offset, unsigned long size, unsigned long flags);
 
-extern inline void * ioremap (unsigned long offset, unsigned long size)
+static inline void * ioremap (unsigned long offset, unsigned long size)
 {
         return __ioremap(offset, size, 0);
 }
@@ -57,7 +57,7 @@
  * it's useful if some control registers are in such an area and write combining
  * or read caching is not desirable:
  */
-extern inline void * ioremap_nocache (unsigned long offset, unsigned long size)
+static inline void * ioremap_nocache (unsigned long offset, unsigned long size)
 {
         return __ioremap(offset, size, 0);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-s390/irq.h linux-2.4.25-kdb-trace/include/asm-s390/irq.h
--- linux-2.4.25-kdb/include/asm-s390/irq.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390/irq.h	2005-01-05 16:45:40.000000000 +0100
@@ -667,7 +667,7 @@
  * Some S390 specific IO instructions as inline
  */
 
-extern __inline__ int stsch(int irq, volatile schib_t *addr)
+static __inline__ int stsch(int irq, volatile schib_t *addr)
 {
         int ccode;
 
@@ -682,7 +682,7 @@
         return ccode;
 }
 
-extern __inline__ int msch(int irq, volatile schib_t *addr)
+static __inline__ int msch(int irq, volatile schib_t *addr)
 {
         int ccode;
 
@@ -697,7 +697,7 @@
         return ccode;
 }
 
-extern __inline__ int msch_err(int irq, volatile schib_t *addr)
+static __inline__ int msch_err(int irq, volatile schib_t *addr)
 {
         int ccode;
 
@@ -735,7 +735,7 @@
         return ccode;
 }
 
-extern __inline__ int tsch(int irq, volatile irb_t *addr)
+static __inline__ int tsch(int irq, volatile irb_t *addr)
 {
         int ccode;
 
@@ -750,7 +750,7 @@
         return ccode;
 }
 
-extern __inline__ int tpi( volatile tpi_info_t *addr)
+static __inline__ int tpi( volatile tpi_info_t *addr)
 {
         int ccode;
 
@@ -764,7 +764,7 @@
         return ccode;
 }
 
-extern __inline__ int ssch(int irq, volatile orb_t *addr)
+static __inline__ int ssch(int irq, volatile orb_t *addr)
 {
         int ccode;
 
@@ -779,7 +779,7 @@
         return ccode;
 }
 
-extern __inline__ int diag98(int irq, volatile orb_t *addr)
+static __inline__ int diag98(int irq, volatile orb_t *addr)
 {
         int ccode;
 
@@ -798,7 +798,7 @@
         return ccode;
 }
 
-extern __inline__ int rsch(int irq)
+static __inline__ int rsch(int irq)
 {
         int ccode;
 
@@ -813,7 +813,7 @@
         return ccode;
 }
 
-extern __inline__ int csch(int irq)
+static __inline__ int csch(int irq)
 {
         int ccode;
 
@@ -828,7 +828,7 @@
         return ccode;
 }
 
-extern __inline__ int hsch(int irq)
+static __inline__ int hsch(int irq)
 {
         int ccode;
 
@@ -843,7 +843,7 @@
         return ccode;
 }
 
-extern __inline__ int xsch(int irq)
+static __inline__ int xsch(int irq)
 {
 	int ccode;
 	
@@ -858,7 +858,7 @@
 	return ccode;
 }
 
-extern __inline__ int iac( void)
+static __inline__ int iac( void)
 {
         int ccode;
 
@@ -870,7 +870,7 @@
         return ccode;
 }
 
-extern __inline__ int rchp(int chpid)
+static __inline__ int rchp(int chpid)
 {
         int ccode;
 
@@ -903,7 +903,7 @@
 
 extern int diag210( diag210_t * addr);
 
-extern __inline__ int chsc( chsc_area_t * chsc_area)
+static __inline__ int chsc( chsc_area_t * chsc_area)
 {
 	int cc;
 	
diff -rbNu linux-2.4.25-kdb/include/asm-s390/lowcore.h linux-2.4.25-kdb-trace/include/asm-s390/lowcore.h
--- linux-2.4.25-kdb/include/asm-s390/lowcore.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/lowcore.h	2005-01-05 16:45:40.000000000 +0100
@@ -176,7 +176,7 @@
 	__u8         pad12[0x1000-0xe04];      /* 0xe04 */
 } __attribute__((packed)); /* End structure*/
 
-extern __inline__ void set_prefix(__u32 address)
+static __inline__ void set_prefix(__u32 address)
 {
         __asm__ __volatile__ ("spx %0" : : "m" (address) : "memory" );
 }
diff -rbNu linux-2.4.25-kdb/include/asm-s390/mmu_context.h linux-2.4.25-kdb-trace/include/asm-s390/mmu_context.h
--- linux-2.4.25-kdb/include/asm-s390/mmu_context.h	2001-02-13 23:13:44.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390/mmu_context.h	2005-01-05 16:45:40.000000000 +0100
@@ -37,7 +37,7 @@
 	set_bit(cpu, &next->cpu_vm_mask);
 }
 
-extern inline void activate_mm(struct mm_struct *prev,
+static inline void activate_mm(struct mm_struct *prev,
                                struct mm_struct *next)
 {
         switch_mm(prev, next, current, smp_processor_id());
diff -rbNu linux-2.4.25-kdb/include/asm-s390/page.h linux-2.4.25-kdb-trace/include/asm-s390/page.h
--- linux-2.4.25-kdb/include/asm-s390/page.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/page.h	2005-01-05 16:45:40.000000000 +0100
@@ -72,7 +72,7 @@
 } while (0)                      
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
         int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-s390/pgalloc.h linux-2.4.25-kdb-trace/include/asm-s390/pgalloc.h
--- linux-2.4.25-kdb/include/asm-s390/pgalloc.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390/pgalloc.h	2005-01-05 16:45:40.000000000 +0100
@@ -30,7 +30,7 @@
  * if any.
  */
 
-extern __inline__ pgd_t* get_pgd_slow(void)
+static __inline__ pgd_t* get_pgd_slow(void)
 {
 	pgd_t *ret;
         int i;
@@ -42,7 +42,7 @@
 	return ret;
 }
 
-extern __inline__ pgd_t* get_pgd_fast(void)
+static __inline__ pgd_t* get_pgd_fast(void)
 {
         unsigned long *ret = pgd_quicklist;
 	
@@ -54,7 +54,7 @@
         return (pgd_t *)ret;
 }
 
-extern __inline__ pgd_t *pgd_alloc(struct mm_struct *mm)
+static __inline__ pgd_t *pgd_alloc(struct mm_struct *mm)
 {
 	pgd_t *pgd;
 
@@ -64,14 +64,14 @@
 	return pgd;
 }
 
-extern __inline__ void free_pgd_fast(pgd_t *pgd)
+static __inline__ void free_pgd_fast(pgd_t *pgd)
 {
         *(unsigned long *)pgd = (unsigned long) pgd_quicklist;
         pgd_quicklist = (unsigned long *) pgd;
         pgtable_cache_size += 2;
 }
 
-extern __inline__ void free_pgd_slow(pgd_t *pgd)
+static __inline__ void free_pgd_slow(pgd_t *pgd)
 {
         free_pages((unsigned long) pgd, 1);
 }
@@ -90,7 +90,7 @@
 #define pmd_free_fast(x)                do { } while (0)
 #define pgd_populate(mm, pmd, pte)      BUG()
 
-extern inline void pmd_populate(struct mm_struct *mm, pmd_t *pmd, pte_t *pte)
+static inline void pmd_populate(struct mm_struct *mm, pmd_t *pmd, pte_t *pte)
 {
 	pmd_val(pmd[0]) = _PAGE_TABLE + __pa(pte);
 	pmd_val(pmd[1]) = _PAGE_TABLE + __pa(pte+256);
@@ -101,7 +101,7 @@
 /*
  * page table entry allocation/free routines.
  */
-extern inline pte_t * pte_alloc_one(struct mm_struct *mm, unsigned long vmaddr)
+static inline pte_t * pte_alloc_one(struct mm_struct *mm, unsigned long vmaddr)
 {
 	pte_t *pte;
         int i;
@@ -114,7 +114,7 @@
 	return pte;
 }
 
-extern __inline__ pte_t *
+static __inline__ pte_t *
 pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
 {
         unsigned long *ret = (unsigned long *) pte_quicklist;
@@ -127,14 +127,14 @@
         return (pte_t *)ret;
 }
 
-extern __inline__ void pte_free_fast(pte_t *pte)
+static __inline__ void pte_free_fast(pte_t *pte)
 {
         *(unsigned long *)pte = (unsigned long) pte_quicklist;
         pte_quicklist = (unsigned long *) pte;
         pgtable_cache_size++;
 }
 
-extern __inline__ void pte_free_slow(pte_t *pte)
+static __inline__ void pte_free_slow(pte_t *pte)
 {
         free_page((unsigned long) pte);
 }
@@ -275,7 +275,7 @@
 
 #endif
 
-extern inline void flush_tlb_pgtables(struct mm_struct *mm,
+static inline void flush_tlb_pgtables(struct mm_struct *mm,
                                       unsigned long start, unsigned long end)
 {
         /* S/390 does not keep any page table caches in TLB */
diff -rbNu linux-2.4.25-kdb/include/asm-s390/pgtable.h linux-2.4.25-kdb-trace/include/asm-s390/pgtable.h
--- linux-2.4.25-kdb/include/asm-s390/pgtable.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/pgtable.h	2005-01-05 16:45:40.000000000 +0100
@@ -227,7 +227,7 @@
  * within a page table are directly modified.  Thus, the following
  * hook is made available.
  */
-extern inline void set_pte(pte_t *pteptr, pte_t pteval)
+static inline void set_pte(pte_t *pteptr, pte_t pteval)
 {
 	*pteptr = pteval;
 }
@@ -237,19 +237,19 @@
 /*
  * pgd/pmd/pte query functions
  */
-extern inline int pgd_present(pgd_t pgd) { return 1; }
-extern inline int pgd_none(pgd_t pgd)    { return 0; }
-extern inline int pgd_bad(pgd_t pgd)     { return 0; }
-
-extern inline int pmd_present(pmd_t pmd) { return pmd_val(pmd) & _SEG_PRESENT; }
-extern inline int pmd_none(pmd_t pmd)    { return pmd_val(pmd) & _PAGE_TABLE_INV; }
-extern inline int pmd_bad(pmd_t pmd)
+static inline int pgd_present(pgd_t pgd) { return 1; }
+static inline int pgd_none(pgd_t pgd)    { return 0; }
+static inline int pgd_bad(pgd_t pgd)     { return 0; }
+
+static inline int pmd_present(pmd_t pmd) { return pmd_val(pmd) & _SEG_PRESENT; }
+static inline int pmd_none(pmd_t pmd)    { return pmd_val(pmd) & _PAGE_TABLE_INV; }
+static inline int pmd_bad(pmd_t pmd)
 {
 	return (pmd_val(pmd) & (~PAGE_MASK & ~_PAGE_TABLE_INV)) != _PAGE_TABLE;
 }
 
-extern inline int pte_present(pte_t pte) { return pte_val(pte) & _PAGE_PRESENT; }
-extern inline int pte_none(pte_t pte)
+static inline int pte_present(pte_t pte) { return pte_val(pte) & _PAGE_PRESENT; }
+static inline int pte_none(pte_t pte)
 {
 	return ((pte_val(pte) & 
                 (_PAGE_INVALID | _PAGE_RO | _PAGE_PRESENT)) == _PAGE_INVALID);
@@ -261,12 +261,12 @@
  * query functions pte_write/pte_dirty/pte_young only work if
  * pte_present() is true. Undefined behaviour if not..
  */
-extern inline int pte_write(pte_t pte)
+static inline int pte_write(pte_t pte)
 {
 	return (pte_val(pte) & _PAGE_RO) == 0;
 }
 
-extern inline int pte_dirty(pte_t pte)
+static inline int pte_dirty(pte_t pte)
 {
 	int skey;
 
@@ -276,7 +276,7 @@
 	return skey & _PAGE_CHANGED;
 }
 
-extern inline int pte_young(pte_t pte)
+static inline int pte_young(pte_t pte)
 {
 	int skey;
 
@@ -287,9 +287,9 @@
 /*
  * pgd/pmd/pte modification functions
  */
-extern inline void pgd_clear(pgd_t * pgdp)      { }
+static inline void pgd_clear(pgd_t * pgdp)      { }
 
-extern inline void pmd_clear(pmd_t * pmdp)
+static inline void pmd_clear(pmd_t * pmdp)
 {
 	pmd_val(pmdp[0]) = _PAGE_TABLE_INV;
 	pmd_val(pmdp[1]) = _PAGE_TABLE_INV;
@@ -297,7 +297,7 @@
 	pmd_val(pmdp[3]) = _PAGE_TABLE_INV;
 }
 
-extern inline void pte_clear(pte_t *ptep)
+static inline void pte_clear(pte_t *ptep)
 {
 	pte_val(*ptep) = _PAGE_INVALID; 
 }
@@ -308,26 +308,26 @@
  * The following pte modification functions only work if
  * pte_present() is true. Undefined behaviour if not..
  */
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 {
 	pte_val(pte) &= PAGE_MASK | _PAGE_ISCLEAN;
 	pte_val(pte) |= pgprot_val(newprot) & ~_PAGE_ISCLEAN;
 	return pte;
 }
 
-extern inline pte_t pte_wrprotect(pte_t pte)
+static inline pte_t pte_wrprotect(pte_t pte)
 {
 	pte_val(pte) |= _PAGE_RO;
 	return pte;
 }
 
-extern inline pte_t pte_mkwrite(pte_t pte) 
+static inline pte_t pte_mkwrite(pte_t pte) 
 {
 	pte_val(pte) &= ~(_PAGE_RO | _PAGE_ISCLEAN);
 	return pte;
 }
 
-extern inline pte_t pte_mkclean(pte_t pte)
+static inline pte_t pte_mkclean(pte_t pte)
 {
 	/* The only user of pte_mkclean is the fork() code.
 	   We must *not* clear the *physical* page dirty bit
@@ -336,7 +336,7 @@
 	return pte;
 }
 
-extern inline pte_t pte_mkdirty(pte_t pte)
+static inline pte_t pte_mkdirty(pte_t pte)
 {
 	/* We do not explicitly set the dirty bit because the
 	 * sske instruction is slow. It is faster to let the
@@ -346,13 +346,13 @@
 	return pte;
 }
 
-extern inline pte_t pte_mkold(pte_t pte)
+static inline pte_t pte_mkold(pte_t pte)
 {
 	asm volatile ("rrbe 0,%0" : : "a" (pte_val(pte)) : "cc" );
 	return pte;
 }
 
-extern inline pte_t pte_mkyoung(pte_t pte)
+static inline pte_t pte_mkyoung(pte_t pte)
 {
 	/* To set the referenced bit we read the first word from the real
 	 * page with a special instruction: load using real address (lura).
@@ -445,7 +445,7 @@
 #define pgd_offset_k(address) pgd_offset(&init_mm, address)
 
 /* Find an entry in the second-level page table.. */
-extern inline pmd_t * pmd_offset(pgd_t * dir, unsigned long address)
+static inline pmd_t * pmd_offset(pgd_t * dir, unsigned long address)
 {
         return (pmd_t *) dir;
 }
@@ -471,7 +471,7 @@
  * 00000000001111111111222222222233
  * 01234567890123456789012345678901
  */
-extern inline pte_t mk_swap_pte(unsigned long type, unsigned long offset)
+static inline pte_t mk_swap_pte(unsigned long type, unsigned long offset)
 {
 	pte_t pte;
 	pte_val(pte) = (type << 1) | (offset << 12) | _PAGE_INVALID | _PAGE_RO;
diff -rbNu linux-2.4.25-kdb/include/asm-s390/processor.h linux-2.4.25-kdb-trace/include/asm-s390/processor.h
--- linux-2.4.25-kdb/include/asm-s390/processor.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/processor.h	2005-01-05 16:45:40.000000000 +0100
@@ -127,7 +127,7 @@
  * schedule, so we have to walk the backchain one time to
  * find the frame schedule() store its return address.
  */
-extern inline unsigned long thread_saved_pc(struct thread_struct *t)
+static inline unsigned long thread_saved_pc(struct thread_struct *t)
 {
 	unsigned long bc;
 	bc = *((unsigned long *) t->ksp);
diff -rbNu linux-2.4.25-kdb/include/asm-s390/s390mach.h linux-2.4.25-kdb-trace/include/asm-s390/s390mach.h
--- linux-2.4.25-kdb/include/asm-s390/s390mach.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390/s390mach.h	2005-01-05 16:45:40.000000000 +0100
@@ -103,7 +103,7 @@
 void s390_do_machine_check  ( void );
 void s390_do_crw_pending    ( crwe_t *pcrwe );
 
-extern __inline__ int stcrw( __u32 *pcrw )
+static __inline__ int stcrw( __u32 *pcrw )
 {
         int ccode;
 
diff -rbNu linux-2.4.25-kdb/include/asm-s390/sigp.h linux-2.4.25-kdb-trace/include/asm-s390/sigp.h
--- linux-2.4.25-kdb/include/asm-s390/sigp.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390/sigp.h	2005-01-05 16:45:40.000000000 +0100
@@ -66,7 +66,7 @@
 /*
  * Signal processor
  */
-extern __inline__ sigp_ccode
+static __inline__ sigp_ccode
 signal_processor(__u16 cpu_addr, sigp_order_code order_code)
 {
 	sigp_ccode ccode;
@@ -85,7 +85,7 @@
 /*
  * Signal processor with parameter
  */
-extern __inline__ sigp_ccode
+static __inline__ sigp_ccode
 signal_processor_p(__u32 parameter,__u16 cpu_addr,sigp_order_code order_code)
 {
 	sigp_ccode ccode;
@@ -105,7 +105,7 @@
 /*
  * Signal processor with parameter and return status
  */
-extern __inline__ sigp_ccode
+static __inline__ sigp_ccode
 signal_processor_ps(__u32 *statusptr, __u32 parameter,
 		    __u16 cpu_addr, sigp_order_code order_code)
 {
diff -rbNu linux-2.4.25-kdb/include/asm-s390/smp.h linux-2.4.25-kdb-trace/include/asm-s390/smp.h
--- linux-2.4.25-kdb/include/asm-s390/smp.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390/smp.h	2005-01-05 16:45:40.000000000 +0100
@@ -44,17 +44,17 @@
 
 #define smp_processor_id() (current->processor)
 
-extern __inline__ int cpu_logical_map(int cpu)
+static __inline__ int cpu_logical_map(int cpu)
 {
         return cpu;
 }
 
-extern __inline__ int cpu_number_map(int cpu)
+static __inline__ int cpu_number_map(int cpu)
 {
         return cpu;
 }
 
-extern __inline__ __u16 hard_smp_processor_id(void)
+static __inline__ __u16 hard_smp_processor_id(void)
 {
         __u16 cpu_address;
  
diff -rbNu linux-2.4.25-kdb/include/asm-s390/smplock.h linux-2.4.25-kdb-trace/include/asm-s390/smplock.h
--- linux-2.4.25-kdb/include/asm-s390/smplock.h	2001-02-13 23:13:44.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390/smplock.h	2005-01-05 16:45:40.000000000 +0100
@@ -48,13 +48,13 @@
  * so we only need to worry about other
  * CPU's.
  */
-extern __inline__ void lock_kernel(void)
+static __inline__ void lock_kernel(void)
 {
         if (!++current->lock_depth)
                 spin_lock(&kernel_flag);
 }
 
-extern __inline__ void unlock_kernel(void)
+static __inline__ void unlock_kernel(void)
 {
         if (--current->lock_depth < 0)
                 spin_unlock(&kernel_flag);
diff -rbNu linux-2.4.25-kdb/include/asm-s390/spinlock.h linux-2.4.25-kdb-trace/include/asm-s390/spinlock.h
--- linux-2.4.25-kdb/include/asm-s390/spinlock.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/spinlock.h	2005-01-05 16:45:40.000000000 +0100
@@ -27,7 +27,7 @@
 #define spin_unlock_wait(lp)	do { barrier(); } while(((volatile spinlock_t *)(lp))->lock)
 #define spin_is_locked(x) ((x)->lock != 0)
 
-extern inline void spin_lock(spinlock_t *lp)
+static inline void spin_lock(spinlock_t *lp)
 {
 	unsigned int reg1, reg2;
         __asm__ __volatile("    bras  %0,1f\n"
@@ -39,7 +39,7 @@
 			   : "a" (&lp->lock) : "cc", "memory" );
 }
 
-extern inline int spin_trylock(spinlock_t *lp)
+static inline int spin_trylock(spinlock_t *lp)
 {
 	unsigned long result, reg;
 	__asm__ __volatile("    slr   %0,%0\n"
@@ -50,7 +50,7 @@
 	return !result;
 }
 
-extern inline void spin_unlock(spinlock_t *lp)
+static inline void spin_unlock(spinlock_t *lp)
 {
 	__asm__ __volatile("    xc 0(4,%0),0(%0)\n"
                            "    bcr 15,0"
diff -rbNu linux-2.4.25-kdb/include/asm-s390/uaccess.h linux-2.4.25-kdb-trace/include/asm-s390/uaccess.h
--- linux-2.4.25-kdb/include/asm-s390/uaccess.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390/uaccess.h	2005-01-05 16:45:40.000000000 +0100
@@ -46,7 +46,7 @@
 
 #define access_ok(type,addr,size) __access_ok(addr,size)
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
         return access_ok(type,addr,size)?0:-EFAULT;
 }
@@ -78,7 +78,7 @@
  * use the right size if we just have the right pointer type.
  */
 
-extern inline int __put_user_asm_8(__u64 x, void *ptr)
+static inline int __put_user_asm_8(__u64 x, void *ptr)
 {
         int err;
 
@@ -107,7 +107,7 @@
         return err;
 }
 
-extern inline int __put_user_asm_4(__u32 x, void *ptr)
+static inline int __put_user_asm_4(__u32 x, void *ptr)
 {
         int err;
 
@@ -135,7 +135,7 @@
         return err;
 }
 
-extern inline int __put_user_asm_2(__u16 x, void *ptr)
+static inline int __put_user_asm_2(__u16 x, void *ptr)
 {
         int err;
 
@@ -163,7 +163,7 @@
         return err;
 }
 
-extern inline int __put_user_asm_1(__u8 x, void *ptr)
+static inline int __put_user_asm_1(__u8 x, void *ptr)
 {
         int err;
 
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/bitops.h linux-2.4.25-kdb-trace/include/asm-s390x/bitops.h
--- linux-2.4.25-kdb/include/asm-s390x/bitops.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/bitops.h	2005-01-05 16:45:41.000000000 +0100
@@ -735,7 +735,7 @@
  * differs in spirit from the above ffz (man ffs).
  */
 
-extern int __inline__ ffs (int x)
+static int __inline__ ffs (int x)
 {
         int r;
 
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/checksum.h linux-2.4.25-kdb-trace/include/asm-s390x/checksum.h
--- linux-2.4.25-kdb/include/asm-s390x/checksum.h	2001-07-25 23:12:02.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/checksum.h	2005-01-05 16:45:41.000000000 +0100
@@ -33,7 +33,7 @@
 /*
  * csum_partial as an inline function
  */
-extern inline unsigned int 
+static inline unsigned int 
 csum_partial_inline(const unsigned char * buff, int len, unsigned int sum)
 {
 	__asm__ __volatile__ (
@@ -55,7 +55,7 @@
  * better 64-bit) boundary
  */
 
-extern inline unsigned int 
+static inline unsigned int 
 csum_partial_copy(const char *src, char *dst, int len,unsigned int sum)
 {
 	memcpy(dst,src,len);
@@ -71,7 +71,7 @@
  * Copy from userspace and compute checksum.  If we catch an exception
  * then zero the rest of the buffer.
  */
-extern inline unsigned int 
+static inline unsigned int 
 csum_partial_copy_from_user (const char *src, char *dst,
                                           int len, unsigned int sum,
                                           int *err_ptr)
@@ -87,7 +87,7 @@
 	return csum_partial(dst, len, sum);
 }
 
-extern inline unsigned int
+static inline unsigned int
 csum_partial_copy_nocheck (const char *src, char *dst, int len, unsigned int sum)
 {
         memcpy(dst,src,len);
@@ -97,7 +97,7 @@
 /*
  *      Fold a partial checksum without adding pseudo headers
  */
-extern inline unsigned short
+static inline unsigned short
 csum_fold(unsigned int sum)
 {
 	__asm__ __volatile__ (
@@ -116,7 +116,7 @@
  *	which always checksum on 4 octet boundaries.
  *
  */
-extern inline unsigned short
+static inline unsigned short
 ip_fast_csum(unsigned char *iph, unsigned int ihl)
 {
 	unsigned long sum;
@@ -137,7 +137,7 @@
  * computes the checksum of the TCP/UDP pseudo-header
  * returns a 32-bit checksum
  */
-extern inline unsigned int 
+static inline unsigned int 
 csum_tcpudp_nofold(unsigned long saddr, unsigned long daddr,
                    unsigned short len, unsigned short proto,
                    unsigned int sum)
@@ -170,7 +170,7 @@
  * returns a 16-bit checksum, already complemented
  */
 
-extern inline unsigned short int
+static inline unsigned short int
 csum_tcpudp_magic(unsigned long saddr, unsigned long daddr,
                   unsigned short len, unsigned short proto,
                   unsigned int sum)
@@ -183,7 +183,7 @@
  * in icmp.c
  */
 
-extern inline unsigned short
+static inline unsigned short
 ip_compute_csum(unsigned char * buff, int len)
 {
 	return csum_fold(csum_partial_inline(buff, len, 0));
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/debug.h linux-2.4.25-kdb-trace/include/asm-s390x/debug.h
--- linux-2.4.25-kdb/include/asm-s390x/debug.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/debug.h	2005-01-05 16:45:41.000000000 +0100
@@ -129,14 +129,14 @@
 
 void debug_set_level(debug_info_t* id, int new_level);
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_event(debug_info_t* id, int level, void* data, int length)
 {
 	if ((!id) || (level > id->level)) return NULL;
         return debug_event_common(id,level,data,length);
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_int_event(debug_info_t* id, int level, unsigned int tag)
 {
         unsigned int t=tag;
@@ -144,7 +144,7 @@
         return debug_event_common(id,level,&t,sizeof(unsigned int));
 }
 
-extern inline debug_entry_t *
+static inline debug_entry_t *
 debug_long_event (debug_info_t* id, int level, unsigned long tag)
 {
         unsigned long t=tag;
@@ -152,7 +152,7 @@
         return debug_event_common(id,level,&t,sizeof(unsigned long));
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_text_event(debug_info_t* id, int level, const char* txt)
 {
 	if ((!id) || (level > id->level)) return NULL;
@@ -163,14 +163,14 @@
 debug_sprintf_event(debug_info_t* id,int level,char *string,...);
 
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_exception(debug_info_t* id, int level, void* data, int length)
 {
 	if ((!id) || (level > id->level)) return NULL;
         return debug_exception_common(id,level,data,length);
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_int_exception(debug_info_t* id, int level, unsigned int tag)
 {
         unsigned int t=tag;
@@ -178,7 +178,7 @@
         return debug_exception_common(id,level,&t,sizeof(unsigned int));
 }
 
-extern inline debug_entry_t * 
+static inline debug_entry_t * 
 debug_long_exception (debug_info_t* id, int level, unsigned long tag)
 {
         unsigned long t=tag;
@@ -186,7 +186,7 @@
         return debug_exception_common(id,level,&t,sizeof(unsigned long));
 }
 
-extern inline debug_entry_t* 
+static inline debug_entry_t* 
 debug_text_exception(debug_info_t* id, int level, const char* txt)
 {
 	if ((!id) || (level > id->level)) return NULL;
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/ebcdic.h linux-2.4.25-kdb-trace/include/asm-s390x/ebcdic.h
--- linux-2.4.25-kdb/include/asm-s390x/ebcdic.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/ebcdic.h	2005-01-05 16:45:41.000000000 +0100
@@ -21,7 +21,7 @@
 extern __u8 _ebc_tolower[]; /* EBCDIC -> lowercase */
 extern __u8 _ebc_toupper[]; /* EBCDIC -> uppercase */
 
-extern __inline__ void
+static __inline__ void
 codepage_convert(const __u8 *codepage, volatile __u8 * addr, unsigned long nr)
 {
 	if (nr-- <= 0)
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/io.h linux-2.4.25-kdb-trace/include/asm-s390x/io.h
--- linux-2.4.25-kdb/include/asm-s390x/io.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/io.h	2005-01-05 16:45:41.000000000 +0100
@@ -24,7 +24,7 @@
  * Change virtual addresses to physical addresses and vv.
  * These are pretty trivial
  */
-extern inline unsigned long virt_to_phys(volatile void * address)
+static inline unsigned long virt_to_phys(volatile void * address)
 {
 	unsigned long real_address;
 	__asm__ ("   lrag   %0,0(%1)\n"
@@ -35,7 +35,7 @@
         return real_address;
 }
 
-extern inline void * phys_to_virt(unsigned long address)
+static inline void * phys_to_virt(unsigned long address)
 {
         return __io_virt(address);
 }
@@ -47,7 +47,7 @@
 
 extern void * __ioremap(unsigned long offset, unsigned long size, unsigned long flags);
 
-extern inline void * ioremap (unsigned long offset, unsigned long size)
+static inline void * ioremap (unsigned long offset, unsigned long size)
 {
         return __ioremap(offset, size, 0);
 }
@@ -57,7 +57,7 @@
  * it's useful if some control registers are in such an area and write combining
  * or read caching is not desirable:
  */
-extern inline void * ioremap_nocache (unsigned long offset, unsigned long size)
+static inline void * ioremap_nocache (unsigned long offset, unsigned long size)
 {
         return __ioremap(offset, size, 0);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/irq.h linux-2.4.25-kdb-trace/include/asm-s390x/irq.h
--- linux-2.4.25-kdb/include/asm-s390x/irq.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/irq.h	2005-01-05 16:45:41.000000000 +0100
@@ -668,7 +668,7 @@
  * Some S390 specific IO instructions as inline
  */
 
-extern __inline__ int stsch(int irq, volatile schib_t *addr)
+static __inline__ int stsch(int irq, volatile schib_t *addr)
 {
         int ccode;
 
@@ -683,7 +683,7 @@
         return ccode;
 }
 
-extern __inline__ int msch(int irq, volatile schib_t *addr)
+static __inline__ int msch(int irq, volatile schib_t *addr)
 {
         int ccode;
 
@@ -698,7 +698,7 @@
         return ccode;
 }
 
-extern __inline__ int msch_err(int irq, volatile schib_t *addr)
+static __inline__ int msch_err(int irq, volatile schib_t *addr)
 {
         int ccode;
 
@@ -736,7 +736,7 @@
         return ccode;
 }
 
-extern __inline__ int tsch(int irq, volatile irb_t *addr)
+static __inline__ int tsch(int irq, volatile irb_t *addr)
 {
         int ccode;
 
@@ -751,7 +751,7 @@
         return ccode;
 }
 
-extern __inline__ int tpi( volatile tpi_info_t *addr)
+static __inline__ int tpi( volatile tpi_info_t *addr)
 {
         int ccode;
 
@@ -765,7 +765,7 @@
         return ccode;
 }
 
-extern __inline__ int ssch(int irq, volatile orb_t *addr)
+static __inline__ int ssch(int irq, volatile orb_t *addr)
 {
         int ccode;
 
@@ -780,7 +780,7 @@
         return ccode;
 }
 
-extern __inline__ int diag98(int irq, volatile orb_t *addr)
+static __inline__ int diag98(int irq, volatile orb_t *addr)
 {
         int ccode;
 
@@ -799,7 +799,7 @@
         return ccode;
 }
 
-extern __inline__ int rsch(int irq)
+static __inline__ int rsch(int irq)
 {
         int ccode;
 
@@ -814,7 +814,7 @@
         return ccode;
 }
 
-extern __inline__ int csch(int irq)
+static __inline__ int csch(int irq)
 {
         int ccode;
 
@@ -829,7 +829,7 @@
         return ccode;
 }
 
-extern __inline__ int hsch(int irq)
+static __inline__ int hsch(int irq)
 {
         int ccode;
 
@@ -844,7 +844,7 @@
         return ccode;
 }
 
-extern __inline__ int xsch(int irq)
+static __inline__ int xsch(int irq)
 {
 	int ccode;
 	
@@ -859,7 +859,7 @@
 	return ccode;
 }
 
-extern __inline__ int iac( void)
+static __inline__ int iac( void)
 {
         int ccode;
 
@@ -871,7 +871,7 @@
         return ccode;
 }
 
-extern __inline__ int rchp(int chpid)
+static __inline__ int rchp(int chpid)
 {
         int ccode;
 
@@ -904,7 +904,7 @@
 
 extern int diag210( diag210_t * addr);
 
-extern __inline__ int chsc( chsc_area_t * chsc_area)
+static __inline__ int chsc( chsc_area_t * chsc_area)
 {
 	int cc;
 	
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/lowcore.h linux-2.4.25-kdb-trace/include/asm-s390x/lowcore.h
--- linux-2.4.25-kdb/include/asm-s390x/lowcore.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/lowcore.h	2005-01-05 16:45:41.000000000 +0100
@@ -194,7 +194,7 @@
 	__u8         pad17[0x2000-0x1400];      /* 0x1400 */
 } __attribute__((packed)); /* End structure*/
 
-extern __inline__ void set_prefix(__u32 address)
+static __inline__ void set_prefix(__u32 address)
 {
         __asm__ __volatile__ ("spx %0" : : "m" (address) : "memory" );
 }
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/mmu_context.h linux-2.4.25-kdb-trace/include/asm-s390x/mmu_context.h
--- linux-2.4.25-kdb/include/asm-s390x/mmu_context.h	2001-02-13 23:13:44.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/mmu_context.h	2005-01-05 16:45:41.000000000 +0100
@@ -36,7 +36,7 @@
 	set_bit(cpu, &next->cpu_vm_mask);
 }
 
-extern inline void activate_mm(struct mm_struct *prev,
+static inline void activate_mm(struct mm_struct *prev,
                                struct mm_struct *next)
 {
         switch_mm(prev, next, current, smp_processor_id());
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/page.h linux-2.4.25-kdb-trace/include/asm-s390x/page.h
--- linux-2.4.25-kdb/include/asm-s390x/page.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/page.h	2005-01-05 16:45:41.000000000 +0100
@@ -70,7 +70,7 @@
 } while (0)                      
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
         int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/pgalloc.h linux-2.4.25-kdb-trace/include/asm-s390x/pgalloc.h
--- linux-2.4.25-kdb/include/asm-s390x/pgalloc.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/pgalloc.h	2005-01-05 16:45:41.000000000 +0100
@@ -34,7 +34,7 @@
 /*
  * page directory allocation/free routines.
  */
-extern __inline__ pgd_t *get_pgd_slow (void)
+static __inline__ pgd_t *get_pgd_slow (void)
 {
 	pgd_t *ret;
         int i;
@@ -46,7 +46,7 @@
 	return ret;
 }
 
-extern __inline__ pgd_t *get_pgd_fast (void)
+static __inline__ pgd_t *get_pgd_fast (void)
 {
 	unsigned long *ret = pgd_quicklist;
 
@@ -58,7 +58,7 @@
 	return (pgd_t *) ret;
 }
 
-extern __inline__ pgd_t *pgd_alloc (struct mm_struct *mm)
+static __inline__ pgd_t *pgd_alloc (struct mm_struct *mm)
 {
 	pgd_t *pgd;
 
@@ -68,14 +68,14 @@
 	return pgd;
 }
 
-extern __inline__ void free_pgd_fast (pgd_t *pgd)
+static __inline__ void free_pgd_fast (pgd_t *pgd)
 {
 	*(unsigned long *) pgd = (unsigned long) pgd_quicklist;
 	pgd_quicklist = (unsigned long *) pgd;
 	pgtable_cache_size += 2;
 }
 
-extern __inline__ void free_pgd_slow (pgd_t *pgd)
+static __inline__ void free_pgd_slow (pgd_t *pgd)
 {
 	free_pages((unsigned long) pgd, 1);
 }
@@ -87,7 +87,7 @@
 /*
  * page middle directory allocation/free routines.
  */
-extern inline pmd_t * pmd_alloc_one(struct mm_struct *mm, unsigned long vmaddr)
+static inline pmd_t * pmd_alloc_one(struct mm_struct *mm, unsigned long vmaddr)
 {
 	pmd_t *pmd;
         int i;
@@ -100,7 +100,7 @@
 	return pmd;
 }
 
-extern __inline__ pmd_t *
+static __inline__ pmd_t *
 pmd_alloc_one_fast(struct mm_struct *mm, unsigned long address)
 {
 	unsigned long *ret = (unsigned long *) pmd_quicklist;
@@ -114,7 +114,7 @@
 }
 
 extern void pmd_free_order2(pmd_t *);
-extern __inline__ void pmd_free_fast (pmd_t *pmd)
+static __inline__ void pmd_free_fast (pmd_t *pmd)
 {
 	if (test_bit(PG_arch_1, &virt_to_page(pmd)->flags) == 0) {
 		*(unsigned long *) pmd = (unsigned long) pmd_quicklist;
@@ -124,14 +124,14 @@
 		pmd_free_order2(pmd);
 }
 
-extern __inline__ void pmd_free_slow (pmd_t *pmd)
+static __inline__ void pmd_free_slow (pmd_t *pmd)
 {
 	free_pages((unsigned long) pmd, 1);
 }
 
 #define pmd_free(pmd)		pmd_free_fast(pmd)
 
-extern inline void pmd_populate(struct mm_struct *mm, pmd_t *pmd, pte_t *pte)
+static inline void pmd_populate(struct mm_struct *mm, pmd_t *pmd, pte_t *pte)
 {
 	pmd_val(*pmd) = _PMD_ENTRY | __pa(pte);
 	pmd_val1(*pmd) = _PMD_ENTRY | __pa(pte+256);
@@ -140,7 +140,7 @@
 /*
  * page table entry allocation/free routines.
  */
-extern inline pte_t * pte_alloc_one(struct mm_struct *mm, unsigned long vmaddr)
+static inline pte_t * pte_alloc_one(struct mm_struct *mm, unsigned long vmaddr)
 {
 	pte_t *pte;
         int i;
@@ -153,7 +153,7 @@
 	return pte;
 }
 
-extern __inline__ pte_t* pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
+static __inline__ pte_t* pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
 {
         unsigned long *ret = (unsigned long *) pte_quicklist;
 
@@ -165,14 +165,14 @@
         return (pte_t *)ret;
 }
 
-extern __inline__ void pte_free_fast (pte_t *pte)
+static __inline__ void pte_free_fast (pte_t *pte)
 {
 	*(unsigned long *) pte = (unsigned long) pte_quicklist;
 	pte_quicklist = (unsigned long *) pte;
 	pgtable_cache_size++;
 }
 
-extern __inline__ void pte_free_slow (pte_t *pte)
+static __inline__ void pte_free_slow (pte_t *pte)
 {
         free_page((unsigned long) pte);
 }
@@ -304,7 +304,7 @@
 
 #endif
 
-extern inline void flush_tlb_pgtables(struct mm_struct *mm,
+static inline void flush_tlb_pgtables(struct mm_struct *mm,
                                       unsigned long start, unsigned long end)
 {
         /* S/390 does not keep any page table caches in TLB */
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/pgtable.h linux-2.4.25-kdb-trace/include/asm-s390x/pgtable.h
--- linux-2.4.25-kdb/include/asm-s390x/pgtable.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/pgtable.h	2005-01-05 16:45:41.000000000 +0100
@@ -224,7 +224,7 @@
  * within a page table are directly modified.  Thus, the following
  * hook is made available.
  */
-extern inline void set_pte(pte_t *pteptr, pte_t pteval)
+static inline void set_pte(pte_t *pteptr, pte_t pteval)
 {
 	*pteptr = pteval;
 }
@@ -234,7 +234,7 @@
 /*
  * pgd/pmd/pte query functions
  */
-extern inline int __pgd_present(pgd_t *pgd)
+static inline int __pgd_present(pgd_t *pgd)
 {
 	unsigned long addr = (unsigned long) pgd;
 	unsigned long *pgd_slot = (unsigned long *) (addr & -8);
@@ -250,13 +250,13 @@
 }
 #define pgd_present(pgd) __pgd_present(&(pgd))
 
-extern inline int __pgd_none(pgd_t *pgd)
+static inline int __pgd_none(pgd_t *pgd)
 {
 	return !__pgd_present(pgd);
 }
 #define pgd_none(pgd) __pgd_none(&(pgd))
 
-extern inline int __pgd_bad(pgd_t *pgd)
+static inline int __pgd_bad(pgd_t *pgd)
 {
 	unsigned long addr = (unsigned long) pgd;
 	unsigned long *pgd_slot = (unsigned long *) (addr & -8);
@@ -266,27 +266,27 @@
 }
 #define pgd_bad(pgd) __pgd_bad(&(pgd))
 
-extern inline int pmd_present(pmd_t pmd)
+static inline int pmd_present(pmd_t pmd)
 {
 	return (pmd_val(pmd) & ~PAGE_MASK) == _PMD_ENTRY;
 }
 
-extern inline int pmd_none(pmd_t pmd)
+static inline int pmd_none(pmd_t pmd)
 {
 	return pmd_val(pmd) & _PMD_ENTRY_INV;
 }
 
-extern inline int pmd_bad(pmd_t pmd)
+static inline int pmd_bad(pmd_t pmd)
 {
 	return (pmd_val(pmd) & (~PAGE_MASK & ~_PMD_ENTRY_INV)) != _PMD_ENTRY;
 }
 
-extern inline int pte_present(pte_t pte)
+static inline int pte_present(pte_t pte)
 {
 	return pte_val(pte) & _PAGE_PRESENT;
 }
 
-extern inline int pte_none(pte_t pte)
+static inline int pte_none(pte_t pte)
 {
 	return ((pte_val(pte) & 
 		 (_PAGE_INVALID | _PAGE_RO | _PAGE_PRESENT)) == _PAGE_INVALID);
@@ -298,12 +298,12 @@
  * query functions pte_write/pte_dirty/pte_young only work if
  * pte_present() is true. Undefined behaviour if not..
  */
-extern inline int pte_write(pte_t pte)
+static inline int pte_write(pte_t pte)
 {
 	return (pte_val(pte) & _PAGE_RO) == 0;
 }
 
-extern inline int pte_dirty(pte_t pte)
+static inline int pte_dirty(pte_t pte)
 {
 	int skey;
 
@@ -313,7 +313,7 @@
 	return skey & _PAGE_CHANGED;
 }
 
-extern inline int pte_young(pte_t pte)
+static inline int pte_young(pte_t pte)
 {
 	int skey;
 
@@ -324,7 +324,7 @@
 /*
  * pgd/pmd/pte modification functions
  */
-extern inline void pgd_clear(pgd_t * pgdp)
+static inline void pgd_clear(pgd_t * pgdp)
 {
 	unsigned long addr = (unsigned long) pgdp;
 	unsigned long *pgd_slot = (unsigned long *) (addr & -8);
@@ -349,13 +349,13 @@
 	*pgd_slot = _PGD_ENTRY_INV;
 }
 
-extern inline void pmd_clear(pmd_t * pmdp)
+static inline void pmd_clear(pmd_t * pmdp)
 {
 	pmd_val(*pmdp) = _PMD_ENTRY_INV | _PMD_ENTRY;
 	pmd_val1(*pmdp) = _PMD_ENTRY_INV | _PMD_ENTRY;
 }
 
-extern inline void pte_clear(pte_t *ptep)
+static inline void pte_clear(pte_t *ptep)
 {
 	pte_val(*ptep) = _PAGE_INVALID;
 }
@@ -366,26 +366,26 @@
  * The following pte_modification functions only work if 
  * pte_present() is true. Undefined behaviour if not..
  */
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 {
 	pte_val(pte) &= PAGE_MASK | _PAGE_ISCLEAN;
 	pte_val(pte) |= pgprot_val(newprot) & ~_PAGE_ISCLEAN;
 	return pte; 
 }
 
-extern inline pte_t pte_wrprotect(pte_t pte)
+static inline pte_t pte_wrprotect(pte_t pte)
 {
 	pte_val(pte) |= _PAGE_RO;
 	return pte;
 }
 
-extern inline pte_t pte_mkwrite(pte_t pte)
+static inline pte_t pte_mkwrite(pte_t pte)
 {
 	pte_val(pte) &= ~(_PAGE_RO | _PAGE_ISCLEAN);
 	return pte;
 }
 
-extern inline pte_t pte_mkclean(pte_t pte)
+static inline pte_t pte_mkclean(pte_t pte)
 {
 	/* The only user of pte_mkclean is the fork() code.
 	   We must *not* clear the *physical* page dirty bit
@@ -394,7 +394,7 @@
 	return pte;
 }
 
-extern inline pte_t pte_mkdirty(pte_t pte)
+static inline pte_t pte_mkdirty(pte_t pte)
 { 
 	/* We do not explicitly set the dirty bit because the
 	 * sske instruction is slow. It is faster to let the
@@ -404,13 +404,13 @@
 	return pte;
 }
 
-extern inline pte_t pte_mkold(pte_t pte)
+static inline pte_t pte_mkold(pte_t pte)
 {
 	asm volatile ("rrbe 0,%0" : : "a" (pte_val(pte)) : "cc" );
 	return pte;
 }
 
-extern inline pte_t pte_mkyoung(pte_t pte)
+static inline pte_t pte_mkyoung(pte_t pte)
 {
 	/* To set the referenced bit we read the first word from the real
 	 * page with a special instruction: load using real address (lura).
@@ -468,7 +468,7 @@
  * Conversion functions: convert a page and protection to a page entry,
  * and a page entry and page directory to the page they refer to.
  */
-extern inline pte_t mk_pte_phys(unsigned long physpage, pgprot_t pgprot)
+static inline pte_t mk_pte_phys(unsigned long physpage, pgprot_t pgprot)
 {
 	pte_t __pte;
 	pte_val(__pte) = physpage + pgprot_val(pgprot);
@@ -530,7 +530,7 @@
  * 0000000000111111111122222222223333333333444444444455555555556666
  * 0123456789012345678901234567890123456789012345678901234567890123
  */
-extern inline pte_t mk_swap_pte(unsigned long type, unsigned long offset)
+static inline pte_t mk_swap_pte(unsigned long type, unsigned long offset)
 {
 	pte_t pte;
 	pte_val(pte) = (type << 1) | (offset << 12) | _PAGE_INVALID | _PAGE_RO;
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/processor.h linux-2.4.25-kdb-trace/include/asm-s390x/processor.h
--- linux-2.4.25-kdb/include/asm-s390x/processor.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/processor.h	2005-01-05 16:45:41.000000000 +0100
@@ -142,7 +142,7 @@
  * schedule, so we have to walk the backchain one time to
  * find the frame schedule() store its return address.
  */
-extern inline unsigned long thread_saved_pc(struct thread_struct *t)
+static inline unsigned long thread_saved_pc(struct thread_struct *t)
 {
 	unsigned long bc;
 	bc = *((unsigned long *) t->ksp);
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/s390mach.h linux-2.4.25-kdb-trace/include/asm-s390x/s390mach.h
--- linux-2.4.25-kdb/include/asm-s390x/s390mach.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/s390mach.h	2005-01-05 16:45:41.000000000 +0100
@@ -103,7 +103,7 @@
 void s390_do_machine_check  ( void );
 void s390_do_crw_pending    ( crwe_t *pcrwe );
 
-extern __inline__ int stcrw( __u32 *pcrw )
+static __inline__ int stcrw( __u32 *pcrw )
 {
         int ccode;
 
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/sigp.h linux-2.4.25-kdb-trace/include/asm-s390x/sigp.h
--- linux-2.4.25-kdb/include/asm-s390x/sigp.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/sigp.h	2005-01-05 16:45:41.000000000 +0100
@@ -67,7 +67,7 @@
 /*
  * Signal processor
  */
-extern __inline__ sigp_ccode
+static __inline__ sigp_ccode
 signal_processor(__u16 cpu_addr, sigp_order_code order_code)
 {
 	sigp_ccode ccode;
@@ -86,7 +86,7 @@
 /*
  * Signal processor with parameter
  */
-extern __inline__ sigp_ccode
+static __inline__ sigp_ccode
 signal_processor_p(__u64 parameter,__u16 cpu_addr,sigp_order_code order_code)
 {
 	sigp_ccode ccode;
@@ -106,7 +106,7 @@
 /*
  * Signal processor with parameter and return status
  */
-extern __inline__ sigp_ccode
+static __inline__ sigp_ccode
 signal_processor_ps(__u32 *statusptr, __u64 parameter,
 		    __u16 cpu_addr, sigp_order_code order_code)
 {
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/smp.h linux-2.4.25-kdb-trace/include/asm-s390x/smp.h
--- linux-2.4.25-kdb/include/asm-s390x/smp.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/smp.h	2005-01-05 16:45:41.000000000 +0100
@@ -44,17 +44,17 @@
 
 #define smp_processor_id() (current->processor)
 
-extern __inline__ int cpu_logical_map(int cpu)
+static __inline__ int cpu_logical_map(int cpu)
 {
         return cpu;
 }
 
-extern __inline__ int cpu_number_map(int cpu)
+static __inline__ int cpu_number_map(int cpu)
 {
         return cpu;
 }
 
-extern __inline__ __u16 hard_smp_processor_id(void)
+static __inline__ __u16 hard_smp_processor_id(void)
 {
         __u16 cpu_address;
  
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/smplock.h linux-2.4.25-kdb-trace/include/asm-s390x/smplock.h
--- linux-2.4.25-kdb/include/asm-s390x/smplock.h	2001-02-13 23:13:44.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/smplock.h	2005-01-05 16:45:41.000000000 +0100
@@ -48,13 +48,13 @@
  * so we only need to worry about other
  * CPU's.
  */
-extern __inline__ void lock_kernel(void)
+static __inline__ void lock_kernel(void)
 {
         if (!++current->lock_depth)
                 spin_lock(&kernel_flag);
 }
 
-extern __inline__ void unlock_kernel(void)
+static __inline__ void unlock_kernel(void)
 {
         if (--current->lock_depth < 0)
                 spin_unlock(&kernel_flag);
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/spinlock.h linux-2.4.25-kdb-trace/include/asm-s390x/spinlock.h
--- linux-2.4.25-kdb/include/asm-s390x/spinlock.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-s390x/spinlock.h	2005-01-05 16:45:41.000000000 +0100
@@ -41,7 +41,7 @@
 #define spin_unlock_wait(lp)	do { barrier(); } while(((volatile spinlock_t *)(lp))->lock)
 #define spin_is_locked(x) ((x)->lock != 0)
 
-extern inline void spin_lock(spinlock_t *lp)
+static inline void spin_lock(spinlock_t *lp)
 {
 	unsigned long reg1, reg2;
         __asm__ __volatile("    bras  %1,1f\n"
@@ -54,7 +54,7 @@
 			   : "cc", "memory" );
 }
 
-extern inline int spin_trylock(spinlock_t *lp)
+static inline int spin_trylock(spinlock_t *lp)
 {
 	unsigned int result, reg;
 	__asm__ __volatile("    slr   %0,%0\n"
@@ -65,7 +65,7 @@
 	return !result;
 }
 
-extern inline void spin_unlock(spinlock_t *lp)
+static inline void spin_unlock(spinlock_t *lp)
 {
 	__asm__ __volatile("    xc 0(4,%0),0(%0)\n"
                            "    bcr 15,0"
diff -rbNu linux-2.4.25-kdb/include/asm-s390x/uaccess.h linux-2.4.25-kdb-trace/include/asm-s390x/uaccess.h
--- linux-2.4.25-kdb/include/asm-s390x/uaccess.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-s390x/uaccess.h	2005-01-05 16:45:41.000000000 +0100
@@ -46,7 +46,7 @@
 
 #define access_ok(type,addr,size) __access_ok(addr,size)
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
         return access_ok(type,addr,size)?0:-EFAULT;
 }
@@ -78,7 +78,7 @@
  * use the right size if we just have the right pointer type.
  */
 
-extern inline int __put_user_asm_8(__u64 x, void *ptr)
+static inline int __put_user_asm_8(__u64 x, void *ptr)
 {
         int err;
 
@@ -100,7 +100,7 @@
                                 : "cc", "4" );
         return err;
 }
-extern inline int __put_user_asm_4(__u32 x, void *ptr)
+static inline int __put_user_asm_4(__u32 x, void *ptr)
 {
         int err;
 
@@ -123,7 +123,7 @@
         return err;
 }
 
-extern inline int __put_user_asm_2(__u16 x, void *ptr)
+static inline int __put_user_asm_2(__u16 x, void *ptr)
 {
         int err;
 
@@ -146,7 +146,7 @@
         return err;
 }
 
-extern inline int __put_user_asm_1(__u8 x, void *ptr)
+static inline int __put_user_asm_1(__u8 x, void *ptr)
 {
         int err;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/checksum.h linux-2.4.25-kdb-trace/include/asm-sh64/checksum.h
--- linux-2.4.25-kdb/include/asm-sh64/checksum.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/checksum.h	2005-01-05 16:45:34.000000000 +0100
@@ -50,7 +50,7 @@
 
 asmlinkage unsigned int csum_partial_copy_generic( const char *src, char *dst, int len, int sum,
 						   int *src_err_ptr, int *dst_err_ptr);
-extern __inline__
+static __inline__
 unsigned int csum_partial_copy_nocheck ( const char *src, char *dst,
 					int len, int sum)
 {
@@ -66,7 +66,7 @@
 
 #ifdef DJM_USE_ASM_CHECKSUM
 
-extern __inline__
+static __inline__
 unsigned int csum_partial_copy_from_user ( const char *src, char *dst,
 						int len, unsigned int sum, int *err_ptr)
 {
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/io.h linux-2.4.25-kdb-trace/include/asm-sh64/io.h
--- linux-2.4.25-kdb/include/asm-sh64/io.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/io.h	2005-01-05 16:45:34.000000000 +0100
@@ -113,12 +113,12 @@
  * Change virtual addresses to physical addresses and vv.
  * These are trivial on the 1:1 Linux/SuperH mapping
  */
-extern __inline__ unsigned long virt_to_phys(volatile void * address)
+static __inline__ unsigned long virt_to_phys(volatile void * address)
 {
 	return __pa(address);
 }
 
-extern __inline__ void * phys_to_virt(unsigned long address)
+static __inline__ void * phys_to_virt(unsigned long address)
 {
 	return __va(address);
 }
@@ -126,12 +126,12 @@
 extern void * __ioremap(unsigned long phys_addr, unsigned long size,
 			unsigned long flags);
 
-extern __inline__ void * ioremap(unsigned long phys_addr, unsigned long size)
+static __inline__ void * ioremap(unsigned long phys_addr, unsigned long size)
 {
 	return __ioremap(phys_addr, size, 1);
 }
 	
-extern __inline__ void * ioremap_nocache (unsigned long phys_addr, unsigned long size)
+static __inline__ void * ioremap_nocache (unsigned long phys_addr, unsigned long size)
 {
 	return __ioremap(phys_addr, size, 0);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/mmu_context.h linux-2.4.25-kdb-trace/include/asm-sh64/mmu_context.h
--- linux-2.4.25-kdb/include/asm-sh64/mmu_context.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/mmu_context.h	2005-01-05 16:45:34.000000000 +0100
@@ -50,7 +50,7 @@
  */
 #define MMU_VPN_MASK	0xfffff000
 
-extern __inline__ void
+static __inline__ void
 get_new_mmu_context(struct mm_struct *mm)
 {
 	extern void flush_tlb_all(void);
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/page.h linux-2.4.25-kdb-trace/include/asm-sh64/page.h
--- linux-2.4.25-kdb/include/asm-sh64/page.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/page.h	2005-01-05 16:45:34.000000000 +0100
@@ -105,7 +105,7 @@
 } while (0)
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
 	int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/pci.h linux-2.4.25-kdb-trace/include/asm-sh64/pci.h
--- linux-2.4.25-kdb/include/asm-sh64/pci.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sh64/pci.h	2005-01-05 16:45:34.000000000 +0100
@@ -243,7 +243,7 @@
 ** only drive the low 24-bits during PCI bus mastering, then
 ** you would pass 0x00ffffff as the mask to this function.
 */
-extern inline int pci_dma_supported(struct pci_dev *hwdev, dma_addr_t mask)
+static inline int pci_dma_supported(struct pci_dev *hwdev, dma_addr_t mask)
 {
 	return 1;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/pgtable.h linux-2.4.25-kdb-trace/include/asm-sh64/pgtable.h
--- linux-2.4.25-kdb/include/asm-sh64/pgtable.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/pgtable.h	2005-01-05 16:45:34.000000000 +0100
@@ -432,23 +432,23 @@
 /*
  * The following have defined behavior only work if pte_present() is true.
  */
-extern inline int pte_read(pte_t pte) { return pte_val(pte) & _PAGE_READ; }
-extern inline int pte_exec(pte_t pte) { return pte_val(pte) & _PAGE_EXECUTE; }
-extern inline int pte_dirty(pte_t pte){ return pte_val(pte) & _PAGE_DIRTY; }
-extern inline int pte_young(pte_t pte){ return pte_val(pte) & _PAGE_ACCESSED; }
-extern inline int pte_write(pte_t pte){ return pte_val(pte) & _PAGE_WRITE; }
-
-extern inline pte_t pte_rdprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_READ)); return pte; }
-extern inline pte_t pte_wrprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_WRITE)); return pte; }
-extern inline pte_t pte_exprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_EXECUTE)); return pte; }
-extern inline pte_t pte_mkclean(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_DIRTY)); return pte; }
-extern inline pte_t pte_mkold(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_ACCESSED)); return pte; }
-
-extern inline pte_t pte_mkread(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_READ)); return pte; }
-extern inline pte_t pte_mkwrite(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_WRITE)); return pte; }
-extern inline pte_t pte_mkexec(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_EXECUTE)); return pte; }
-extern inline pte_t pte_mkdirty(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_DIRTY)); return pte; }
-extern inline pte_t pte_mkyoung(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_ACCESSED)); return pte; }
+static inline int pte_read(pte_t pte) { return pte_val(pte) & _PAGE_READ; }
+static inline int pte_exec(pte_t pte) { return pte_val(pte) & _PAGE_EXECUTE; }
+static inline int pte_dirty(pte_t pte){ return pte_val(pte) & _PAGE_DIRTY; }
+static inline int pte_young(pte_t pte){ return pte_val(pte) & _PAGE_ACCESSED; }
+static inline int pte_write(pte_t pte){ return pte_val(pte) & _PAGE_WRITE; }
+
+static inline pte_t pte_rdprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_READ)); return pte; }
+static inline pte_t pte_wrprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_WRITE)); return pte; }
+static inline pte_t pte_exprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_EXECUTE)); return pte; }
+static inline pte_t pte_mkclean(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_DIRTY)); return pte; }
+static inline pte_t pte_mkold(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_ACCESSED)); return pte; }
+
+static inline pte_t pte_mkread(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_READ)); return pte; }
+static inline pte_t pte_mkwrite(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_WRITE)); return pte; }
+static inline pte_t pte_mkexec(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_EXECUTE)); return pte; }
+static inline pte_t pte_mkdirty(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_DIRTY)); return pte; }
+static inline pte_t pte_mkyoung(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_ACCESSED)); return pte; }
 
 /*
  * Conversion functions: convert a page and protection to a page entry.
@@ -471,7 +471,7 @@
 #define mk_pte_phys(physpage, pgprot) \
 ({ pte_t __pte; set_pte(&__pte, __pte(physpage | pgprot_val(pgprot))); __pte; })
 
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 { set_pte(&pte, __pte((pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot))); return pte; }
 
 #define page_pte_prot(page, prot) mk_pte(page, prot)
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/processor.h linux-2.4.25-kdb-trace/include/asm-sh64/processor.h
--- linux-2.4.25-kdb/include/asm-sh64/processor.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sh64/processor.h	2005-01-05 16:45:34.000000000 +0100
@@ -210,7 +210,7 @@
  * FPU lazy state save handling.
  */
 
-extern __inline__ void release_fpu(void)
+static __inline__ void release_fpu(void)
 {
 	unsigned long long __dummy;
 
@@ -222,7 +222,7 @@
 			     : "r" (SR_FD));
 }
 
-extern __inline__ void grab_fpu(void)
+static __inline__ void grab_fpu(void)
 {
 	unsigned long long __dummy;
 
@@ -252,7 +252,7 @@
 /*
  * Return saved PC of a blocked thread.
  */
-extern __inline__ unsigned long thread_saved_pc(struct thread_struct *t)
+static __inline__ unsigned long thread_saved_pc(struct thread_struct *t)
 {
 	return t->pc;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/smplock.h linux-2.4.25-kdb-trace/include/asm-sh64/smplock.h
--- linux-2.4.25-kdb/include/asm-sh64/smplock.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/smplock.h	2005-01-05 16:45:34.000000000 +0100
@@ -40,13 +40,13 @@
  * so we only need to worry about other
  * CPU's.
  */
-extern __inline__ void lock_kernel(void)
+static __inline__ void lock_kernel(void)
 {
 	if (!++current->lock_depth)
 		spin_lock(&kernel_flag);
 }
 
-extern __inline__ void unlock_kernel(void)
+static __inline__ void unlock_kernel(void)
 {
 	if (--current->lock_depth < 0)
 		spin_unlock(&kernel_flag);
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/system.h linux-2.4.25-kdb-trace/include/asm-sh64/system.h
--- linux-2.4.25-kdb/include/asm-sh64/system.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/system.h	2005-01-05 16:45:34.000000000 +0100
@@ -269,7 +269,7 @@
 #define SR_MASK_LL 0x0000000010000000LL
 #endif
 
-extern __inline__ void __sti(void)
+static __inline__ void __sti(void)
 {
 	/* cli/sti based on SR.BL */
 	unsigned long long __dummy0, __dummy1=~SR_MASK_LL;
@@ -281,7 +281,7 @@
 			     : "r" (__dummy1));
 }
 
-extern __inline__ void __cli(void)
+static __inline__ void __cli(void)
 {
 	/* cli/sti based on SR.BL */
 	unsigned long long __dummy0, __dummy1=SR_MASK_LL;
@@ -348,7 +348,7 @@
 
 #endif
 
-extern __inline__ unsigned long xchg_u32(volatile int * m, unsigned long val)
+static __inline__ unsigned long xchg_u32(volatile int * m, unsigned long val)
 {
 	unsigned long flags, retval;
 
@@ -359,7 +359,7 @@
 	return retval;
 }
 
-extern __inline__ unsigned long xchg_u8(volatile unsigned char * m, unsigned long val)
+static __inline__ unsigned long xchg_u8(volatile unsigned char * m, unsigned long val)
 {
 	unsigned long flags, retval;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sh64/uaccess.h linux-2.4.25-kdb-trace/include/asm-sh64/uaccess.h
--- linux-2.4.25-kdb/include/asm-sh64/uaccess.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sh64/uaccess.h	2005-01-05 16:45:34.000000000 +0100
@@ -59,7 +59,7 @@
 #define access_ok(type,addr,size) (__range_ok(addr,size) == 0)
 #define __access_ok(addr,size) (__range_ok(addr,size) == 0)
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
 	return access_ok(type,addr,size) ? 0 : -EFAULT;
 }
@@ -263,7 +263,7 @@
  */
 extern long __strnlen_user(const char *__s, long __n);
 
-extern __inline__ long strnlen_user(const char *s, long n)
+static __inline__ long strnlen_user(const char *s, long n)
 {
 	if (!__addr_ok(s))
 		return 0;
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/btfixup.h linux-2.4.25-kdb-trace/include/asm-sparc/btfixup.h
--- linux-2.4.25-kdb/include/asm-sparc/btfixup.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/btfixup.h	2005-01-05 16:45:36.000000000 +0100
@@ -51,7 +51,7 @@
 #define BTFIXUPDEF_SIMM13(__name)							\
 	extern unsigned int ___sf_##__name(void) __attribute__((const));		\
 	extern unsigned ___ss_##__name[2];						\
-	extern __inline__ unsigned int ___sf_##__name(void) {				\
+	static __inline__ unsigned int ___sf_##__name(void) {				\
 		unsigned int ret;							\
 		__asm__ ("or %%g0, ___s_" #__name ", %0" : "=r"(ret));			\
 		return ret;								\
@@ -59,7 +59,7 @@
 #define BTFIXUPDEF_SIMM13_INIT(__name,__val)						\
 	extern unsigned int ___sf_##__name(void) __attribute__((const));		\
 	extern unsigned ___ss_##__name[2];						\
-	extern __inline__ unsigned int ___sf_##__name(void) {				\
+	static __inline__ unsigned int ___sf_##__name(void) {				\
 		unsigned int ret;							\
 		__asm__ ("or %%g0, ___s_" #__name "__btset_" #__val ", %0" : "=r"(ret));\
 		return ret;								\
@@ -73,7 +73,7 @@
 #define BTFIXUPDEF_HALF(__name)								\
 	extern unsigned int ___af_##__name(void) __attribute__((const));		\
 	extern unsigned ___as_##__name[2];						\
-	extern __inline__ unsigned int ___af_##__name(void) {				\
+	static __inline__ unsigned int ___af_##__name(void) {				\
 		unsigned int ret;							\
 		__asm__ ("or %%g0, ___a_" #__name ", %0" : "=r"(ret));			\
 		return ret;								\
@@ -81,7 +81,7 @@
 #define BTFIXUPDEF_HALF_INIT(__name,__val)						\
 	extern unsigned int ___af_##__name(void) __attribute__((const));		\
 	extern unsigned ___as_##__name[2];						\
-	extern __inline__ unsigned int ___af_##__name(void) {				\
+	static __inline__ unsigned int ___af_##__name(void) {				\
 		unsigned int ret;							\
 		__asm__ ("or %%g0, ___a_" #__name "__btset_" #__val ", %0" : "=r"(ret));\
 		return ret;								\
@@ -92,7 +92,7 @@
 #define BTFIXUPDEF_SETHI(__name)							\
 	extern unsigned int ___hf_##__name(void) __attribute__((const));		\
 	extern unsigned ___hs_##__name[2];						\
-	extern __inline__ unsigned int ___hf_##__name(void) {				\
+	static __inline__ unsigned int ___hf_##__name(void) {				\
 		unsigned int ret;							\
 		__asm__ ("sethi %%hi(___h_" #__name "), %0" : "=r"(ret));		\
 		return ret;								\
@@ -100,7 +100,7 @@
 #define BTFIXUPDEF_SETHI_INIT(__name,__val)						\
 	extern unsigned int ___hf_##__name(void) __attribute__((const));		\
 	extern unsigned ___hs_##__name[2];						\
-	extern __inline__ unsigned int ___hf_##__name(void) {				\
+	static __inline__ unsigned int ___hf_##__name(void) {				\
 		unsigned int ret;							\
 		__asm__ ("sethi %%hi(___h_" #__name "__btset_" #__val "), %0" : 	\
 			 "=r"(ret));							\
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/cache.h linux-2.4.25-kdb-trace/include/asm-sparc/cache.h
--- linux-2.4.25-kdb/include/asm-sparc/cache.h	1999-08-31 20:23:30.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/cache.h	2005-01-05 16:45:36.000000000 +0100
@@ -33,7 +33,7 @@
  */
 
 /* First, cache-tag access. */
-extern __inline__ unsigned int get_icache_tag(int setnum, int tagnum)
+static __inline__ unsigned int get_icache_tag(int setnum, int tagnum)
 {
 	unsigned int vaddr, retval;
 
@@ -44,7 +44,7 @@
 	return retval;
 }
 
-extern __inline__ void put_icache_tag(int setnum, int tagnum, unsigned int entry)
+static __inline__ void put_icache_tag(int setnum, int tagnum, unsigned int entry)
 {
 	unsigned int vaddr;
 
@@ -57,7 +57,7 @@
 /* Second cache-data access.  The data is returned two-32bit quantities
  * at a time.
  */
-extern __inline__ void get_icache_data(int setnum, int tagnum, int subblock,
+static __inline__ void get_icache_data(int setnum, int tagnum, int subblock,
 				       unsigned int *data)
 {
 	unsigned int value1, value2, vaddr;
@@ -73,7 +73,7 @@
 	data[0] = value1; data[1] = value2;
 }
 
-extern __inline__ void put_icache_data(int setnum, int tagnum, int subblock,
+static __inline__ void put_icache_data(int setnum, int tagnum, int subblock,
 				       unsigned int *data)
 {
 	unsigned int value1, value2, vaddr;
@@ -98,35 +98,35 @@
  */
 
 /* Flushes which clear out both the on-chip and external caches */
-extern __inline__ void flush_ei_page(unsigned int addr)
+static __inline__ void flush_ei_page(unsigned int addr)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (addr), "i" (ASI_M_FLUSH_PAGE) :
 			     "memory");
 }
 
-extern __inline__ void flush_ei_seg(unsigned int addr)
+static __inline__ void flush_ei_seg(unsigned int addr)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (addr), "i" (ASI_M_FLUSH_SEG) :
 			     "memory");
 }
 
-extern __inline__ void flush_ei_region(unsigned int addr)
+static __inline__ void flush_ei_region(unsigned int addr)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (addr), "i" (ASI_M_FLUSH_REGION) :
 			     "memory");
 }
 
-extern __inline__ void flush_ei_ctx(unsigned int addr)
+static __inline__ void flush_ei_ctx(unsigned int addr)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (addr), "i" (ASI_M_FLUSH_CTX) :
 			     "memory");
 }
 
-extern __inline__ void flush_ei_user(unsigned int addr)
+static __inline__ void flush_ei_user(unsigned int addr)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (addr), "i" (ASI_M_FLUSH_USER) :
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/cypress.h linux-2.4.25-kdb-trace/include/asm-sparc/cypress.h
--- linux-2.4.25-kdb/include/asm-sparc/cypress.h	1996-11-09 09:29:16.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/cypress.h	2005-01-05 16:45:36.000000000 +0100
@@ -48,25 +48,25 @@
 #define CYPRESS_NFAULT    0x00000002
 #define CYPRESS_MENABLE   0x00000001
 
-extern __inline__ void cypress_flush_page(unsigned long page)
+static __inline__ void cypress_flush_page(unsigned long page)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (page), "i" (ASI_M_FLUSH_PAGE));
 }
 
-extern __inline__ void cypress_flush_segment(unsigned long addr)
+static __inline__ void cypress_flush_segment(unsigned long addr)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (addr), "i" (ASI_M_FLUSH_SEG));
 }
 
-extern __inline__ void cypress_flush_region(unsigned long addr)
+static __inline__ void cypress_flush_region(unsigned long addr)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : :
 			     "r" (addr), "i" (ASI_M_FLUSH_REGION));
 }
 
-extern __inline__ void cypress_flush_context(void)
+static __inline__ void cypress_flush_context(void)
 {
 	__asm__ __volatile__("sta %%g0, [%%g0] %0\n\t" : :
 			     "i" (ASI_M_FLUSH_CTX));
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/delay.h linux-2.4.25-kdb-trace/include/asm-sparc/delay.h
--- linux-2.4.25-kdb/include/asm-sparc/delay.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/delay.h	2005-01-05 16:45:36.000000000 +0100
@@ -9,7 +9,7 @@
 
 extern unsigned long loops_per_jiffy;
 
-extern __inline__ void __delay(unsigned long loops)
+static __inline__ void __delay(unsigned long loops)
 {
 	__asm__ __volatile__("cmp %0, 0\n\t"
 			     "1: bne 1b\n\t"
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/dma.h linux-2.4.25-kdb-trace/include/asm-sparc/dma.h
--- linux-2.4.25-kdb/include/asm-sparc/dma.h	2000-01-03 21:01:31.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/dma.h	2005-01-05 16:45:36.000000000 +0100
@@ -197,7 +197,7 @@
 /* Pause until counter runs out or BIT isn't set in the DMA condition
  * register.
  */
-extern __inline__ void sparc_dma_pause(struct sparc_dma_registers *regs,
+static __inline__ void sparc_dma_pause(struct sparc_dma_registers *regs,
 				       unsigned long bit)
 {
 	int ctr = 50000;   /* Let's find some bugs ;) */
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/iommu.h linux-2.4.25-kdb-trace/include/asm-sparc/iommu.h
--- linux-2.4.25-kdb/include/asm-sparc/iommu.h	1996-11-09 20:40:09.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/iommu.h	2005-01-05 16:45:36.000000000 +0100
@@ -107,12 +107,12 @@
 	unsigned long end;   /* Last managed virtual address */
 };
 
-extern __inline__ void iommu_invalidate(struct iommu_regs *regs)
+static __inline__ void iommu_invalidate(struct iommu_regs *regs)
 {
 	regs->tlbflush = 0;
 }
 
-extern __inline__ void iommu_invalidate_page(struct iommu_regs *regs, unsigned long page)
+static __inline__ void iommu_invalidate_page(struct iommu_regs *regs, unsigned long page)
 {
 	regs->pageflush = (page & PAGE_MASK);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/kdebug.h linux-2.4.25-kdb-trace/include/asm-sparc/kdebug.h
--- linux-2.4.25-kdb/include/asm-sparc/kdebug.h	2000-06-20 02:59:39.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/kdebug.h	2005-01-05 16:45:36.000000000 +0100
@@ -46,7 +46,7 @@
 extern struct kernel_debug *linux_dbvec;
 
 /* Use this macro in C-code to enter the debugger. */
-extern __inline__ void sp_enter_debugger(void)
+static __inline__ void sp_enter_debugger(void)
 {
 	__asm__ __volatile__("jmpl %0, %%o7\n\t"
 			     "nop\n\t" : :
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/mbus.h linux-2.4.25-kdb-trace/include/asm-sparc/mbus.h
--- linux-2.4.25-kdb/include/asm-sparc/mbus.h	1997-07-07 17:18:55.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/mbus.h	2005-01-05 16:45:36.000000000 +0100
@@ -83,7 +83,7 @@
  */
 #define TBR_ID_SHIFT            20
 
-extern __inline__ int get_cpuid(void)
+static __inline__ int get_cpuid(void)
 {
 	register int retval;
 	__asm__ __volatile__("rd %%tbr, %0\n\t"
@@ -93,7 +93,7 @@
 	return (retval & 3);
 }
 
-extern __inline__ int get_modid(void)
+static __inline__ int get_modid(void)
 {
 	return (get_cpuid() | 0x8);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/msi.h linux-2.4.25-kdb-trace/include/asm-sparc/msi.h
--- linux-2.4.25-kdb/include/asm-sparc/msi.h	1996-11-09 09:29:46.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/msi.h	2005-01-05 16:45:36.000000000 +0100
@@ -19,7 +19,7 @@
 #define MSI_ASYNC_MODE  0x80000000	/* Operate the MSI asynchronously */
 
 
-extern __inline__ void msi_set_sync(void)
+static __inline__ void msi_set_sync(void)
 {
 	__asm__ __volatile__ ("lda [%0] %1, %%g3\n\t"
 			      "andn %%g3, %2, %%g3\n\t"
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/mxcc.h linux-2.4.25-kdb-trace/include/asm-sparc/mxcc.h
--- linux-2.4.25-kdb/include/asm-sparc/mxcc.h	1997-04-24 04:01:28.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/mxcc.h	2005-01-05 16:45:36.000000000 +0100
@@ -85,7 +85,7 @@
 
 #ifndef __ASSEMBLY__
 
-extern __inline__ void mxcc_set_stream_src(unsigned long *paddr)
+static __inline__ void mxcc_set_stream_src(unsigned long *paddr)
 {
 	unsigned long data0 = paddr[0];
 	unsigned long data1 = paddr[1];
@@ -98,7 +98,7 @@
 			      "i" (ASI_M_MXCC) : "g2", "g3");
 }
 
-extern __inline__ void mxcc_set_stream_dst(unsigned long *paddr)
+static __inline__ void mxcc_set_stream_dst(unsigned long *paddr)
 {
 	unsigned long data0 = paddr[0];
 	unsigned long data1 = paddr[1];
@@ -111,7 +111,7 @@
 			      "i" (ASI_M_MXCC) : "g2", "g3");
 }
 
-extern __inline__ unsigned long mxcc_get_creg(void)
+static __inline__ unsigned long mxcc_get_creg(void)
 {
 	unsigned long mxcc_control;
 
@@ -125,7 +125,7 @@
 	return mxcc_control;
 }
 
-extern __inline__ void mxcc_set_creg(unsigned long mxcc_control)
+static __inline__ void mxcc_set_creg(unsigned long mxcc_control)
 {
 	__asm__ __volatile__("sta %0, [%1] %2\n\t" : :
 			     "r" (mxcc_control), "r" (MXCC_CREG),
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/obio.h linux-2.4.25-kdb-trace/include/asm-sparc/obio.h
--- linux-2.4.25-kdb/include/asm-sparc/obio.h	1998-04-15 02:44:23.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/obio.h	2005-01-05 16:45:36.000000000 +0100
@@ -98,7 +98,7 @@
 
 #ifndef __ASSEMBLY__
 
-extern __inline__ int bw_get_intr_mask(int sbus_level)
+static __inline__ int bw_get_intr_mask(int sbus_level)
 {
 	int mask;
 	
@@ -109,7 +109,7 @@
 	return mask;
 }
 
-extern __inline__ void bw_clear_intr_mask(int sbus_level, int mask)
+static __inline__ void bw_clear_intr_mask(int sbus_level, int mask)
 {
 	__asm__ __volatile__ ("stha %0, [%1] %2" : :
 			      "r" (mask),
@@ -117,7 +117,7 @@
 			      "i" (ASI_M_CTL));
 }
 
-extern __inline__ unsigned bw_get_prof_limit(int cpu)
+static __inline__ unsigned bw_get_prof_limit(int cpu)
 {
 	unsigned limit;
 	
@@ -128,7 +128,7 @@
 	return limit;
 }
 
-extern __inline__ void bw_set_prof_limit(int cpu, unsigned limit)
+static __inline__ void bw_set_prof_limit(int cpu, unsigned limit)
 {
 	__asm__ __volatile__ ("sta %0, [%1] %2" : :
 			      "r" (limit),
@@ -136,7 +136,7 @@
 			      "i" (ASI_M_CTL));
 }
 
-extern __inline__ unsigned bw_get_ctrl(int cpu)
+static __inline__ unsigned bw_get_ctrl(int cpu)
 {
 	unsigned ctrl;
 	
@@ -147,7 +147,7 @@
 	return ctrl;
 }
 
-extern __inline__ void bw_set_ctrl(int cpu, unsigned ctrl)
+static __inline__ void bw_set_ctrl(int cpu, unsigned ctrl)
 {
 	__asm__ __volatile__ ("sta %0, [%1] %2" : :
 			      "r" (ctrl),
@@ -157,7 +157,7 @@
 
 extern unsigned char cpu_leds[32];
 
-extern __inline__ void show_leds(int cpuid)
+static __inline__ void show_leds(int cpuid)
 {
 	cpuid &= 0x1e;
 	__asm__ __volatile__ ("stba %0, [%1] %2" : :
@@ -166,7 +166,7 @@
 			      "i" (ASI_M_CTL));
 }
 
-extern __inline__ unsigned cc_get_ipen(void)
+static __inline__ unsigned cc_get_ipen(void)
 {
 	unsigned pending;
 	
@@ -177,7 +177,7 @@
 	return pending;
 }
 
-extern __inline__ void cc_set_iclr(unsigned clear)
+static __inline__ void cc_set_iclr(unsigned clear)
 {
 	__asm__ __volatile__ ("stha %0, [%1] %2" : :
 			      "r" (clear),
@@ -185,7 +185,7 @@
 			      "i" (ASI_M_MXCC));
 }
 
-extern __inline__ unsigned cc_get_imsk(void)
+static __inline__ unsigned cc_get_imsk(void)
 {
 	unsigned mask;
 	
@@ -196,7 +196,7 @@
 	return mask;
 }
 
-extern __inline__ void cc_set_imsk(unsigned mask)
+static __inline__ void cc_set_imsk(unsigned mask)
 {
 	__asm__ __volatile__ ("stha %0, [%1] %2" : :
 			      "r" (mask),
@@ -204,7 +204,7 @@
 			      "i" (ASI_M_MXCC));
 }
 
-extern __inline__ unsigned cc_get_imsk_other(int cpuid)
+static __inline__ unsigned cc_get_imsk_other(int cpuid)
 {
 	unsigned mask;
 	
@@ -215,7 +215,7 @@
 	return mask;
 }
 
-extern __inline__ void cc_set_imsk_other(int cpuid, unsigned mask)
+static __inline__ void cc_set_imsk_other(int cpuid, unsigned mask)
 {
 	__asm__ __volatile__ ("stha %0, [%1] %2" : :
 			      "r" (mask),
@@ -223,7 +223,7 @@
 			      "i" (ASI_M_CTL));
 }
 
-extern __inline__ void cc_set_igen(unsigned gen)
+static __inline__ void cc_set_igen(unsigned gen)
 {
 	__asm__ __volatile__ ("sta %0, [%1] %2" : :
 			      "r" (gen),
@@ -239,7 +239,7 @@
 #define IGEN_MESSAGE(bcast, devid, sid, levels) \
 	(((bcast) << 31) | ((devid) << 23) | ((sid) << 15) | (levels))
             
-extern __inline__ void sun4d_send_ipi(int cpu, int level)
+static __inline__ void sun4d_send_ipi(int cpu, int level)
 {
 	cc_set_igen(IGEN_MESSAGE(0, cpu << 3, 6 + ((level >> 1) & 7), 1 << (level - 1)));
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/page.h linux-2.4.25-kdb-trace/include/asm-sparc/page.h
--- linux-2.4.25-kdb/include/asm-sparc/page.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/page.h	2005-01-05 16:45:36.000000000 +0100
@@ -151,7 +151,7 @@
 #define TASK_UNMAPPED_BASE	BTFIXUP_SETHI(sparc_unmapped_base)
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
 	int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/pci.h linux-2.4.25-kdb-trace/include/asm-sparc/pci.h
--- linux-2.4.25-kdb/include/asm-sparc/pci.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/pci.h	2005-01-05 16:45:36.000000000 +0100
@@ -15,12 +15,12 @@
 
 #define PCI_IRQ_NONE		0xffffffff
 
-extern inline void pcibios_set_master(struct pci_dev *dev)
+static inline void pcibios_set_master(struct pci_dev *dev)
 {
 	/* No special bus mastering setup handling */
 }
 
-extern inline void pcibios_penalize_isa_irq(int irq)
+static inline void pcibios_penalize_isa_irq(int irq)
 {
 	/* We don't do dynamic PCI IRQ allocation */
 }
@@ -131,7 +131,7 @@
  * only drive the low 24-bits during PCI bus mastering, then
  * you would pass 0x00ffffff as the mask to this function.
  */
-extern inline int pci_dma_supported(struct pci_dev *hwdev, u64 mask)
+static inline int pci_dma_supported(struct pci_dev *hwdev, u64 mask)
 {
 	return 1;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/pgalloc.h linux-2.4.25-kdb-trace/include/asm-sparc/pgalloc.h
--- linux-2.4.25-kdb/include/asm-sparc/pgalloc.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/pgalloc.h	2005-01-05 16:45:36.000000000 +0100
@@ -70,7 +70,7 @@
 BTFIXUPDEF_CALL(void, flush_tlb_range, struct mm_struct *, unsigned long, unsigned long)
 BTFIXUPDEF_CALL(void, flush_tlb_page, struct vm_area_struct *, unsigned long)
 
-extern __inline__ void flush_tlb_pgtables(struct mm_struct *mm, unsigned long start, unsigned long end)
+static __inline__ void flush_tlb_pgtables(struct mm_struct *mm, unsigned long start, unsigned long end)
 {
 }
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/pgtable.h linux-2.4.25-kdb-trace/include/asm-sparc/pgtable.h
--- linux-2.4.25-kdb/include/asm-sparc/pgtable.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/pgtable.h	2005-01-05 16:45:36.000000000 +0100
@@ -67,7 +67,7 @@
 BTFIXUPDEF_SETHI(pmd_mask)
 
 extern unsigned int pmd_align(unsigned int addr) __attribute__((const));
-extern __inline__ unsigned int pmd_align(unsigned int addr)
+static __inline__ unsigned int pmd_align(unsigned int addr)
 {
 	return ((addr + ~BTFIXUP_SETHI(pmd_mask)) & BTFIXUP_SETHI(pmd_mask));
 }
@@ -77,7 +77,7 @@
 BTFIXUPDEF_SETHI(pgdir_mask)
 
 extern unsigned int pgdir_align(unsigned int addr) __attribute__((const));
-extern __inline__ unsigned int pgdir_align(unsigned int addr)
+static __inline__ unsigned int pgdir_align(unsigned int addr)
 {
 	return ((addr + ~BTFIXUP_SETHI(pgdir_mask)) & BTFIXUP_SETHI(pgdir_mask));
 }
@@ -203,7 +203,7 @@
 BTFIXUPDEF_CALL_CONST(int, pte_present, pte_t)
 BTFIXUPDEF_CALL(void, pte_clear, pte_t *)
 
-extern __inline__ int pte_none(pte_t pte)
+static __inline__ int pte_none(pte_t pte)
 {
 	return !(pte_val(pte) & ~BTFIXUP_SETHI(none_mask));
 }
@@ -215,7 +215,7 @@
 BTFIXUPDEF_CALL_CONST(int, pmd_present, pmd_t)
 BTFIXUPDEF_CALL(void, pmd_clear, pmd_t *)
 
-extern __inline__ int pmd_none(pmd_t pmd)
+static __inline__ int pmd_none(pmd_t pmd)
 {
 	return !(pmd_val(pmd) & ~BTFIXUP_SETHI(none_mask));
 }
@@ -243,19 +243,19 @@
 BTFIXUPDEF_HALF(pte_youngi)
 
 extern int pte_write(pte_t pte) __attribute__((const));
-extern __inline__ int pte_write(pte_t pte)
+static __inline__ int pte_write(pte_t pte)
 {
 	return pte_val(pte) & BTFIXUP_HALF(pte_writei);
 }
 
 extern int pte_dirty(pte_t pte) __attribute__((const));
-extern __inline__ int pte_dirty(pte_t pte)
+static __inline__ int pte_dirty(pte_t pte)
 {
 	return pte_val(pte) & BTFIXUP_HALF(pte_dirtyi);
 }
 
 extern int pte_young(pte_t pte) __attribute__((const));
-extern __inline__ int pte_young(pte_t pte)
+static __inline__ int pte_young(pte_t pte)
 {
 	return pte_val(pte) & BTFIXUP_HALF(pte_youngi);
 }
@@ -265,19 +265,19 @@
 BTFIXUPDEF_HALF(pte_mkoldi)
 
 extern pte_t pte_wrprotect(pte_t pte) __attribute__((const));
-extern __inline__ pte_t pte_wrprotect(pte_t pte)
+static __inline__ pte_t pte_wrprotect(pte_t pte)
 {
 	return __pte(pte_val(pte) & ~BTFIXUP_HALF(pte_wrprotecti));
 }
 
 extern pte_t pte_mkclean(pte_t pte) __attribute__((const));
-extern __inline__ pte_t pte_mkclean(pte_t pte)
+static __inline__ pte_t pte_mkclean(pte_t pte)
 {
 	return __pte(pte_val(pte) & ~BTFIXUP_HALF(pte_mkcleani));
 }
 
 extern pte_t pte_mkold(pte_t pte) __attribute__((const));
-extern __inline__ pte_t pte_mkold(pte_t pte)
+static __inline__ pte_t pte_mkold(pte_t pte)
 {
 	return __pte(pte_val(pte) & ~BTFIXUP_HALF(pte_mkoldi));
 }
@@ -318,7 +318,7 @@
 BTFIXUPDEF_INT(pte_modify_mask)
 
 extern pte_t pte_modify(pte_t pte, pgprot_t newprot) __attribute__((const));
-extern __inline__ pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static __inline__ pte_t pte_modify(pte_t pte, pgprot_t newprot)
 {
 	return __pte((pte_val(pte) & BTFIXUP_INT(pte_modify_mask)) |
 		pgprot_val(newprot));
@@ -392,13 +392,13 @@
 
 #define NO_CONTEXT     -1
 
-extern __inline__ void remove_from_ctx_list(struct ctx_list *entry)
+static __inline__ void remove_from_ctx_list(struct ctx_list *entry)
 {
 	entry->next->prev = entry->prev;
 	entry->prev->next = entry->next;
 }
 
-extern __inline__ void add_to_ctx_list(struct ctx_list *head, struct ctx_list *entry)
+static __inline__ void add_to_ctx_list(struct ctx_list *head, struct ctx_list *entry)
 {
 	entry->next = head;
 	(entry->prev = head->prev)->next = entry;
@@ -407,7 +407,7 @@
 #define add_to_free_ctxlist(entry) add_to_ctx_list(&ctx_free, entry)
 #define add_to_used_ctxlist(entry) add_to_ctx_list(&ctx_used, entry)
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __get_phys (unsigned long addr)
 {
 	switch (sparc_cpu_model){
@@ -422,7 +422,7 @@
 	}
 }
 
-extern __inline__ int
+static __inline__ int
 __get_iospace (unsigned long addr)
 {
 	switch (sparc_cpu_model){
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/pgtsrmmu.h linux-2.4.25-kdb-trace/include/asm-sparc/pgtsrmmu.h
--- linux-2.4.25-kdb/include/asm-sparc/pgtsrmmu.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/pgtsrmmu.h	2005-01-05 16:45:36.000000000 +0100
@@ -102,7 +102,7 @@
 #ifndef __ASSEMBLY__
 
 /* Accessing the MMU control register. */
-extern __inline__ unsigned int srmmu_get_mmureg(void)
+static __inline__ unsigned int srmmu_get_mmureg(void)
 {
         unsigned int retval;
 	__asm__ __volatile__("lda [%%g0] %1, %0\n\t" :
@@ -111,14 +111,14 @@
 	return retval;
 }
 
-extern __inline__ void srmmu_set_mmureg(unsigned long regval)
+static __inline__ void srmmu_set_mmureg(unsigned long regval)
 {
 	__asm__ __volatile__("sta %0, [%%g0] %1\n\t" : :
 			     "r" (regval), "i" (ASI_M_MMUREGS) : "memory");
 
 }
 
-extern __inline__ void srmmu_set_ctable_ptr(unsigned long paddr)
+static __inline__ void srmmu_set_ctable_ptr(unsigned long paddr)
 {
 	paddr = ((paddr >> 4) & SRMMU_CTX_PMASK);
 	__asm__ __volatile__("sta %0, [%1] %2\n\t" : :
@@ -127,7 +127,7 @@
 			     "memory");
 }
 
-extern __inline__ unsigned long srmmu_get_ctable_ptr(void)
+static __inline__ unsigned long srmmu_get_ctable_ptr(void)
 {
 	unsigned int retval;
 
@@ -138,14 +138,14 @@
 	return (retval & SRMMU_CTX_PMASK) << 4;
 }
 
-extern __inline__ void srmmu_set_context(int context)
+static __inline__ void srmmu_set_context(int context)
 {
 	__asm__ __volatile__("sta %0, [%1] %2\n\t" : :
 			     "r" (context), "r" (SRMMU_CTX_REG),
 			     "i" (ASI_M_MMUREGS) : "memory");
 }
 
-extern __inline__ int srmmu_get_context(void)
+static __inline__ int srmmu_get_context(void)
 {
 	register int retval;
 	__asm__ __volatile__("lda [%1] %2, %0\n\t" :
@@ -155,7 +155,7 @@
 	return retval;
 }
 
-extern __inline__ unsigned int srmmu_get_fstatus(void)
+static __inline__ unsigned int srmmu_get_fstatus(void)
 {
 	unsigned int retval;
 
@@ -165,7 +165,7 @@
 	return retval;
 }
 
-extern __inline__ unsigned int srmmu_get_faddr(void)
+static __inline__ unsigned int srmmu_get_faddr(void)
 {
 	unsigned int retval;
 
@@ -176,7 +176,7 @@
 }
 
 /* This is guaranteed on all SRMMU's. */
-extern __inline__ void srmmu_flush_whole_tlb(void)
+static __inline__ void srmmu_flush_whole_tlb(void)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t": :
 			     "r" (0x400),        /* Flush entire TLB!! */
@@ -185,7 +185,7 @@
 }
 
 /* These flush types are not available on all chips... */
-extern __inline__ void srmmu_flush_tlb_ctx(void)
+static __inline__ void srmmu_flush_tlb_ctx(void)
 {
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t": :
 			     "r" (0x300),        /* Flush TLB ctx.. */
@@ -193,7 +193,7 @@
 
 }
 
-extern __inline__ void srmmu_flush_tlb_region(unsigned long addr)
+static __inline__ void srmmu_flush_tlb_region(unsigned long addr)
 {
 	addr &= SRMMU_PGDIR_MASK;
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t": :
@@ -203,7 +203,7 @@
 }
 
 
-extern __inline__ void srmmu_flush_tlb_segment(unsigned long addr)
+static __inline__ void srmmu_flush_tlb_segment(unsigned long addr)
 {
 	addr &= SRMMU_PMD_MASK;
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t": :
@@ -212,7 +212,7 @@
 
 }
 
-extern __inline__ void srmmu_flush_tlb_page(unsigned long page)
+static __inline__ void srmmu_flush_tlb_page(unsigned long page)
 {
 	page &= PAGE_MASK;
 	__asm__ __volatile__("sta %%g0, [%0] %1\n\t": :
@@ -221,7 +221,7 @@
 
 }
 
-extern __inline__ unsigned long srmmu_hwprobe(unsigned long vaddr)
+static __inline__ unsigned long srmmu_hwprobe(unsigned long vaddr)
 {
 	unsigned long retval;
 
@@ -233,7 +233,7 @@
 	return retval;
 }
 
-extern __inline__ int
+static __inline__ int
 srmmu_get_pte (unsigned long addr)
 {
 	register unsigned long entry;
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/processor.h linux-2.4.25-kdb-trace/include/asm-sparc/processor.h
--- linux-2.4.25-kdb/include/asm-sparc/processor.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/processor.h	2005-01-05 16:45:36.000000000 +0100
@@ -115,13 +115,13 @@
 }
 
 /* Return saved PC of a blocked thread. */
-extern __inline__ unsigned long thread_saved_pc(struct thread_struct *t)
+static __inline__ unsigned long thread_saved_pc(struct thread_struct *t)
 {
 	return t->kpc;
 }
 
 /* Do necessary setup to start up a newly executed thread. */
-extern __inline__ void start_thread(struct pt_regs * regs, unsigned long pc,
+static __inline__ void start_thread(struct pt_regs * regs, unsigned long pc,
 				    unsigned long sp)
 {
 	register unsigned long zero asm("g1");
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/psr.h linux-2.4.25-kdb-trace/include/asm-sparc/psr.h
--- linux-2.4.25-kdb/include/asm-sparc/psr.h	1998-01-13 00:15:54.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/psr.h	2005-01-05 16:45:36.000000000 +0100
@@ -38,7 +38,7 @@
 
 #ifndef __ASSEMBLY__
 /* Get the %psr register. */
-extern __inline__ unsigned int get_psr(void)
+static __inline__ unsigned int get_psr(void)
 {
 	unsigned int psr;
 	__asm__ __volatile__(
@@ -53,7 +53,7 @@
 	return psr;
 }
 
-extern __inline__ void put_psr(unsigned int new_psr)
+static __inline__ void put_psr(unsigned int new_psr)
 {
 	__asm__ __volatile__(
 		"wr	%0, 0x0, %%psr\n\t"
@@ -72,7 +72,7 @@
 
 extern unsigned int fsr_storage;
 
-extern __inline__ unsigned int get_fsr(void)
+static __inline__ unsigned int get_fsr(void)
 {
 	unsigned int fsr = 0;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/sbi.h linux-2.4.25-kdb-trace/include/asm-sparc/sbi.h
--- linux-2.4.25-kdb/include/asm-sparc/sbi.h	1998-04-15 02:44:23.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/sbi.h	2005-01-05 16:45:36.000000000 +0100
@@ -65,7 +65,7 @@
 
 #ifndef __ASSEMBLY__
 
-extern __inline__ int acquire_sbi(int devid, int mask)
+static __inline__ int acquire_sbi(int devid, int mask)
 {
 	__asm__ __volatile__ ("swapa [%2] %3, %0" :
 			      "=r" (mask) :
@@ -75,7 +75,7 @@
 	return mask;
 }
 
-extern __inline__ void release_sbi(int devid, int mask)
+static __inline__ void release_sbi(int devid, int mask)
 {
 	__asm__ __volatile__ ("sta %0, [%1] %2" : :
 			      "r" (mask),
@@ -83,7 +83,7 @@
 			      "i" (ASI_M_CTL));
 }
 
-extern __inline__ void set_sbi_tid(int devid, int targetid)
+static __inline__ void set_sbi_tid(int devid, int targetid)
 {
 	__asm__ __volatile__ ("sta %0, [%1] %2" : :
 			      "r" (targetid),
@@ -91,7 +91,7 @@
 			      "i" (ASI_M_CTL));
 }
 
-extern __inline__ int get_sbi_ctl(int devid, int cfgno)
+static __inline__ int get_sbi_ctl(int devid, int cfgno)
 {
 	int cfg;
 	
@@ -102,7 +102,7 @@
 	return cfg;
 }
 
-extern __inline__ void set_sbi_ctl(int devid, int cfgno, int cfg)
+static __inline__ void set_sbi_ctl(int devid, int cfgno, int cfg)
 {
 	__asm__ __volatile__ ("sta %0, [%1] %2" : :
 			      "r" (cfg),
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/sbus.h linux-2.4.25-kdb-trace/include/asm-sparc/sbus.h
--- linux-2.4.25-kdb/include/asm-sparc/sbus.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/sbus.h	2005-01-05 16:45:36.000000000 +0100
@@ -27,12 +27,12 @@
  * numbers + offsets, and vice versa.
  */
 
-extern __inline__ unsigned long sbus_devaddr(int slotnum, unsigned long offset)
+static __inline__ unsigned long sbus_devaddr(int slotnum, unsigned long offset)
 {
   return (unsigned long) (SUN_SBUS_BVADDR+((slotnum)<<25)+(offset));
 }
 
-extern __inline__ int sbus_dev_slot(unsigned long dev_addr)
+static __inline__ int sbus_dev_slot(unsigned long dev_addr)
 {
   return (int) (((dev_addr)-SUN_SBUS_BVADDR)>>25);
 }
@@ -79,7 +79,7 @@
 
 extern struct sbus_bus *sbus_root;
 
-extern __inline__ int
+static __inline__ int
 sbus_is_slave(struct sbus_dev *dev)
 {
 	/* XXX Have to write this for sun4c's */
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/siginfo.h linux-2.4.25-kdb-trace/include/asm-sparc/siginfo.h
--- linux-2.4.25-kdb/include/asm-sparc/siginfo.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/siginfo.h	2005-01-05 16:45:36.000000000 +0100
@@ -226,7 +226,7 @@
 
 #include <linux/string.h>
 
-extern inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
+static inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
 {
 	if (from->si_code < 0)
 		*to = *from;
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/smp.h linux-2.4.25-kdb-trace/include/asm-sparc/smp.h
--- linux-2.4.25-kdb/include/asm-sparc/smp.h	2001-11-13 18:16:05.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/smp.h	2005-01-05 16:45:36.000000000 +0100
@@ -80,22 +80,22 @@
 #define smp_cross_call(func,arg1,arg2,arg3,arg4,arg5) BTFIXUP_CALL(smp_cross_call)(func,arg1,arg2,arg3,arg4,arg5)
 #define smp_message_pass(target,msg,data,wait) BTFIXUP_CALL(smp_message_pass)(target,msg,data,wait)
 
-extern __inline__ void xc0(smpfunc_t func) { smp_cross_call(func, 0, 0, 0, 0, 0); }
-extern __inline__ void xc1(smpfunc_t func, unsigned long arg1)
+static __inline__ void xc0(smpfunc_t func) { smp_cross_call(func, 0, 0, 0, 0, 0); }
+static __inline__ void xc1(smpfunc_t func, unsigned long arg1)
 { smp_cross_call(func, arg1, 0, 0, 0, 0); }
-extern __inline__ void xc2(smpfunc_t func, unsigned long arg1, unsigned long arg2)
+static __inline__ void xc2(smpfunc_t func, unsigned long arg1, unsigned long arg2)
 { smp_cross_call(func, arg1, arg2, 0, 0, 0); }
-extern __inline__ void xc3(smpfunc_t func, unsigned long arg1, unsigned long arg2,
+static __inline__ void xc3(smpfunc_t func, unsigned long arg1, unsigned long arg2,
 			   unsigned long arg3)
 { smp_cross_call(func, arg1, arg2, arg3, 0, 0); }
-extern __inline__ void xc4(smpfunc_t func, unsigned long arg1, unsigned long arg2,
+static __inline__ void xc4(smpfunc_t func, unsigned long arg1, unsigned long arg2,
 			   unsigned long arg3, unsigned long arg4)
 { smp_cross_call(func, arg1, arg2, arg3, arg4, 0); }
-extern __inline__ void xc5(smpfunc_t func, unsigned long arg1, unsigned long arg2,
+static __inline__ void xc5(smpfunc_t func, unsigned long arg1, unsigned long arg2,
 			   unsigned long arg3, unsigned long arg4, unsigned long arg5)
 { smp_cross_call(func, arg1, arg2, arg3, arg4, arg5); }
 
-extern __inline__ int smp_call_function(void (*func)(void *info), void *info, int nonatomic, int wait)
+static __inline__ int smp_call_function(void (*func)(void *info), void *info, int nonatomic, int wait)
 {
 	xc1((smpfunc_t)func, (unsigned long)info);
 	return 0;
@@ -105,16 +105,16 @@
 extern __volatile__ int __cpu_logical_map[NR_CPUS];
 extern unsigned long smp_proc_in_lock[NR_CPUS];
 
-extern __inline__ int cpu_logical_map(int cpu)
+static __inline__ int cpu_logical_map(int cpu)
 {
 	return __cpu_logical_map[cpu];
 }
-extern __inline__ int cpu_number_map(int cpu)
+static __inline__ int cpu_number_map(int cpu)
 {
 	return __cpu_number_map[cpu];
 }
 
-extern __inline__ int hard_smp4m_processor_id(void)
+static __inline__ int hard_smp4m_processor_id(void)
 {
 	int cpuid;
 
@@ -125,7 +125,7 @@
 	return cpuid;
 }
 
-extern __inline__ int hard_smp4d_processor_id(void)
+static __inline__ int hard_smp4d_processor_id(void)
 {
 	int cpuid;
 
@@ -135,7 +135,7 @@
 }
 
 #ifndef MODULE
-extern __inline__ int hard_smp_processor_id(void)
+static __inline__ int hard_smp_processor_id(void)
 {
 	int cpuid;
 
@@ -157,7 +157,7 @@
 	return cpuid;
 }
 #else
-extern __inline__ int hard_smp_processor_id(void)
+static __inline__ int hard_smp_processor_id(void)
 {
 	int cpuid;
 	
@@ -171,8 +171,8 @@
 
 #define smp_processor_id() hard_smp_processor_id()
 /* XXX We really need to implement this now.  -DaveM */
-extern __inline__ void smp_send_reschedule(int cpu) { }
-extern __inline__ void smp_send_stop(void) { }
+static __inline__ void smp_send_reschedule(int cpu) { }
+static __inline__ void smp_send_stop(void) { }
 
 #endif /* !(__ASSEMBLY__) */
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/smplock.h linux-2.4.25-kdb-trace/include/asm-sparc/smplock.h
--- linux-2.4.25-kdb/include/asm-sparc/smplock.h	2000-03-23 21:50:09.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/smplock.h	2005-01-05 16:45:36.000000000 +0100
@@ -38,13 +38,13 @@
  * so we only need to worry about other
  * CPU's.
  */
-extern __inline__ void lock_kernel(void)
+static __inline__ void lock_kernel(void)
 {
 	if (!++current->lock_depth)
 		spin_lock(&kernel_flag);
 }
 
-extern __inline__ void unlock_kernel(void)
+static __inline__ void unlock_kernel(void)
 {
 	if (--current->lock_depth < 0)
 		spin_unlock(&kernel_flag);
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/smpprim.h linux-2.4.25-kdb-trace/include/asm-sparc/smpprim.h
--- linux-2.4.25-kdb/include/asm-sparc/smpprim.h	1996-11-09 09:30:07.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/smpprim.h	2005-01-05 16:45:36.000000000 +0100
@@ -15,7 +15,7 @@
  * atomic.
  */
 
-extern __inline__ __volatile__ char test_and_set(void *addr)
+static __inline__ __volatile__ char test_and_set(void *addr)
 {
 	char state = 0;
 
@@ -27,7 +27,7 @@
 }
 
 /* Initialize a spin-lock. */
-extern __inline__ __volatile__ smp_initlock(void *spinlock)
+static __inline__ __volatile__ smp_initlock(void *spinlock)
 {
 	/* Unset the lock. */
 	*((unsigned char *) spinlock) = 0;
@@ -36,7 +36,7 @@
 }
 
 /* This routine spins until it acquires the lock at ADDR. */
-extern __inline__ __volatile__ smp_lock(void *addr)
+static __inline__ __volatile__ smp_lock(void *addr)
 {
 	while(test_and_set(addr) == 0xff)
 		;
@@ -46,7 +46,7 @@
 }
 
 /* This routine releases the lock at ADDR. */
-extern __inline__ __volatile__ smp_unlock(void *addr)
+static __inline__ __volatile__ smp_unlock(void *addr)
 {
 	*((unsigned char *) addr) = 0;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/spinlock.h linux-2.4.25-kdb-trace/include/asm-sparc/spinlock.h
--- linux-2.4.25-kdb/include/asm-sparc/spinlock.h	2001-10-31 00:08:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/spinlock.h	2005-01-05 16:45:36.000000000 +0100
@@ -97,7 +97,7 @@
 	barrier(); \
 } while(*((volatile unsigned char *)lock))
 
-extern __inline__ void spin_lock(spinlock_t *lock)
+static __inline__ void spin_lock(spinlock_t *lock)
 {
 	__asm__ __volatile__(
 	"\n1:\n\t"
@@ -117,7 +117,7 @@
 	: "g2", "memory", "cc");
 }
 
-extern __inline__ int spin_trylock(spinlock_t *lock)
+static __inline__ int spin_trylock(spinlock_t *lock)
 {
 	unsigned int result;
 	__asm__ __volatile__("ldstub [%1], %0"
@@ -127,7 +127,7 @@
 	return (result == 0);
 }
 
-extern __inline__ void spin_unlock(spinlock_t *lock)
+static __inline__ void spin_unlock(spinlock_t *lock)
 {
 	__asm__ __volatile__("stb %%g0, [%0]" : : "r" (lock) : "memory");
 }
@@ -165,7 +165,7 @@
  *
  * Unfortunately this scheme limits us to ~16,000,000 cpus.
  */
-extern __inline__ void _read_lock(rwlock_t *rw)
+static __inline__ void _read_lock(rwlock_t *rw)
 {
 	register rwlock_t *lp asm("g1");
 	lp = rw;
@@ -185,7 +185,7 @@
 	__restore_flags(flags); \
 } while(0)
 
-extern __inline__ void _read_unlock(rwlock_t *rw)
+static __inline__ void _read_unlock(rwlock_t *rw)
 {
 	register rwlock_t *lp asm("g1");
 	lp = rw;
@@ -205,7 +205,7 @@
 	__restore_flags(flags); \
 } while(0)
 
-extern __inline__ void write_lock(rwlock_t *rw)
+static __inline__ void write_lock(rwlock_t *rw)
 {
 	register rwlock_t *lp asm("g1");
 	lp = rw;
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/system.h linux-2.4.25-kdb-trace/include/asm-sparc/system.h
--- linux-2.4.25-kdb/include/asm-sparc/system.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc/system.h	2005-01-05 16:45:36.000000000 +0100
@@ -150,7 +150,7 @@
 /*
  * Changing the IRQ level on the Sparc.
  */
-extern __inline__ void setipl(unsigned long __orig_psr)
+static __inline__ void setipl(unsigned long __orig_psr)
 {
 	__asm__ __volatile__(
 		"wr	%0, 0x0, %%psr\n\t"
@@ -160,7 +160,7 @@
 		: "memory", "cc");
 }
 
-extern __inline__ void __cli(void)
+static __inline__ void __cli(void)
 {
 	unsigned long tmp;
 
@@ -175,7 +175,7 @@
 		: "memory");
 }
 
-extern __inline__ void __sti(void)
+static __inline__ void __sti(void)
 {
 	unsigned long tmp;
 
@@ -190,7 +190,7 @@
 		: "memory");
 }
 
-extern __inline__ unsigned long getipl(void)
+static __inline__ unsigned long getipl(void)
 {
 	unsigned long retval;
 
@@ -198,7 +198,7 @@
 	return retval;
 }
 
-extern __inline__ unsigned long swap_pil(unsigned long __new_psr)
+static __inline__ unsigned long swap_pil(unsigned long __new_psr)
 {
 	unsigned long retval;
 
@@ -220,7 +220,7 @@
 	return retval;
 }
 
-extern __inline__ unsigned long read_psr_and_cli(void)
+static __inline__ unsigned long read_psr_and_cli(void)
 {
 	unsigned long retval;
 
@@ -237,7 +237,7 @@
 	return retval;
 }
 
-extern __inline__ unsigned long read_psr_and_sti(void)
+static __inline__ unsigned long read_psr_and_sti(void)
 {
 	unsigned long retval;
 
@@ -306,7 +306,7 @@
 BTFIXUPDEF_CALL(void, ___xchg32, void)
 #endif
 
-extern __inline__ unsigned long xchg_u32(__volatile__ unsigned long *m, unsigned long val)
+static __inline__ unsigned long xchg_u32(__volatile__ unsigned long *m, unsigned long val)
 {
 #ifdef CONFIG_SMP
 	__asm__ __volatile__("swap [%2], %0"
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/traps.h linux-2.4.25-kdb-trace/include/asm-sparc/traps.h
--- linux-2.4.25-kdb/include/asm-sparc/traps.h	1998-04-15 02:44:24.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/traps.h	2005-01-05 16:45:36.000000000 +0100
@@ -22,7 +22,7 @@
 /* We set this to _start in system setup. */
 extern struct tt_entry *sparc_ttable;
 
-extern __inline__ unsigned long get_tbr(void)
+static __inline__ unsigned long get_tbr(void)
 {
 	unsigned long tbr;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc/uaccess.h linux-2.4.25-kdb-trace/include/asm-sparc/uaccess.h
--- linux-2.4.25-kdb/include/asm-sparc/uaccess.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc/uaccess.h	2005-01-05 16:45:36.000000000 +0100
@@ -44,7 +44,7 @@
 #define __access_ok(addr,size) (__user_ok((addr) & get_fs().seg,(size)))
 #define access_ok(type,addr,size) __access_ok((unsigned long)(addr),(size))
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
 	return access_ok(type,addr,size)?0:-EFAULT;
 }
@@ -319,7 +319,7 @@
 	__copy_user((void *)(to),		\
 		    (void *)(from), n)
 
-extern __inline__ __kernel_size_t __clear_user(void *addr, __kernel_size_t size)
+static __inline__ __kernel_size_t __clear_user(void *addr, __kernel_size_t size)
 {
   __kernel_size_t ret;
   __asm__ __volatile__ (
@@ -360,7 +360,7 @@
 extern int __strlen_user(const char *);
 extern int __strnlen_user(const char *, long len);
 
-extern __inline__ int strlen_user(const char *str)
+static __inline__ int strlen_user(const char *str)
 {
 	if(!access_ok(VERIFY_READ, str, 0))
 		return 0;
@@ -368,7 +368,7 @@
 		return __strlen_user(str);
 }
 
-extern __inline__ int strnlen_user(const char *str, long len)
+static __inline__ int strnlen_user(const char *str, long len)
 {
 	if(!access_ok(VERIFY_READ, str, 0))
 		return 0;
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/bitops.h linux-2.4.25-kdb-trace/include/asm-sparc64/bitops.h
--- linux-2.4.25-kdb/include/asm-sparc64/bitops.h	2001-12-21 18:42:03.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/bitops.h	2005-01-05 16:45:37.000000000 +0100
@@ -64,13 +64,13 @@
 #define smp_mb__before_clear_bit()	do { } while(0)
 #define smp_mb__after_clear_bit()	do { } while(0)
 
-extern __inline__ int test_bit(int nr, __const__ void *addr)
+static __inline__ int test_bit(int nr, __const__ void *addr)
 {
 	return (1UL & (((__const__ long *) addr)[nr >> 6] >> (nr & 63))) != 0UL;
 }
 
 /* The easy/cheese version for now. */
-extern __inline__ unsigned long ffz(unsigned long word)
+static __inline__ unsigned long ffz(unsigned long word)
 {
 	unsigned long result;
 
@@ -132,7 +132,7 @@
 
 #ifdef ULTRA_HAS_POPULATION_COUNT
 
-extern __inline__ unsigned int hweight32(unsigned int w)
+static __inline__ unsigned int hweight32(unsigned int w)
 {
 	unsigned int res;
 
@@ -140,7 +140,7 @@
 	return res;
 }
 
-extern __inline__ unsigned int hweight16(unsigned int w)
+static __inline__ unsigned int hweight16(unsigned int w)
 {
 	unsigned int res;
 
@@ -148,7 +148,7 @@
 	return res;
 }
 
-extern __inline__ unsigned int hweight8(unsigned int w)
+static __inline__ unsigned int hweight8(unsigned int w)
 {
 	unsigned int res;
 
@@ -170,7 +170,7 @@
  * on Linus's ALPHA routines, which are pretty portable BTW.
  */
 
-extern __inline__ unsigned long find_next_zero_bit(void *addr, unsigned long size, unsigned long offset)
+static __inline__ unsigned long find_next_zero_bit(void *addr, unsigned long size, unsigned long offset)
 {
 	unsigned long *p = ((unsigned long *) addr) + (offset >> 6);
 	unsigned long result = offset & ~63UL;
@@ -219,7 +219,7 @@
 #define set_le_bit(nr,addr)		((void)___test_and_set_le_bit(nr,addr))
 #define clear_le_bit(nr,addr)		((void)___test_and_clear_le_bit(nr,addr))
 
-extern __inline__ int test_le_bit(int nr, __const__ void * addr)
+static __inline__ int test_le_bit(int nr, __const__ void * addr)
 {
 	int			mask;
 	__const__ unsigned char	*ADDR = (__const__ unsigned char *) addr;
@@ -232,7 +232,7 @@
 #define find_first_zero_le_bit(addr, size) \
         find_next_zero_le_bit((addr), (size), 0)
 
-extern __inline__ unsigned long find_next_zero_le_bit(void *addr, unsigned long size, unsigned long offset)
+static __inline__ unsigned long find_next_zero_le_bit(void *addr, unsigned long size, unsigned long offset)
 {
 	unsigned long *p = ((unsigned long *) addr) + (offset >> 6);
 	unsigned long result = offset & ~63UL;
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/checksum.h linux-2.4.25-kdb-trace/include/asm-sparc64/checksum.h
--- linux-2.4.25-kdb/include/asm-sparc64/checksum.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/checksum.h	2005-01-05 16:45:37.000000000 +0100
@@ -40,7 +40,7 @@
  */
 extern unsigned int csum_partial_copy_sparc64(const char *src, char *dst, int len, unsigned int sum);
 			
-extern __inline__ unsigned int 
+static __inline__ unsigned int 
 csum_partial_copy_nocheck (const char *src, char *dst, int len, 
 			   unsigned int sum)
 {
@@ -52,7 +52,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned int 
+static __inline__ unsigned int 
 csum_partial_copy_from_user(const char *src, char *dst, int len, 
 			    unsigned int sum, int *err)
 {
@@ -66,7 +66,7 @@
  */
 #define HAVE_CSUM_COPY_USER
 extern unsigned int csum_partial_copy_user_sparc64(const char *src, char *dst, int len, unsigned int sum);
-extern __inline__ unsigned int 
+static __inline__ unsigned int 
 csum_and_copy_to_user(const char *src, char *dst, int len, 
 		      unsigned int sum, int *err)
 {
@@ -78,7 +78,7 @@
 /* ihl is always 5 or greater, almost always is 5, and iph is word aligned
  * the majority of the time.
  */
-extern __inline__ unsigned short ip_fast_csum(__const__ unsigned char *iph,
+static __inline__ unsigned short ip_fast_csum(__const__ unsigned char *iph,
 					      unsigned int ihl)
 {
 	unsigned short sum;
@@ -119,7 +119,7 @@
 }
 
 /* Fold a partial checksum without adding pseudo headers. */
-extern __inline__ unsigned short csum_fold(unsigned int sum)
+static __inline__ unsigned short csum_fold(unsigned int sum)
 {
 	unsigned int tmp;
 
@@ -134,7 +134,7 @@
 	return (sum & 0xffff);
 }
 
-extern __inline__ unsigned long csum_tcpudp_nofold(unsigned long saddr,
+static __inline__ unsigned long csum_tcpudp_nofold(unsigned long saddr,
 						   unsigned long daddr,
 						   unsigned int len,
 						   unsigned short proto,
@@ -201,7 +201,7 @@
 }
 
 /* this routine is used for miscellaneous IP-like checksums, mainly in icmp.c */
-extern __inline__ unsigned short ip_compute_csum(unsigned char * buff, int len)
+static __inline__ unsigned short ip_compute_csum(unsigned char * buff, int len)
 {
 	return csum_fold(csum_partial(buff, len, 0));
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/delay.h linux-2.4.25-kdb-trace/include/asm-sparc64/delay.h
--- linux-2.4.25-kdb/include/asm-sparc64/delay.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/delay.h	2005-01-05 16:45:37.000000000 +0100
@@ -18,7 +18,7 @@
 extern unsigned long loops_per_jiffy;
 #endif 
 
-extern __inline__ void __delay(unsigned long loops)
+static __inline__ void __delay(unsigned long loops)
 {
 	__asm__ __volatile__(
 "	b,pt	%%xcc, 1f\n"
@@ -32,7 +32,7 @@
 	: "cc");
 }
 
-extern __inline__ void __udelay(unsigned long usecs, unsigned long lps)
+static __inline__ void __udelay(unsigned long usecs, unsigned long lps)
 {
 	usecs *= 0x00000000000010c6UL;		/* 2**32 / 1000000 */
 
@@ -45,7 +45,7 @@
 	__delay(usecs * HZ);
 }
 
-extern __inline__ void __ndelay(unsigned long usecs, unsigned long lps)
+static __inline__ void __ndelay(unsigned long usecs, unsigned long lps)
 {
 	usecs *= 0x0000000000000005UL;		/* 2**32 / 10000 */
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/fpumacro.h linux-2.4.25-kdb-trace/include/asm-sparc64/fpumacro.h
--- linux-2.4.25-kdb/include/asm-sparc64/fpumacro.h	1999-05-27 18:55:22.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/fpumacro.h	2005-01-05 16:45:37.000000000 +0100
@@ -16,7 +16,7 @@
 
 #define FPUSTATE (struct fpustate *)(((unsigned long)current) + AOFF_task_fpregs)
 
-extern __inline__ unsigned long fprs_read(void)
+static __inline__ unsigned long fprs_read(void)
 {
 	unsigned long retval;
 
@@ -25,7 +25,7 @@
 	return retval;
 }
 
-extern __inline__ void fprs_write(unsigned long val)
+static __inline__ void fprs_write(unsigned long val)
 {
 	__asm__ __volatile__("wr %0, 0x0, %%fprs" : : "r" (val));
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/irq.h linux-2.4.25-kdb-trace/include/asm-sparc64/irq.h
--- linux-2.4.25-kdb/include/asm-sparc64/irq.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/irq.h	2005-01-05 16:45:37.000000000 +0100
@@ -130,21 +130,21 @@
 			    unsigned long flags, __const__ char *devname,
 			    void *dev_id);
 
-extern __inline__ void set_softint(unsigned long bits)
+static __inline__ void set_softint(unsigned long bits)
 {
 	__asm__ __volatile__("wr	%0, 0x0, %%set_softint"
 			     : /* No outputs */
 			     : "r" (bits));
 }
 
-extern __inline__ void clear_softint(unsigned long bits)
+static __inline__ void clear_softint(unsigned long bits)
 {
 	__asm__ __volatile__("wr	%0, 0x0, %%clear_softint"
 			     : /* No outputs */
 			     : "r" (bits));
 }
 
-extern __inline__ unsigned long get_softint(void)
+static __inline__ unsigned long get_softint(void)
 {
 	unsigned long retval;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/page.h linux-2.4.25-kdb-trace/include/asm-sparc64/page.h
--- linux-2.4.25-kdb/include/asm-sparc64/page.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/page.h	2005-01-05 16:45:37.000000000 +0100
@@ -142,7 +142,7 @@
 extern struct sparc_phys_banks sp_banks[SPARC_PHYS_BANKS];
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
 	int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/pci.h linux-2.4.25-kdb-trace/include/asm-sparc64/pci.h
--- linux-2.4.25-kdb/include/asm-sparc64/pci.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/pci.h	2005-01-05 16:45:37.000000000 +0100
@@ -18,12 +18,12 @@
 
 #define PCI_IRQ_NONE		0xffffffff
 
-extern inline void pcibios_set_master(struct pci_dev *dev)
+static inline void pcibios_set_master(struct pci_dev *dev)
 {
 	/* No special bus mastering setup handling */
 }
 
-extern inline void pcibios_penalize_isa_irq(int irq)
+static inline void pcibios_penalize_isa_irq(int irq)
 {
 	/* We don't do dynamic PCI IRQ allocation */
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/pgalloc.h linux-2.4.25-kdb-trace/include/asm-sparc64/pgalloc.h
--- linux-2.4.25-kdb/include/asm-sparc64/pgalloc.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/pgalloc.h	2005-01-05 16:45:37.000000000 +0100
@@ -100,7 +100,7 @@
 
 #endif /* ! CONFIG_SMP */
 
-extern __inline__ void flush_tlb_pgtables(struct mm_struct *mm, unsigned long start,
+static __inline__ void flush_tlb_pgtables(struct mm_struct *mm, unsigned long start,
 					  unsigned long end)
 {
 	/* Note the signed type.  */
@@ -142,7 +142,7 @@
 
 #ifndef CONFIG_SMP
 
-extern __inline__ void free_pgd_fast(pgd_t *pgd)
+static __inline__ void free_pgd_fast(pgd_t *pgd)
 {
 	struct page *page = virt_to_page(pgd);
 
@@ -155,7 +155,7 @@
 	pgd_cache_size++;
 }
 
-extern __inline__ pgd_t *get_pgd_fast(void)
+static __inline__ pgd_t *get_pgd_fast(void)
 {
         struct page *ret;
 
@@ -191,14 +191,14 @@
 
 #else /* CONFIG_SMP */
 
-extern __inline__ void free_pgd_fast(pgd_t *pgd)
+static __inline__ void free_pgd_fast(pgd_t *pgd)
 {
 	*(unsigned long *)pgd = (unsigned long) pgd_quicklist;
 	pgd_quicklist = (unsigned long *) pgd;
 	pgtable_cache_size++;
 }
 
-extern __inline__ pgd_t *get_pgd_fast(void)
+static __inline__ pgd_t *get_pgd_fast(void)
 {
 	unsigned long *ret;
 
@@ -214,7 +214,7 @@
 	return (pgd_t *)ret;
 }
 
-extern __inline__ void free_pgd_slow(pgd_t *pgd)
+static __inline__ void free_pgd_slow(pgd_t *pgd)
 {
 	free_page((unsigned long)pgd);
 }
@@ -231,7 +231,7 @@
 
 #define pgd_populate(MM, PGD, PMD)	pgd_set(PGD, PMD)
 
-extern __inline__ pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long address)
+static __inline__ pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long address)
 {
 	pmd_t *pmd = (pmd_t *)__get_free_page(GFP_KERNEL);
 	if (pmd)
@@ -239,7 +239,7 @@
 	return pmd;
 }
 
-extern __inline__ pmd_t *pmd_alloc_one_fast(struct mm_struct *mm, unsigned long address)
+static __inline__ pmd_t *pmd_alloc_one_fast(struct mm_struct *mm, unsigned long address)
 {
 	unsigned long *ret;
 	int color = 0;
@@ -254,7 +254,7 @@
 	return (pmd_t *)ret;
 }
 
-extern __inline__ void free_pmd_fast(pmd_t *pmd)
+static __inline__ void free_pmd_fast(pmd_t *pmd)
 {
 	unsigned long color = DCACHE_COLOR((unsigned long)pmd);
 	*(unsigned long *)pmd = (unsigned long) pte_quicklist[color];
@@ -262,7 +262,7 @@
 	pgtable_cache_size++;
 }
 
-extern __inline__ void free_pmd_slow(pmd_t *pmd)
+static __inline__ void free_pmd_slow(pmd_t *pmd)
 {
 	free_page((unsigned long)pmd);
 }
@@ -271,7 +271,7 @@
 
 extern pte_t *pte_alloc_one(struct mm_struct *mm, unsigned long address);
 
-extern __inline__ pte_t *pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
+static __inline__ pte_t *pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
 {
 	unsigned long color = VPTE_COLOR(address);
 	unsigned long *ret;
@@ -284,7 +284,7 @@
 	return (pte_t *)ret;
 }
 
-extern __inline__ void free_pte_fast(pte_t *pte)
+static __inline__ void free_pte_fast(pte_t *pte)
 {
 	unsigned long color = DCACHE_COLOR((unsigned long)pte);
 	*(unsigned long *)pte = (unsigned long) pte_quicklist[color];
@@ -292,7 +292,7 @@
 	pgtable_cache_size++;
 }
 
-extern __inline__ void free_pte_slow(pte_t *pte)
+static __inline__ void free_pte_slow(pte_t *pte)
 {
 	free_page((unsigned long)pte);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/pgtable.h linux-2.4.25-kdb-trace/include/asm-sparc64/pgtable.h
--- linux-2.4.25-kdb/include/asm-sparc64/pgtable.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/pgtable.h	2005-01-05 16:45:37.000000000 +0100
@@ -202,7 +202,7 @@
 
 #define mk_pte_phys(physpage, pgprot)	(__pte((physpage) | pgprot_val(pgprot) | _PAGE_SZBITS))
 
-extern inline pte_t pte_modify(pte_t orig_pte, pgprot_t new_prot)
+static inline pte_t pte_modify(pte_t orig_pte, pgprot_t new_prot)
 {
 	pte_t __pte;
 
@@ -279,7 +279,7 @@
 #define flush_icache_user_range(vma,pg,adr,len)	do { } while (0)
 
 /* Make a non-present pseudo-TTE. */
-extern inline pte_t mk_pte_io(unsigned long page, pgprot_t prot, int space)
+static inline pte_t mk_pte_io(unsigned long page, pgprot_t prot, int space)
 {
 	pte_t pte;
 	pte_val(pte) = ((page) | pgprot_val(prot) | _PAGE_E) & ~(unsigned long)_PAGE_CACHE;
@@ -301,7 +301,7 @@
 
 extern unsigned long prom_virt_to_phys(unsigned long, int *);
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 sun4u_get_pte (unsigned long addr)
 {
 	pgd_t *pgdp;
@@ -318,13 +318,13 @@
 	return pte_val (*ptep) & _PAGE_PADDR;
 }
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __get_phys (unsigned long addr)
 {
 	return sun4u_get_pte (addr);
 }
 
-extern __inline__ int
+static __inline__ int
 __get_iospace (unsigned long addr)
 {
 	return ((sun4u_get_pte (addr) & 0xf0000000) >> 28);
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/processor.h linux-2.4.25-kdb-trace/include/asm-sparc64/processor.h
--- linux-2.4.25-kdb/include/asm-sparc64/processor.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/processor.h	2005-01-05 16:45:37.000000000 +0100
@@ -165,7 +165,7 @@
 #ifndef __ASSEMBLY__
 
 /* Return saved PC of a blocked thread. */
-extern __inline__ unsigned long thread_saved_pc(struct thread_struct *t)
+static __inline__ unsigned long thread_saved_pc(struct thread_struct *t)
 {
 	unsigned long ret = 0xdeadbeefUL;
 	
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/psrcompat.h linux-2.4.25-kdb-trace/include/asm-sparc64/psrcompat.h
--- linux-2.4.25-kdb/include/asm-sparc64/psrcompat.h	1998-10-27 18:52:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/psrcompat.h	2005-01-05 16:45:37.000000000 +0100
@@ -24,7 +24,7 @@
 #define PSR_V8PLUS  0xff000000         /* fake impl/ver, meaning a 64bit CPU is present */
 #define PSR_XCC	    0x000f0000         /* if PSR_V8PLUS, this is %xcc */
 
-extern inline unsigned int tstate_to_psr(unsigned long tstate)
+static inline unsigned int tstate_to_psr(unsigned long tstate)
 {
 	return ((tstate & TSTATE_CWP)			|
 		PSR_S					|
@@ -33,7 +33,7 @@
 		PSR_V8PLUS);
 }
 
-extern inline unsigned long psr_to_tstate_icc(unsigned int psr)
+static inline unsigned long psr_to_tstate_icc(unsigned int psr)
 {
 	unsigned long tstate = ((unsigned long)(psr & PSR_ICC)) << 12;
 	if ((psr & (PSR_VERS|PSR_IMPL)) == PSR_V8PLUS)
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/sbus.h linux-2.4.25-kdb-trace/include/asm-sparc64/sbus.h
--- linux-2.4.25-kdb/include/asm-sparc64/sbus.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/sbus.h	2005-01-05 16:45:37.000000000 +0100
@@ -27,12 +27,12 @@
  * numbers + offsets, and vice versa.
  */
 
-extern __inline__ unsigned long sbus_devaddr(int slotnum, unsigned long offset)
+static __inline__ unsigned long sbus_devaddr(int slotnum, unsigned long offset)
 {
   return (unsigned long) (SUN_SBUS_BVADDR+((slotnum)<<28)+(offset));
 }
 
-extern __inline__ int sbus_dev_slot(unsigned long dev_addr)
+static __inline__ int sbus_dev_slot(unsigned long dev_addr)
 {
   return (int) (((dev_addr)-SUN_SBUS_BVADDR)>>28);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/siginfo.h linux-2.4.25-kdb-trace/include/asm-sparc64/siginfo.h
--- linux-2.4.25-kdb/include/asm-sparc64/siginfo.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/siginfo.h	2005-01-05 16:45:37.000000000 +0100
@@ -301,7 +301,7 @@
 
 #include <linux/string.h>
 
-extern inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
+static inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
 {
 	if (from->si_code < 0)
 		*to = *from;
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/smp.h linux-2.4.25-kdb-trace/include/asm-sparc64/smp.h
--- linux-2.4.25-kdb/include/asm-sparc64/smp.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/smp.h	2005-01-05 16:45:37.000000000 +0100
@@ -75,16 +75,16 @@
 extern __volatile__ int __cpu_number_map[NR_CPUS];
 extern __volatile__ int __cpu_logical_map[NR_CPUS];
 
-extern __inline__ int cpu_logical_map(int cpu)
+static __inline__ int cpu_logical_map(int cpu)
 {
 	return __cpu_logical_map[cpu];
 }
-extern __inline__ int cpu_number_map(int cpu)
+static __inline__ int cpu_number_map(int cpu)
 {
 	return __cpu_number_map[cpu];
 }
 
-extern __inline__ int hard_smp_processor_id(void)
+static __inline__ int hard_smp_processor_id(void)
 {
 	if (tlb_type == cheetah || tlb_type == cheetah_plus) {
 		unsigned long cfg, ver;
@@ -121,7 +121,7 @@
  *           delivery case, we detect that by just seeing
  *           if we are trying to send this to an idler or not.
  */
-extern __inline__ void smp_send_reschedule(int cpu)
+static __inline__ void smp_send_reschedule(int cpu)
 {
 	extern void smp_receive_signal(int);
 	if(cpu_data[cpu].idle_volume == 0)
@@ -131,7 +131,7 @@
 /* This is a nop as well because we capture all other cpus
  * anyways when making the PROM active.
  */
-extern __inline__ void smp_send_stop(void) { }
+static __inline__ void smp_send_stop(void) { }
 
 #endif /* !(__ASSEMBLY__) */
 
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/spinlock.h linux-2.4.25-kdb-trace/include/asm-sparc64/spinlock.h
--- linux-2.4.25-kdb/include/asm-sparc64/spinlock.h	2001-12-21 18:42:03.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/spinlock.h	2005-01-05 16:45:37.000000000 +0100
@@ -40,7 +40,7 @@
 do {	membar("#LoadLoad");	\
 } while(*((volatile unsigned char *)lock))
 
-extern __inline__ void spin_lock(spinlock_t *lock)
+static __inline__ void spin_lock(spinlock_t *lock)
 {
 	__asm__ __volatile__(
 "1:	ldstub		[%0], %%g7\n"
@@ -57,7 +57,7 @@
 	: "g7", "memory");
 }
 
-extern __inline__ int spin_trylock(spinlock_t *lock)
+static __inline__ int spin_trylock(spinlock_t *lock)
 {
 	unsigned int result;
 	__asm__ __volatile__("ldstub [%1], %0\n\t"
@@ -68,7 +68,7 @@
 	return (result == 0);
 }
 
-extern __inline__ void spin_unlock(spinlock_t *lock)
+static __inline__ void spin_unlock(spinlock_t *lock)
 {
 	__asm__ __volatile__("membar	#StoreStore | #LoadStore\n\t"
 			     "stb	%%g0, [%0]"
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/spitfire.h linux-2.4.25-kdb-trace/include/asm-sparc64/spitfire.h
--- linux-2.4.25-kdb/include/asm-sparc64/spitfire.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/spitfire.h	2005-01-05 16:45:37.000000000 +0100
@@ -54,7 +54,7 @@
 	 SPITFIRE_HIGHEST_LOCKED_TLBENT : \
 	 CHEETAH_HIGHEST_LOCKED_TLBENT)
 
-extern __inline__ unsigned long spitfire_get_isfsr(void)
+static __inline__ unsigned long spitfire_get_isfsr(void)
 {
 	unsigned long ret;
 
@@ -64,7 +64,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned long spitfire_get_dsfsr(void)
+static __inline__ unsigned long spitfire_get_dsfsr(void)
 {
 	unsigned long ret;
 
@@ -74,7 +74,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned long spitfire_get_sfar(void)
+static __inline__ unsigned long spitfire_get_sfar(void)
 {
 	unsigned long ret;
 
@@ -84,7 +84,7 @@
 	return ret;
 }
 
-extern __inline__ void spitfire_put_isfsr(unsigned long sfsr)
+static __inline__ void spitfire_put_isfsr(unsigned long sfsr)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -92,7 +92,7 @@
 			     : "r" (sfsr), "r" (TLB_SFSR), "i" (ASI_IMMU));
 }
 
-extern __inline__ void spitfire_put_dsfsr(unsigned long sfsr)
+static __inline__ void spitfire_put_dsfsr(unsigned long sfsr)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -100,7 +100,7 @@
 			     : "r" (sfsr), "r" (TLB_SFSR), "i" (ASI_DMMU));
 }
 
-extern __inline__ unsigned long spitfire_get_primary_context(void)
+static __inline__ unsigned long spitfire_get_primary_context(void)
 {
 	unsigned long ctx;
 
@@ -110,7 +110,7 @@
 	return ctx;
 }
 
-extern __inline__ void spitfire_set_primary_context(unsigned long ctx)
+static __inline__ void spitfire_set_primary_context(unsigned long ctx)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -120,7 +120,7 @@
 	__asm__ __volatile__ ("membar #Sync" : : : "memory");
 }
 
-extern __inline__ unsigned long spitfire_get_secondary_context(void)
+static __inline__ unsigned long spitfire_get_secondary_context(void)
 {
 	unsigned long ctx;
 
@@ -130,7 +130,7 @@
 	return ctx;
 }
 
-extern __inline__ void spitfire_set_secondary_context(unsigned long ctx)
+static __inline__ void spitfire_set_secondary_context(unsigned long ctx)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -143,7 +143,7 @@
 /* The data cache is write through, so this just invalidates the
  * specified line.
  */
-extern __inline__ void spitfire_put_dcache_tag(unsigned long addr, unsigned long tag)
+static __inline__ void spitfire_put_dcache_tag(unsigned long addr, unsigned long tag)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -158,7 +158,7 @@
  * a flush instruction (to any address) is sufficient to handle
  * this issue after the line is invalidated.
  */
-extern __inline__ void spitfire_put_icache_tag(unsigned long addr, unsigned long tag)
+static __inline__ void spitfire_put_icache_tag(unsigned long addr, unsigned long tag)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -166,7 +166,7 @@
 			     : "r" (tag), "r" (addr), "i" (ASI_IC_TAG));
 }
 
-extern __inline__ unsigned long spitfire_get_dtlb_data(int entry)
+static __inline__ unsigned long spitfire_get_dtlb_data(int entry)
 {
 	unsigned long data;
 
@@ -180,7 +180,7 @@
 	return data;
 }
 
-extern __inline__ unsigned long spitfire_get_dtlb_tag(int entry)
+static __inline__ unsigned long spitfire_get_dtlb_tag(int entry)
 {
 	unsigned long tag;
 
@@ -190,7 +190,7 @@
 	return tag;
 }
 
-extern __inline__ void spitfire_put_dtlb_data(int entry, unsigned long data)
+static __inline__ void spitfire_put_dtlb_data(int entry, unsigned long data)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -199,7 +199,7 @@
 			       "i" (ASI_DTLB_DATA_ACCESS));
 }
 
-extern __inline__ unsigned long spitfire_get_itlb_data(int entry)
+static __inline__ unsigned long spitfire_get_itlb_data(int entry)
 {
 	unsigned long data;
 
@@ -213,7 +213,7 @@
 	return data;
 }
 
-extern __inline__ unsigned long spitfire_get_itlb_tag(int entry)
+static __inline__ unsigned long spitfire_get_itlb_tag(int entry)
 {
 	unsigned long tag;
 
@@ -223,7 +223,7 @@
 	return tag;
 }
 
-extern __inline__ void spitfire_put_itlb_data(int entry, unsigned long data)
+static __inline__ void spitfire_put_itlb_data(int entry, unsigned long data)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -235,7 +235,7 @@
 /* Spitfire hardware assisted TLB flushes. */
 
 /* Context level flushes. */
-extern __inline__ void spitfire_flush_dtlb_primary_context(void)
+static __inline__ void spitfire_flush_dtlb_primary_context(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -243,7 +243,7 @@
 			     : "r" (0x40), "i" (ASI_DMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_itlb_primary_context(void)
+static __inline__ void spitfire_flush_itlb_primary_context(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -251,7 +251,7 @@
 			     : "r" (0x40), "i" (ASI_IMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_dtlb_secondary_context(void)
+static __inline__ void spitfire_flush_dtlb_secondary_context(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -259,7 +259,7 @@
 			     : "r" (0x50), "i" (ASI_DMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_itlb_secondary_context(void)
+static __inline__ void spitfire_flush_itlb_secondary_context(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -267,7 +267,7 @@
 			     : "r" (0x50), "i" (ASI_IMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_dtlb_nucleus_context(void)
+static __inline__ void spitfire_flush_dtlb_nucleus_context(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -275,7 +275,7 @@
 			     : "r" (0x60), "i" (ASI_DMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_itlb_nucleus_context(void)
+static __inline__ void spitfire_flush_itlb_nucleus_context(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -284,7 +284,7 @@
 }
 
 /* Page level flushes. */
-extern __inline__ void spitfire_flush_dtlb_primary_page(unsigned long page)
+static __inline__ void spitfire_flush_dtlb_primary_page(unsigned long page)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -292,7 +292,7 @@
 			     : "r" (page), "i" (ASI_DMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_itlb_primary_page(unsigned long page)
+static __inline__ void spitfire_flush_itlb_primary_page(unsigned long page)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -300,7 +300,7 @@
 			     : "r" (page), "i" (ASI_IMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_dtlb_secondary_page(unsigned long page)
+static __inline__ void spitfire_flush_dtlb_secondary_page(unsigned long page)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -308,7 +308,7 @@
 			     : "r" (page | 0x10), "i" (ASI_DMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_itlb_secondary_page(unsigned long page)
+static __inline__ void spitfire_flush_itlb_secondary_page(unsigned long page)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -316,7 +316,7 @@
 			     : "r" (page | 0x10), "i" (ASI_IMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_dtlb_nucleus_page(unsigned long page)
+static __inline__ void spitfire_flush_dtlb_nucleus_page(unsigned long page)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -324,7 +324,7 @@
 			     : "r" (page | 0x20), "i" (ASI_DMMU_DEMAP));
 }
 
-extern __inline__ void spitfire_flush_itlb_nucleus_page(unsigned long page)
+static __inline__ void spitfire_flush_itlb_nucleus_page(unsigned long page)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -333,7 +333,7 @@
 }
 
 /* Cheetah has "all non-locked" tlb flushes. */
-extern __inline__ void cheetah_flush_dtlb_all(void)
+static __inline__ void cheetah_flush_dtlb_all(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -341,7 +341,7 @@
 			     : "r" (0x80), "i" (ASI_DMMU_DEMAP));
 }
 
-extern __inline__ void cheetah_flush_itlb_all(void)
+static __inline__ void cheetah_flush_itlb_all(void)
 {
 	__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 			     "membar	#Sync"
@@ -363,7 +363,7 @@
  * ASI_{D,I}TLB_DATA_ACCESS loads, doing the load twice fixes
  * the problem for me. -DaveM
  */
-extern __inline__ unsigned long cheetah_get_ldtlb_data(int entry)
+static __inline__ unsigned long cheetah_get_ldtlb_data(int entry)
 {
 	unsigned long data;
 
@@ -376,7 +376,7 @@
 	return data;
 }
 
-extern __inline__ unsigned long cheetah_get_litlb_data(int entry)
+static __inline__ unsigned long cheetah_get_litlb_data(int entry)
 {
 	unsigned long data;
 
@@ -389,7 +389,7 @@
 	return data;
 }
 
-extern __inline__ unsigned long cheetah_get_ldtlb_tag(int entry)
+static __inline__ unsigned long cheetah_get_ldtlb_tag(int entry)
 {
 	unsigned long tag;
 
@@ -401,7 +401,7 @@
 	return tag;
 }
 
-extern __inline__ unsigned long cheetah_get_litlb_tag(int entry)
+static __inline__ unsigned long cheetah_get_litlb_tag(int entry)
 {
 	unsigned long tag;
 
@@ -413,7 +413,7 @@
 	return tag;
 }
 
-extern __inline__ void cheetah_put_ldtlb_data(int entry, unsigned long data)
+static __inline__ void cheetah_put_ldtlb_data(int entry, unsigned long data)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -423,7 +423,7 @@
 			       "i" (ASI_DTLB_DATA_ACCESS));
 }
 
-extern __inline__ void cheetah_put_litlb_data(int entry, unsigned long data)
+static __inline__ void cheetah_put_litlb_data(int entry, unsigned long data)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -433,7 +433,7 @@
 			       "i" (ASI_ITLB_DATA_ACCESS));
 }
 
-extern __inline__ unsigned long cheetah_get_dtlb_data(int entry, int tlb)
+static __inline__ unsigned long cheetah_get_dtlb_data(int entry, int tlb)
 {
 	unsigned long data;
 
@@ -445,7 +445,7 @@
 	return data;
 }
 
-extern __inline__ unsigned long cheetah_get_dtlb_tag(int entry, int tlb)
+static __inline__ unsigned long cheetah_get_dtlb_tag(int entry, int tlb)
 {
 	unsigned long tag;
 
@@ -455,7 +455,7 @@
 	return tag;
 }
 
-extern __inline__ void cheetah_put_dtlb_data(int entry, unsigned long data, int tlb)
+static __inline__ void cheetah_put_dtlb_data(int entry, unsigned long data, int tlb)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
@@ -465,7 +465,7 @@
 			       "i" (ASI_DTLB_DATA_ACCESS));
 }
 
-extern __inline__ unsigned long cheetah_get_itlb_data(int entry)
+static __inline__ unsigned long cheetah_get_itlb_data(int entry)
 {
 	unsigned long data;
 
@@ -478,7 +478,7 @@
 	return data;
 }
 
-extern __inline__ unsigned long cheetah_get_itlb_tag(int entry)
+static __inline__ unsigned long cheetah_get_itlb_tag(int entry)
 {
 	unsigned long tag;
 
@@ -488,7 +488,7 @@
 	return tag;
 }
 
-extern __inline__ void cheetah_put_itlb_data(int entry, unsigned long data)
+static __inline__ void cheetah_put_itlb_data(int entry, unsigned long data)
 {
 	__asm__ __volatile__("stxa	%0, [%1] %2\n\t"
 			     "membar	#Sync"
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/system.h linux-2.4.25-kdb-trace/include/asm-sparc64/system.h
--- linux-2.4.25-kdb/include/asm-sparc64/system.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/system.h	2005-01-05 16:45:37.000000000 +0100
@@ -243,7 +243,7 @@
 	}									\
 } while(0)
 
-extern __inline__ unsigned long xchg32(__volatile__ unsigned int *m, unsigned int val)
+static __inline__ unsigned long xchg32(__volatile__ unsigned int *m, unsigned int val)
 {
 	__asm__ __volatile__(
 "	mov		%0, %%g5\n"
@@ -259,7 +259,7 @@
 	return val;
 }
 
-extern __inline__ unsigned long xchg64(__volatile__ unsigned long *m, unsigned long val)
+static __inline__ unsigned long xchg64(__volatile__ unsigned long *m, unsigned long val)
 {
 	__asm__ __volatile__(
 "	mov		%0, %%g5\n"
@@ -303,7 +303,7 @@
 
 #define __HAVE_ARCH_CMPXCHG 1
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __cmpxchg_u32(volatile int *m, int old, int new)
 {
 	__asm__ __volatile__("cas [%2], %3, %0\n\t"
@@ -315,7 +315,7 @@
 	return new;
 }
 
-extern __inline__ unsigned long
+static __inline__ unsigned long
 __cmpxchg_u64(volatile long *m, unsigned long old, unsigned long new)
 {
 	__asm__ __volatile__("casx [%2], %3, %0\n\t"
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/uaccess.h linux-2.4.25-kdb-trace/include/asm-sparc64/uaccess.h
--- linux-2.4.25-kdb/include/asm-sparc64/uaccess.h	2001-10-01 18:19:56.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/uaccess.h	2005-01-05 16:45:37.000000000 +0100
@@ -52,7 +52,7 @@
 #define __access_ok(addr,size) 1
 #define access_ok(type,addr,size) 1
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
 	return 0;
 }
@@ -270,7 +270,7 @@
 	__copy_in_user((void *)(to), \
 	(void *) (from), (__kernel_size_t)(n))
 
-extern __inline__ __kernel_size_t __clear_user(void *addr, __kernel_size_t size)
+static __inline__ __kernel_size_t __clear_user(void *addr, __kernel_size_t size)
 {
 	extern __kernel_size_t __bzero_noasi(void *addr, __kernel_size_t size);
 	
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/upa.h linux-2.4.25-kdb-trace/include/asm-sparc64/upa.h
--- linux-2.4.25-kdb/include/asm-sparc64/upa.h	1999-12-21 07:05:52.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/upa.h	2005-01-05 16:45:37.000000000 +0100
@@ -25,7 +25,7 @@
 
 /* UPA I/O space accessors */
 #if defined(__KERNEL__) && !defined(__ASSEMBLY__)
-extern __inline__ unsigned char _upa_readb(unsigned long addr)
+static __inline__ unsigned char _upa_readb(unsigned long addr)
 {
 	unsigned char ret;
 
@@ -36,7 +36,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned short _upa_readw(unsigned long addr)
+static __inline__ unsigned short _upa_readw(unsigned long addr)
 {
 	unsigned short ret;
 
@@ -47,7 +47,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned int _upa_readl(unsigned long addr)
+static __inline__ unsigned int _upa_readl(unsigned long addr)
 {
 	unsigned int ret;
 
@@ -58,7 +58,7 @@
 	return ret;
 }
 
-extern __inline__ unsigned long _upa_readq(unsigned long addr)
+static __inline__ unsigned long _upa_readq(unsigned long addr)
 {
 	unsigned long ret;
 
@@ -69,28 +69,28 @@
 	return ret;
 }
 
-extern __inline__ void _upa_writeb(unsigned char b, unsigned long addr)
+static __inline__ void _upa_writeb(unsigned char b, unsigned long addr)
 {
 	__asm__ __volatile__("stba\t%0, [%1] %2\t/* upa_writeb */"
 			     : /* no outputs */
 			     : "r" (b), "r" (addr), "i" (ASI_PHYS_BYPASS_EC_E));
 }
 
-extern __inline__ void _upa_writew(unsigned short w, unsigned long addr)
+static __inline__ void _upa_writew(unsigned short w, unsigned long addr)
 {
 	__asm__ __volatile__("stha\t%0, [%1] %2\t/* upa_writew */"
 			     : /* no outputs */
 			     : "r" (w), "r" (addr), "i" (ASI_PHYS_BYPASS_EC_E));
 }
 
-extern __inline__ void _upa_writel(unsigned int l, unsigned long addr)
+static __inline__ void _upa_writel(unsigned int l, unsigned long addr)
 {
 	__asm__ __volatile__("stwa\t%0, [%1] %2\t/* upa_writel */"
 			     : /* no outputs */
 			     : "r" (l), "r" (addr), "i" (ASI_PHYS_BYPASS_EC_E));
 }
 
-extern __inline__ void _upa_writeq(unsigned long q, unsigned long addr)
+static __inline__ void _upa_writeq(unsigned long q, unsigned long addr)
 {
 	__asm__ __volatile__("stxa\t%0, [%1] %2\t/* upa_writeq */"
 			     : /* no outputs */
diff -rbNu linux-2.4.25-kdb/include/asm-sparc64/visasm.h linux-2.4.25-kdb-trace/include/asm-sparc64/visasm.h
--- linux-2.4.25-kdb/include/asm-sparc64/visasm.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-sparc64/visasm.h	2005-01-05 16:45:37.000000000 +0100
@@ -46,7 +46,7 @@
 	wr		%o5, 0, %fprs;
 
 #ifndef __ASSEMBLY__	
-extern __inline__ void save_and_clear_fpu(void) {
+static __inline__ void save_and_clear_fpu(void) {
 	__asm__ __volatile__ (
 "		rd %%fprs, %%o5\n"
 "		andcc %%o5, %0, %%g0\n"
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/apic.h linux-2.4.25-kdb-trace/include/asm-x86_64/apic.h
--- linux-2.4.25-kdb/include/asm-x86_64/apic.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/apic.h	2005-01-05 16:45:34.000000000 +0100
@@ -78,7 +78,7 @@
 extern void smp_local_timer_interrupt (struct pt_regs * regs);
 extern void setup_APIC_clocks (void);
 extern void setup_apic_nmi_watchdog (void);
-extern inline void nmi_watchdog_tick (struct pt_regs * regs, unsigned reason);
+extern void nmi_watchdog_tick (struct pt_regs * regs, unsigned reason);
 extern int APIC_init_uniprocessor (void);
 extern void disable_APIC_timer(void);
 extern void enable_APIC_timer(void);
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/fixmap.h linux-2.4.25-kdb-trace/include/asm-x86_64/fixmap.h
--- linux-2.4.25-kdb/include/asm-x86_64/fixmap.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/fixmap.h	2005-01-05 16:45:34.000000000 +0100
@@ -73,7 +73,7 @@
  * directly without tranlation, we catch the bug with a NULL-deference
  * kernel oops. Illegal ranges of incoming indices are caught too.
  */
-extern inline unsigned long fix_to_virt(const unsigned int idx)
+static inline unsigned long fix_to_virt(const unsigned int idx)
 {
 	/*
 	 * this branch gets completely eliminated after inlining,
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/io.h linux-2.4.25-kdb-trace/include/asm-x86_64/io.h
--- linux-2.4.25-kdb/include/asm-x86_64/io.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/io.h	2005-01-05 16:45:34.000000000 +0100
@@ -52,7 +52,7 @@
  * Talk about misusing macros..
  */
 #define __OUT1(s,x) \
-extern inline void out##s(unsigned x value, unsigned short port) {
+static inline void out##s(unsigned x value, unsigned short port) {
 
 #define __OUT2(s,s1,s2) \
 __asm__ __volatile__ ("out" #s " %" s1 "0,%" s2 "1"
@@ -62,7 +62,7 @@
 __OUT1(s##_p,x) __OUT2(s,s1,"w") __FULL_SLOW_DOWN_IO : : "a" (value), "Nd" (port));} \
 
 #define __IN1(s) \
-extern inline RETURN_TYPE in##s(unsigned short port) { RETURN_TYPE _v;
+static inline RETURN_TYPE in##s(unsigned short port) { RETURN_TYPE _v;
 
 #define __IN2(s,s1,s2) \
 __asm__ __volatile__ ("in" #s " %" s2 "1,%" s1 "0"
@@ -72,12 +72,12 @@
 __IN1(s##_p) __IN2(s,s1,"w") __FULL_SLOW_DOWN_IO : "=a" (_v) : "Nd" (port) ,##i ); return _v; } \
 
 #define __INS(s) \
-extern inline void ins##s(unsigned short port, void * addr, unsigned long count) \
+static inline void ins##s(unsigned short port, void * addr, unsigned long count) \
 { __asm__ __volatile__ ("rep ; ins" #s \
 : "=D" (addr), "=c" (count) : "d" (port),"0" (addr),"1" (count)); }
 
 #define __OUTS(s) \
-extern inline void outs##s(unsigned short port, const void * addr, unsigned long count) \
+static inline void outs##s(unsigned short port, const void * addr, unsigned long count) \
 { __asm__ __volatile__ ("rep ; outs" #s \
 : "=S" (addr), "=c" (count) : "d" (port),"0" (addr),"1" (count)); }
 
@@ -127,12 +127,12 @@
  * Change virtual addresses to physical addresses and vv.
  * These are pretty trivial
  */
-extern inline unsigned long virt_to_phys(volatile void * address)
+static inline unsigned long virt_to_phys(volatile void * address)
 {
 	return __pa(address);
 }
 
-extern inline void * phys_to_virt(unsigned long address)
+static inline void * phys_to_virt(unsigned long address)
 {
 	return __va(address);
 }
@@ -148,7 +148,7 @@
 
 extern void * __ioremap(unsigned long offset, unsigned long size, unsigned long flags);
 
-extern inline void * ioremap (unsigned long offset, unsigned long size)
+static inline void * ioremap (unsigned long offset, unsigned long size)
 {
 	return __ioremap(offset, size, 0);
 }
@@ -158,7 +158,7 @@
  * it's useful if some control registers are in such an area and write combining
  * or read caching is not desirable:
  */
-extern inline void * ioremap_nocache (unsigned long offset, unsigned long size)
+static inline void * ioremap_nocache (unsigned long offset, unsigned long size)
 {
         return __ioremap(offset, size, _PAGE_PCD);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/locks.h linux-2.4.25-kdb-trace/include/asm-x86_64/locks.h
--- linux-2.4.25-kdb/include/asm-x86_64/locks.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/locks.h	2005-01-05 16:45:34.000000000 +0100
@@ -10,7 +10,7 @@
  *	to borrow for other processors if it was just assembler.
  */
 
-extern __inline__ void prim_spin_lock(struct spinlock *sp)
+static __inline__ void prim_spin_lock(struct spinlock *sp)
 {
 	int processor=smp_processor_id();
 	
@@ -56,7 +56,7 @@
  *	Release a spin lock
  */
  
-extern __inline__ int prim_spin_unlock(struct spinlock *sp)
+static __inline__ int prim_spin_unlock(struct spinlock *sp)
 {
 	/* This is safe. The decrement is still guarded by the lock. A multilock would
 	   not be safe this way */
@@ -73,7 +73,7 @@
  *	Non blocking lock grab
  */
  
-extern __inline__ int prim_spin_lock_nb(struct spinlock *sp)
+static __inline__ int prim_spin_lock_nb(struct spinlock *sp)
 {
 	if(lock_set_bit(0,&sp->lock))
 		return 0;		/* Locked already */
@@ -86,7 +86,7 @@
  *	These wrap the locking primitives up for usage
  */
  
-extern __inline__ void spinlock(struct spinlock *sp)
+static __inline__ void spinlock(struct spinlock *sp)
 {
 	if(sp->priority<current->lock_order)
 		panic("lock order violation: %s (%d)\n", sp->name, current->lock_order);
@@ -100,7 +100,7 @@
 	}
 }
 
-extern __inline__ void spinunlock(struct spinlock *sp)
+static __inline__ void spinunlock(struct spinlock *sp)
 {
 	int pri;
 	if(current->lock_order!=sp->priority)
@@ -116,7 +116,7 @@
 	}	
 }
 
-extern __inline__ void spintestlock(struct spinlock *sp)
+static __inline__ void spintestlock(struct spinlock *sp)
 {
 	/*
 	 *	We do no sanity checks, it's legal to optimistically
@@ -125,7 +125,7 @@
 	prim_spin_lock_nb(sp);
 }
 
-extern __inline__ void spintestunlock(struct spinlock *sp)
+static __inline__ void spintestunlock(struct spinlock *sp)
 {
 	/*
 	 *	A testlock doesn't update the lock chain so we
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/page.h linux-2.4.25-kdb-trace/include/asm-x86_64/page.h
--- linux-2.4.25-kdb/include/asm-x86_64/page.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/page.h	2005-01-05 16:45:34.000000000 +0100
@@ -98,7 +98,7 @@
 #define PAGE_BUG(page) BUG()
 
 /* Pure 2^n version of get_order */
-extern __inline__ int get_order(unsigned long size)
+static __inline__ int get_order(unsigned long size)
 {
 	int order;
 
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/pgalloc.h linux-2.4.25-kdb-trace/include/asm-x86_64/pgalloc.h
--- linux-2.4.25-kdb/include/asm-x86_64/pgalloc.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/pgalloc.h	2005-01-05 16:45:34.000000000 +0100
@@ -17,12 +17,12 @@
 #define pgd_populate(mm, pgd, pmd) \
 		set_pgd(pgd, __pgd(_PAGE_TABLE | __pa(pmd)))
 
-extern __inline__ pmd_t *get_pmd_slow(void)
+static __inline__ pmd_t *get_pmd_slow(void)
 {
 	return (pmd_t *)get_zeroed_page(GFP_KERNEL);
 }
 
-extern __inline__ pmd_t *get_pmd_fast(void)
+static __inline__ pmd_t *get_pmd_fast(void)
 {
 	unsigned long *ret;
 
@@ -35,14 +35,14 @@
 	return (pmd_t *)ret;
 }
 
-extern __inline__ void pmd_free(pmd_t *pmd)
+static __inline__ void pmd_free(pmd_t *pmd)
 {
 	*(unsigned long *)pmd = (unsigned long) read_pda(pmd_quick);
 	write_pda(pmd_quick,(unsigned long *) pmd);
 	inc_pgcache_size();
 }
 
-extern __inline__ void pmd_free_slow(pmd_t *pmd)
+static __inline__ void pmd_free_slow(pmd_t *pmd)
 {
 	if ((unsigned long)pmd & (PAGE_SIZE-1)) 
 		out_of_line_bug(); 
@@ -109,7 +109,7 @@
 	return (pte_t *)get_zeroed_page(GFP_KERNEL); 
 }
 
-extern __inline__ pte_t *pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
+static __inline__ pte_t *pte_alloc_one_fast(struct mm_struct *mm, unsigned long address)
 {
 	unsigned long *ret;
 
@@ -124,14 +124,14 @@
 /* Should really implement gc for free page table pages. This could be done with 
    a reference count in struct page. */
 
-extern __inline__ void pte_free(pte_t *pte)
+static __inline__ void pte_free(pte_t *pte)
 {	
 	*(unsigned long *)pte = (unsigned long) read_pda(pte_quick);
 	write_pda(pte_quick, (unsigned long *) pte); 
 	inc_pgcache_size();
 }
 
-extern __inline__ void pte_free_slow(pte_t *pte)
+static __inline__ void pte_free_slow(pte_t *pte)
 {
 	if ((unsigned long)pte & (PAGE_SIZE-1))
 		out_of_line_bug();
@@ -210,7 +210,7 @@
 
 #endif
 
-extern inline void flush_tlb_pgtables(struct mm_struct *mm,
+static inline void flush_tlb_pgtables(struct mm_struct *mm,
 				      unsigned long start, unsigned long end)
 {
 	flush_tlb_mm(mm);
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/pgtable.h linux-2.4.25-kdb-trace/include/asm-x86_64/pgtable.h
--- linux-2.4.25-kdb/include/asm-x86_64/pgtable.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/pgtable.h	2005-01-05 16:45:34.000000000 +0100
@@ -116,7 +116,7 @@
 #define pgd_none(x)	(!pgd_val(x))
 
 
-extern inline int pgd_present(pgd_t pgd)	{ return !pgd_none(pgd); }
+static inline int pgd_present(pgd_t pgd)	{ return !pgd_none(pgd); }
 
 static inline void set_pte(pte_t *dst, pte_t val)
 {
@@ -138,12 +138,12 @@
 	pml4_val(*dst) = pml4_val(val);
 } 
 
-extern inline void __pgd_clear (pgd_t * pgd)
+static inline void __pgd_clear (pgd_t * pgd)
 {
 	set_pgd(pgd, __pgd(0));
 }
 
-extern inline void pgd_clear (pgd_t * pgd)
+static inline void pgd_clear (pgd_t * pgd)
 {
 	__pgd_clear(pgd);
 	__flush_tlb();
@@ -320,22 +320,22 @@
  * The following only work if pte_present() is true.
  * Undefined behaviour if not..
  */
-extern inline int pte_read(pte_t pte)		{ return pte_val(pte) & _PAGE_USER; }
-extern inline int pte_exec(pte_t pte)		{ return pte_val(pte) & _PAGE_USER; }
-extern inline int pte_dirty(pte_t pte)		{ return pte_val(pte) & _PAGE_DIRTY; }
-extern inline int pte_young(pte_t pte)		{ return pte_val(pte) & _PAGE_ACCESSED; }
-extern inline int pte_write(pte_t pte)		{ return pte_val(pte) & _PAGE_RW; }
-
-extern inline pte_t pte_rdprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_USER)); return pte; }
-extern inline pte_t pte_exprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_USER)); return pte; }
-extern inline pte_t pte_mkclean(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_DIRTY)); return pte; }
-extern inline pte_t pte_mkold(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_ACCESSED)); return pte; }
-extern inline pte_t pte_wrprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_RW)); return pte; }
-extern inline pte_t pte_mkread(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_USER)); return pte; }
-extern inline pte_t pte_mkexec(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_USER)); return pte; }
-extern inline pte_t pte_mkdirty(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_DIRTY)); return pte; }
-extern inline pte_t pte_mkyoung(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_ACCESSED)); return pte; }
-extern inline pte_t pte_mkwrite(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_RW)); return pte; }
+static inline int pte_read(pte_t pte)		{ return pte_val(pte) & _PAGE_USER; }
+static inline int pte_exec(pte_t pte)		{ return pte_val(pte) & _PAGE_USER; }
+static inline int pte_dirty(pte_t pte)		{ return pte_val(pte) & _PAGE_DIRTY; }
+static inline int pte_young(pte_t pte)		{ return pte_val(pte) & _PAGE_ACCESSED; }
+static inline int pte_write(pte_t pte)		{ return pte_val(pte) & _PAGE_RW; }
+
+static inline pte_t pte_rdprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_USER)); return pte; }
+static inline pte_t pte_exprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_USER)); return pte; }
+static inline pte_t pte_mkclean(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_DIRTY)); return pte; }
+static inline pte_t pte_mkold(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_ACCESSED)); return pte; }
+static inline pte_t pte_wrprotect(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) & ~_PAGE_RW)); return pte; }
+static inline pte_t pte_mkread(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_USER)); return pte; }
+static inline pte_t pte_mkexec(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_USER)); return pte; }
+static inline pte_t pte_mkdirty(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_DIRTY)); return pte; }
+static inline pte_t pte_mkyoung(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_ACCESSED)); return pte; }
+static inline pte_t pte_mkwrite(pte_t pte)	{ set_pte(&pte, __pte(pte_val(pte) | _PAGE_RW)); return pte; }
 static inline  int ptep_test_and_clear_dirty(pte_t *ptep)	{ return test_and_clear_bit(_PAGE_BIT_DIRTY, ptep); }
 static inline  int ptep_test_and_clear_young(pte_t *ptep)	{ return test_and_clear_bit(_PAGE_BIT_ACCESSED, ptep); }
 static inline void ptep_set_wrprotect(pte_t *ptep)		{ clear_bit(_PAGE_BIT_RW, ptep); }
@@ -364,7 +364,7 @@
 	return __pte;
 }
 
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 { 
 	set_pte(&pte, 
 		__pte(((pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot))  &
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/processor.h linux-2.4.25-kdb-trace/include/asm-x86_64/processor.h
--- linux-2.4.25-kdb/include/asm-x86_64/processor.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/processor.h	2005-01-05 16:45:34.000000000 +0100
@@ -109,7 +109,7 @@
  *	Generic CPUID function
  * 	FIXME: This really belongs to msr.h
  */
-extern inline void cpuid(int op, int *eax, int *ebx, int *ecx, int *edx)
+static inline void cpuid(int op, int *eax, int *ebx, int *ecx, int *edx)
 {
 	__asm__("cpuid"
 		: "=a" (*eax),
@@ -122,7 +122,7 @@
 /*
  * CPUID functions returning a single datum
  */
-extern inline unsigned int cpuid_eax(unsigned int op)
+static inline unsigned int cpuid_eax(unsigned int op)
 {
 	unsigned int eax;
 
@@ -132,7 +132,7 @@
 		: "bx", "cx", "dx");
 	return eax;
 }
-extern inline unsigned int cpuid_ebx(unsigned int op)
+static inline unsigned int cpuid_ebx(unsigned int op)
 {
 	unsigned int eax, ebx;
 
@@ -142,7 +142,7 @@
 		: "cx", "dx" );
 	return ebx;
 }
-extern inline unsigned int cpuid_ecx(unsigned int op)
+static inline unsigned int cpuid_ecx(unsigned int op)
 {
 	unsigned int eax, ecx;
 
@@ -152,7 +152,7 @@
 		: "bx", "dx" );
 	return ecx;
 }
-extern inline unsigned int cpuid_edx(unsigned int op)
+static inline unsigned int cpuid_edx(unsigned int op)
 {
 	unsigned int eax, edx;
 
@@ -366,7 +366,7 @@
  * What is this good for? it will be always the scheduler or ret_from_fork.
  */
 
-extern inline unsigned long thread_saved_pc(struct thread_struct *t)
+static inline unsigned long thread_saved_pc(struct thread_struct *t)
 { 
 	return *(unsigned long *)(t->rsp - 8);
 } 
@@ -387,13 +387,13 @@
 #define init_stack	(init_task_union.stack)
 
 /* REP NOP (PAUSE) is a good thing to insert into busy-wait loops. */
-extern inline void rep_nop(void)
+static inline void rep_nop(void)
 {
 	__asm__ __volatile__("rep;nop":::"memory");
 }
 
 /* Avoid speculative execution by the CPU */
-extern inline void sync_core(void)
+static inline void sync_core(void)
 { 
 	int tmp;
 	asm volatile("cpuid" : "=a" (tmp) : "0" (1) : "ebx","ecx","edx","memory");
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/siginfo.h linux-2.4.25-kdb-trace/include/asm-x86_64/siginfo.h
--- linux-2.4.25-kdb/include/asm-x86_64/siginfo.h	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/siginfo.h	2005-01-05 16:45:34.000000000 +0100
@@ -216,7 +216,7 @@
 #ifdef __KERNEL__
 #include <linux/string.h>
 
-extern inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
+static inline void copy_siginfo(siginfo_t *to, siginfo_t *from)
 {
 	if (from->si_code < 0)
 		memcpy(to, from, sizeof(siginfo_t));
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/signal.h linux-2.4.25-kdb-trace/include/asm-x86_64/signal.h
--- linux-2.4.25-kdb/include/asm-x86_64/signal.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/signal.h	2005-01-05 16:45:34.000000000 +0100
@@ -155,23 +155,23 @@
 #undef __HAVE_ARCH_SIG_BITOPS
 #if 0
 
-extern __inline__ void sigaddset(sigset_t *set, int _sig)
+static __inline__ void sigaddset(sigset_t *set, int _sig)
 {
 	__asm__("btsq %1,%0" : "=m"(*set) : "Ir"(_sig - 1) : "cc");
 }
 
-extern __inline__ void sigdelset(sigset_t *set, int _sig)
+static __inline__ void sigdelset(sigset_t *set, int _sig)
 {
 	__asm__("btrq %1,%0" : "=m"(*set) : "Ir"(_sig - 1) : "cc");
 }
 
-extern __inline__ int __const_sigismember(sigset_t *set, int _sig)
+static __inline__ int __const_sigismember(sigset_t *set, int _sig)
 {
 	unsigned long sig = _sig - 1;
 	return 1 & (set->sig[sig / _NSIG_BPW] >> (sig & ~(_NSIG_BPW-1)));
 }
 
-extern __inline__ int __gen_sigismember(sigset_t *set, int _sig)
+static __inline__ int __gen_sigismember(sigset_t *set, int _sig)
 {
 	int ret;
 	__asm__("btq %2,%1\n\tsbbq %0,%0"
@@ -186,7 +186,7 @@
 
 #define sigmask(sig)	(1UL << ((sig) - 1))
 
-extern __inline__ int sigfindinword(unsigned long word)
+static __inline__ int sigfindinword(unsigned long word)
 {
 	__asm__("bsfq %1,%0" : "=r"(word) : "rm"(word) : "cc");
 	return word;
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/smp.h linux-2.4.25-kdb-trace/include/asm-x86_64/smp.h
--- linux-2.4.25-kdb/include/asm-x86_64/smp.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/smp.h	2005-01-05 16:45:34.000000000 +0100
@@ -49,11 +49,11 @@
  * This simplifies scheduling and IPI sending and
  * compresses data structures.
  */
-extern inline int cpu_logical_map(int cpu)
+static inline int cpu_logical_map(int cpu)
 {
 	return cpu;
 }
-extern inline int cpu_number_map(int cpu)
+static inline int cpu_number_map(int cpu)
 {
 	return cpu;
 }
@@ -83,7 +83,7 @@
 #define stack_smp_processor_id() (stack_current()->processor)
 
 
-extern __inline int hard_smp_processor_id(void)
+static __inline int hard_smp_processor_id(void)
 {
 	/* we don't want to mark this access volatile - bad code generation */
 	return GET_APIC_ID(*(unsigned *)(APIC_BASE+APIC_ID));
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/smplock.h linux-2.4.25-kdb-trace/include/asm-x86_64/smplock.h
--- linux-2.4.25-kdb/include/asm-x86_64/smplock.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/smplock.h	2005-01-05 16:45:34.000000000 +0100
@@ -39,7 +39,7 @@
  * so we only need to worry about other
  * CPU's.
  */
-extern __inline__ void lock_kernel(void)
+static __inline__ void lock_kernel(void)
 {
 #if 1
 	if (!++current->lock_depth)
@@ -55,7 +55,7 @@
 #endif
 }
 
-extern __inline__ void unlock_kernel(void)
+static __inline__ void unlock_kernel(void)
 {
 	if (current->lock_depth < 0)
 		out_of_line_bug();
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/socket32.h linux-2.4.25-kdb-trace/include/asm-x86_64/socket32.h
--- linux-2.4.25-kdb/include/asm-x86_64/socket32.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/socket32.h	2005-01-05 16:45:34.000000000 +0100
@@ -10,7 +10,7 @@
 extern struct socket *sockfd_lookup(int fd, int *err);
 
 /* XXX This as well... */
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/spinlock.h linux-2.4.25-kdb-trace/include/asm-x86_64/spinlock.h
--- linux-2.4.25-kdb/include/asm-x86_64/spinlock.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/spinlock.h	2005-01-05 16:45:34.000000000 +0100
@@ -149,7 +149,7 @@
  */
 /* the spinlock helpers are in arch/x86_64/kernel/semaphore.S */
 
-extern inline void read_lock(rwlock_t *rw)
+static inline void read_lock(rwlock_t *rw)
 {
 #if SPINLOCK_DEBUG
 	if (rw->magic != RWLOCK_MAGIC)
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/system.h linux-2.4.25-kdb-trace/include/asm-x86_64/system.h
--- linux-2.4.25-kdb/include/asm-x86_64/system.h	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/system.h	2005-01-05 16:45:34.000000000 +0100
@@ -134,7 +134,7 @@
 
 #define __xg(x) ((volatile long *)(x))
 
-extern inline void set_64bit(volatile unsigned long *ptr, unsigned long val)
+static inline void set_64bit(volatile unsigned long *ptr, unsigned long val)
 {
 	*ptr = val;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/uaccess.h linux-2.4.25-kdb-trace/include/asm-x86_64/uaccess.h
--- linux-2.4.25-kdb/include/asm-x86_64/uaccess.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/uaccess.h	2005-01-05 16:45:34.000000000 +0100
@@ -47,7 +47,7 @@
 
 #define access_ok(type,addr,size) (__range_not_ok(addr,size) == 0)
 
-extern inline int verify_area(int type, const void * addr, unsigned long size)
+static inline int verify_area(int type, const void * addr, unsigned long size)
 {
 	return access_ok(type,addr,size) ? 0 : -EFAULT;
 }
diff -rbNu linux-2.4.25-kdb/include/asm-x86_64/unistd.h linux-2.4.25-kdb-trace/include/asm-x86_64/unistd.h
--- linux-2.4.25-kdb/include/asm-x86_64/unistd.h	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/asm-x86_64/unistd.h	2005-01-05 16:45:34.000000000 +0100
@@ -673,7 +673,7 @@
 }
 
 extern long sys_exit(int) __attribute__((noreturn));
-extern inline long exit(int error_code)
+static inline long exit(int error_code)
 {
 	sys_exit(error_code);
 }
diff -rbNu linux-2.4.25-kdb/include/linux/blkdev.h linux-2.4.25-kdb-trace/include/linux/blkdev.h
--- linux-2.4.25-kdb/include/linux/blkdev.h	2005-01-05 13:49:57.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/blkdev.h	2005-01-05 16:54:56.000000000 +0100
@@ -162,7 +162,7 @@
 #define blk_fs_request(rq)	((rq)->cmd == READ || (rq)->cmd == WRITE)
 #define blk_queue_empty(q)	list_empty(&(q)->queue_head)
 
-extern inline int rq_data_dir(struct request *rq)
+static inline int rq_data_dir(struct request *rq)
 {
 	if (rq->cmd == READ)
 		return READ;
@@ -183,7 +183,7 @@
 
 #ifdef CONFIG_HIGHMEM
 extern struct buffer_head *create_bounce(int, struct buffer_head *);
-extern inline struct buffer_head *blk_queue_bounce(request_queue_t *q, int rw,
+static inline struct buffer_head *blk_queue_bounce(request_queue_t *q, int rw,
 						   struct buffer_head *bh)
 {
 	struct page *page = bh->b_page;
@@ -233,7 +233,7 @@
 extern void grok_partitions(struct gendisk *dev, int drive, unsigned minors, long size);
 extern void register_disk(struct gendisk *dev, kdev_t first, unsigned minors, struct block_device_operations *ops, long size);
 extern void generic_make_request(int rw, struct buffer_head * bh);
-extern inline request_queue_t *blk_get_queue(kdev_t dev);
+extern request_queue_t *blk_get_queue(kdev_t dev);
 extern void blkdev_release_request(struct request *);
 
 /*
@@ -246,7 +246,7 @@
 extern void blk_queue_throttle_sectors(request_queue_t *, int);
 extern void blk_queue_make_request(request_queue_t *, make_request_fn *);
 extern void generic_unplug_device(void *);
-extern inline int blk_seg_merge_ok(struct buffer_head *, struct buffer_head *);
+extern int blk_seg_merge_ok(struct buffer_head *, struct buffer_head *);
 
 extern int * blk_size[MAX_BLKDEV];
 
diff -rbNu linux-2.4.25-kdb/include/linux/fs.h linux-2.4.25-kdb-trace/include/linux/fs.h
--- linux-2.4.25-kdb/include/linux/fs.h	2005-01-05 13:49:57.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/fs.h	2005-01-05 16:54:56.000000000 +0100
@@ -1259,7 +1259,7 @@
 }
 
 extern void set_buffer_flushtime(struct buffer_head *);
-extern inline int get_buffer_flushtime(void);
+extern int get_buffer_flushtime(void);
 extern void balance_dirty(void);
 extern int check_disk_change(kdev_t);
 extern int invalidate_inodes(struct super_block *);
@@ -1523,7 +1523,7 @@
 extern int generic_file_mmap(struct file *, struct vm_area_struct *);
 extern int file_read_actor(read_descriptor_t * desc, struct page *page, unsigned long offset, unsigned long size);
 extern ssize_t generic_file_read(struct file *, char *, size_t, loff_t *);
-extern inline ssize_t do_generic_direct_read(struct file *, char *, size_t, loff_t *);
+extern ssize_t do_generic_direct_read(struct file *, char *, size_t, loff_t *);
 extern int precheck_file_write(struct file *, struct inode *, size_t *, loff_t *);
 extern ssize_t generic_file_write(struct file *, const char *, size_t, loff_t *);
 extern void do_generic_file_read(struct file *, loff_t *, read_descriptor_t *, read_actor_t);
diff -rbNu linux-2.4.25-kdb/include/linux/i2c-proc.h linux-2.4.25-kdb-trace/include/linux/i2c-proc.h
--- linux-2.4.25-kdb/include/linux/i2c-proc.h	2005-01-05 13:52:09.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/i2c-proc.h	2005-01-05 16:57:21.000000000 +0100
@@ -362,7 +362,7 @@
 
 /* This macro is used to scale user-input to sensible values in almost all
    chip drivers. */
-extern inline int SENSORS_LIMIT(long value, long low, long high)
+static inline int SENSORS_LIMIT(long value, long low, long high)
 {
 	if (value < low)
 		return low;
diff -rbNu linux-2.4.25-kdb/include/linux/ide.h linux-2.4.25-kdb-trace/include/linux/ide.h
--- linux-2.4.25-kdb/include/linux/ide.h	2005-01-05 13:52:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/ide.h	2005-01-05 16:57:22.000000000 +0100
@@ -1446,10 +1446,10 @@
 	void			*special;
 } pkt_task_t;
 
-extern inline void SELECT_DRIVE(ide_drive_t *);
-extern inline void SELECT_INTERRUPT(ide_drive_t *);
-extern inline void SELECT_MASK(ide_drive_t *, int);
-extern inline void QUIRK_LIST(ide_drive_t *);
+extern void SELECT_DRIVE(ide_drive_t *);
+extern void SELECT_INTERRUPT(ide_drive_t *);
+extern void SELECT_MASK(ide_drive_t *, int);
+extern void QUIRK_LIST(ide_drive_t *);
 
 extern void ata_input_data(ide_drive_t *, void *, u32);
 extern void ata_output_data(ide_drive_t *, void *, u32);
diff -rbNu linux-2.4.25-kdb/include/linux/intermezzo_fs.h linux-2.4.25-kdb-trace/include/linux/intermezzo_fs.h
--- linux-2.4.25-kdb/include/linux/intermezzo_fs.h	2005-01-05 14:02:17.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/intermezzo_fs.h	2005-01-05 17:11:07.000000000 +0100
@@ -425,8 +425,8 @@
                        struct presto_file_set **);
 /* cache.c */
 extern struct presto_cache *presto_cache_init(void);
-extern inline void presto_cache_add(struct presto_cache *cache, kdev_t dev);
-extern inline void presto_cache_init_hash(void);
+extern void presto_cache_add(struct presto_cache *cache, kdev_t dev);
+extern void presto_cache_init_hash(void);
 
 struct presto_cache *presto_cache_find(kdev_t dev);
 
diff -rbNu linux-2.4.25-kdb/include/linux/kernel_stat.h linux-2.4.25-kdb-trace/include/linux/kernel_stat.h
--- linux-2.4.25-kdb/include/linux/kernel_stat.h	2005-01-05 13:52:55.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/kernel_stat.h	2005-01-05 16:58:09.000000000 +0100
@@ -55,7 +55,7 @@
 /*
  * Number of interrupts per specific IRQ source, since bootup
  */
-extern inline int kstat_irqs (int irq)
+static inline int kstat_irqs (int irq)
 {
 	int i, sum=0;
 
diff -rbNu linux-2.4.25-kdb/include/linux/mtd/compatmac.h linux-2.4.25-kdb-trace/include/linux/mtd/compatmac.h
--- linux-2.4.25-kdb/include/linux/mtd/compatmac.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/linux/mtd/compatmac.h	2005-01-05 16:45:35.000000000 +0100
@@ -85,8 +85,8 @@
 #  else
 #    define cpu_to_be16(x) (x)
 #    define cpu_to_be32(x) (x)
-     extern inline __u16 cpu_to_le16(__u16 x) { return (x<<8) | (x>>8);}
-     extern inline __u32 cpu_to_le32(__u32 x) { return((x>>24) |
+     static inline __u16 cpu_to_le16(__u16 x) { return (x<<8) | (x>>8);}
+     static inline __u32 cpu_to_le32(__u32 x) { return((x>>24) |
              ((x>>8)&0xff00) | ((x<<8)&0xff0000) | (x<<24));}
 #  endif
 
@@ -103,10 +103,10 @@
 #  define cpu_to_be16p(addr) (cpu_to_be16(*(addr)))
 #  define cpu_to_be32p(addr) (cpu_to_be32(*(addr)))
 
-   extern inline void cpu_to_le16s(__u16 *a) {*a = cpu_to_le16(*a);}
-   extern inline void cpu_to_le32s(__u16 *a) {*a = cpu_to_le32(*a);}
-   extern inline void cpu_to_be16s(__u16 *a) {*a = cpu_to_be16(*a);}
-   extern inline void cpu_to_be32s(__u16 *a) {*a = cpu_to_be32(*a);}
+   static inline void cpu_to_le16s(__u16 *a) {*a = cpu_to_le16(*a);}
+   static inline void cpu_to_le32s(__u16 *a) {*a = cpu_to_le32(*a);}
+   static inline void cpu_to_be16s(__u16 *a) {*a = cpu_to_be16(*a);}
+   static inline void cpu_to_be32s(__u16 *a) {*a = cpu_to_be32(*a);}
 
 #  define le16_to_cpup(x) cpu_to_le16p(x)
 #  define le32_to_cpup(x) cpu_to_le32p(x)
diff -rbNu linux-2.4.25-kdb/include/linux/netfilter_ipv4/ip_conntrack.h linux-2.4.25-kdb-trace/include/linux/netfilter_ipv4/ip_conntrack.h
--- linux-2.4.25-kdb/include/linux/netfilter_ipv4/ip_conntrack.h	2005-01-05 14:04:57.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/netfilter_ipv4/ip_conntrack.h	2005-01-05 17:14:10.000000000 +0100
@@ -228,7 +228,7 @@
 ip_conntrack_get(struct sk_buff *skb, enum ip_conntrack_info *ctinfo);
 
 /* decrement reference count on a conntrack */
-extern inline void ip_conntrack_put(struct ip_conntrack *ct);
+extern void ip_conntrack_put(struct ip_conntrack *ct);
 
 /* find unconfirmed expectation based on tuple */
 struct ip_conntrack_expect *
diff -rbNu linux-2.4.25-kdb/include/linux/parport_pc.h linux-2.4.25-kdb-trace/include/linux/parport_pc.h
--- linux-2.4.25-kdb/include/linux/parport_pc.h	2001-11-14 23:52:47.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/parport_pc.h	2005-01-05 16:45:35.000000000 +0100
@@ -41,7 +41,7 @@
 	struct pci_dev *dev;
 };
 
-extern __inline__ void parport_pc_write_data(struct parport *p, unsigned char d)
+static __inline__ void parport_pc_write_data(struct parport *p, unsigned char d)
 {
 #ifdef DEBUG_PARPORT
 	printk (KERN_DEBUG "parport_pc_write_data(%p,0x%02x)\n", p, d);
@@ -49,7 +49,7 @@
 	outb(d, DATA(p));
 }
 
-extern __inline__ unsigned char parport_pc_read_data(struct parport *p)
+static __inline__ unsigned char parport_pc_read_data(struct parport *p)
 {
 	unsigned char val = inb (DATA (p));
 #ifdef DEBUG_PARPORT
@@ -60,7 +60,7 @@
 }
 
 #ifdef DEBUG_PARPORT
-extern __inline__ void dump_parport_state (char *str, struct parport *p)
+static __inline__ void dump_parport_state (char *str, struct parport *p)
 {
 	/* here's hoping that reading these ports won't side-effect anything underneath */
 	unsigned char ecr = inb (ECONTROL (p));
@@ -124,17 +124,17 @@
 	return ctr;
 }
 
-extern __inline__ void parport_pc_data_reverse (struct parport *p)
+static __inline__ void parport_pc_data_reverse (struct parport *p)
 {
 	__parport_pc_frob_control (p, 0x20, 0x20);
 }
 
-extern __inline__ void parport_pc_data_forward (struct parport *p)
+static __inline__ void parport_pc_data_forward (struct parport *p)
 {
 	__parport_pc_frob_control (p, 0x20, 0x00);
 }
 
-extern __inline__ void parport_pc_write_control (struct parport *p,
+static __inline__ void parport_pc_write_control (struct parport *p,
 						 unsigned char d)
 {
 	const unsigned char wm = (PARPORT_CONTROL_STROBE |
@@ -152,7 +152,7 @@
 	__parport_pc_frob_control (p, wm, d & wm);
 }
 
-extern __inline__ unsigned char parport_pc_read_control(struct parport *p)
+static __inline__ unsigned char parport_pc_read_control(struct parport *p)
 {
 	const unsigned char rm = (PARPORT_CONTROL_STROBE |
 				  PARPORT_CONTROL_AUTOFD |
@@ -162,7 +162,7 @@
 	return priv->ctr & rm; /* Use soft copy */
 }
 
-extern __inline__ unsigned char parport_pc_frob_control (struct parport *p,
+static __inline__ unsigned char parport_pc_frob_control (struct parport *p,
 							 unsigned char mask,
 							 unsigned char val)
 {
@@ -189,18 +189,18 @@
 	return __parport_pc_frob_control (p, mask, val);
 }
 
-extern __inline__ unsigned char parport_pc_read_status(struct parport *p)
+static __inline__ unsigned char parport_pc_read_status(struct parport *p)
 {
 	return inb(STATUS(p));
 }
 
 
-extern __inline__ void parport_pc_disable_irq(struct parport *p)
+static __inline__ void parport_pc_disable_irq(struct parport *p)
 {
 	__parport_pc_frob_control (p, 0x10, 0x00);
 }
 
-extern __inline__ void parport_pc_enable_irq(struct parport *p)
+static __inline__ void parport_pc_enable_irq(struct parport *p)
 {
 	__parport_pc_frob_control (p, 0x10, 0x10);
 }
diff -rbNu linux-2.4.25-kdb/include/linux/quota.h linux-2.4.25-kdb-trace/include/linux/quota.h
--- linux-2.4.25-kdb/include/linux/quota.h	2005-01-05 13:49:57.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/quota.h	2005-01-05 16:54:56.000000000 +0100
@@ -172,7 +172,7 @@
 #define DQF_INFO_DIRTY 0x10000  /* Is info dirty? */
 #define DQF_ANY_DQUOT_DIRTY 0x20000	/* Is any dquot dirty? */
 
-extern inline void mark_info_dirty(struct mem_dqinfo *info)
+static inline void mark_info_dirty(struct mem_dqinfo *info)
 {
 	info->dqi_flags |= DQF_INFO_DIRTY;
 }
diff -rbNu linux-2.4.25-kdb/include/linux/quotaops.h linux-2.4.25-kdb-trace/include/linux/quotaops.h
--- linux-2.4.25-kdb/include/linux/quotaops.h	2005-01-05 14:02:29.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/quotaops.h	2005-01-05 17:11:20.000000000 +0100
@@ -194,7 +194,7 @@
 #define DQUOT_SYNC_SB(sb)			do { } while(0)
 #define DQUOT_OFF(sb)				do { } while(0)
 #define DQUOT_TRANSFER(inode, iattr)		(0)
-extern __inline__ int DQUOT_PREALLOC_SPACE_NODIRTY(struct inode *inode, qsize_t nr)
+static __inline__ int DQUOT_PREALLOC_SPACE_NODIRTY(struct inode *inode, qsize_t nr)
 {
 	lock_kernel();
 	inode_add_bytes(inode, nr);
@@ -202,14 +202,14 @@
 	return 0;
 }
 
-extern __inline__ int DQUOT_PREALLOC_SPACE(struct inode *inode, qsize_t nr)
+static __inline__ int DQUOT_PREALLOC_SPACE(struct inode *inode, qsize_t nr)
 {
 	DQUOT_PREALLOC_SPACE_NODIRTY(inode, nr);
 	mark_inode_dirty(inode);
 	return 0;
 }
 
-extern __inline__ int DQUOT_ALLOC_SPACE_NODIRTY(struct inode *inode, qsize_t nr)
+static __inline__ int DQUOT_ALLOC_SPACE_NODIRTY(struct inode *inode, qsize_t nr)
 {
 	lock_kernel();
 	inode_add_bytes(inode, nr);
@@ -217,21 +217,21 @@
 	return 0;
 }
 
-extern __inline__ int DQUOT_ALLOC_SPACE(struct inode *inode, qsize_t nr)
+static __inline__ int DQUOT_ALLOC_SPACE(struct inode *inode, qsize_t nr)
 {
 	DQUOT_ALLOC_SPACE_NODIRTY(inode, nr);
 	mark_inode_dirty(inode);
 	return 0;
 }
 
-extern __inline__ void DQUOT_FREE_SPACE_NODIRTY(struct inode *inode, qsize_t nr)
+static __inline__ void DQUOT_FREE_SPACE_NODIRTY(struct inode *inode, qsize_t nr)
 {
 	lock_kernel();
 	inode_sub_bytes(inode, nr);
 	unlock_kernel();
 }
 
-extern __inline__ void DQUOT_FREE_SPACE(struct inode *inode, qsize_t nr)
+static __inline__ void DQUOT_FREE_SPACE(struct inode *inode, qsize_t nr)
 {
 	DQUOT_FREE_SPACE_NODIRTY(inode, nr);
 	mark_inode_dirty(inode);
diff -rbNu linux-2.4.25-kdb/include/linux/reiserfs_fs.h linux-2.4.25-kdb-trace/include/linux/reiserfs_fs.h
--- linux-2.4.25-kdb/include/linux/reiserfs_fs.h	2005-01-05 14:02:23.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/reiserfs_fs.h	2005-01-05 17:11:14.000000000 +0100
@@ -1770,26 +1770,26 @@
 
 /* stree.c */
 int B_IS_IN_TREE(const struct buffer_head *);
-extern inline void copy_short_key (void * to, const void * from);
-extern inline void copy_item_head(struct item_head * p_v_to, 
+extern void copy_short_key (void * to, const void * from);
+extern void copy_item_head(struct item_head * p_v_to, 
 								  const struct item_head * p_v_from);
 
 // first key is in cpu form, second - le
-extern inline int comp_keys (const struct key * le_key, 
+extern int comp_keys (const struct key * le_key, 
 			     const struct cpu_key * cpu_key);
-extern inline int  comp_short_keys (const struct key * le_key, 
+extern int  comp_short_keys (const struct key * le_key, 
 				    const struct cpu_key * cpu_key);
-extern inline void le_key2cpu_key (struct cpu_key * to, const struct key * from);
+extern void le_key2cpu_key (struct cpu_key * to, const struct key * from);
 
 // both are cpu keys
-extern inline int comp_cpu_keys (const struct cpu_key *, const struct cpu_key *);
-extern inline int comp_short_cpu_keys (const struct cpu_key *, 
+extern int comp_cpu_keys (const struct cpu_key *, const struct cpu_key *);
+extern int comp_short_cpu_keys (const struct cpu_key *, 
 				       const struct cpu_key *);
-extern inline void cpu_key2cpu_key (struct cpu_key *, const struct cpu_key *);
+extern void cpu_key2cpu_key (struct cpu_key *, const struct cpu_key *);
 
 // both are in le form
-extern inline int comp_le_keys (const struct key *, const struct key *);
-extern inline int comp_short_le_keys (const struct key *, const struct key *);
+extern int comp_le_keys (const struct key *, const struct key *);
+extern int comp_short_le_keys (const struct key *, const struct key *);
 
 //
 // get key version from on disk key - kludge
@@ -1824,7 +1824,7 @@
 int search_for_position_by_key (struct super_block * p_s_sb, 
 								const struct cpu_key * p_s_cpu_key, 
 								struct path * p_s_search_path);
-extern inline void decrement_bcount (struct buffer_head * p_s_bh);
+extern void decrement_bcount (struct buffer_head * p_s_bh);
 void decrement_counters_in_path (struct path * p_s_search_path);
 void pathrelse (struct path * p_s_search_path);
 int reiserfs_check_path(struct path *p) ;
@@ -2097,7 +2097,7 @@
 int is_reusable (struct super_block * s, unsigned long block, int bit_value);
 void reiserfs_free_block (struct reiserfs_transaction_handle *th, unsigned long);
 int reiserfs_allocate_blocknrs(reiserfs_blocknr_hint_t *, b_blocknr_t * , int, int);
-extern inline int reiserfs_new_form_blocknrs (struct tree_balance * tb,
+static inline int reiserfs_new_form_blocknrs (struct tree_balance * tb,
 					      b_blocknr_t *new_blocknrs, int amount_needed)
 {
     reiserfs_blocknr_hint_t hint = {
@@ -2111,7 +2111,7 @@
     return reiserfs_allocate_blocknrs(&hint, new_blocknrs, amount_needed, 0);
 }
 
-extern inline int reiserfs_new_unf_blocknrs (struct reiserfs_transaction_handle *th,
+static inline int reiserfs_new_unf_blocknrs (struct reiserfs_transaction_handle *th,
 					     struct inode *inode,
 					     b_blocknr_t *new_blocknrs,
 					     struct path * path, long block)
@@ -2128,7 +2128,7 @@
 }
 
 #ifdef REISERFS_PREALLOCATE
-extern inline int reiserfs_new_unf_blocknrs2(struct reiserfs_transaction_handle *th,
+static inline int reiserfs_new_unf_blocknrs2(struct reiserfs_transaction_handle *th,
 					     struct inode * inode,
 					     b_blocknr_t *new_blocknrs,
 					     struct path * path, long block)
diff -rbNu linux-2.4.25-kdb/include/linux/sched.h linux-2.4.25-kdb-trace/include/linux/sched.h
--- linux-2.4.25-kdb/include/linux/sched.h	2005-01-05 13:49:57.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/sched.h	2005-01-05 16:54:56.000000000 +0100
@@ -763,7 +763,7 @@
 extern void end_lazy_tlb(struct mm_struct *mm);
 
 /* mmdrop drops the mm and the page tables */
-extern inline void FASTCALL(__mmdrop(struct mm_struct *));
+extern void FASTCALL(__mmdrop(struct mm_struct *));
 static inline void mmdrop(struct mm_struct * mm)
 {
 	if (atomic_dec_and_test(&mm->mm_count))
diff -rbNu linux-2.4.25-kdb/include/linux/sysrq.h linux-2.4.25-kdb-trace/include/linux/sysrq.h
--- linux-2.4.25-kdb/include/linux/sysrq.h	2005-01-05 14:07:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/linux/sysrq.h	2005-01-05 17:16:49.000000000 +0100
@@ -56,7 +56,7 @@
 struct sysrq_key_op *__sysrq_get_key_op (int key);
 void __sysrq_put_key_op (int key, struct sysrq_key_op *op_p);
 
-extern __inline__ int
+static __inline__ int
 __sysrq_swap_key_ops_nolock(int key, struct sysrq_key_op *insert_op_p,
 				struct sysrq_key_op *remove_op_p)
 {
@@ -70,7 +70,7 @@
 	return retval;
 }
 
-extern __inline__ int
+static __inline__ int
 __sysrq_swap_key_ops(int key, struct sysrq_key_op *insert_op_p,
 				struct sysrq_key_op *remove_op_p) {
 	int retval;
diff -rbNu linux-2.4.25-kdb/include/net/ax25.h linux-2.4.25-kdb-trace/include/net/ax25.h
--- linux-2.4.25-kdb/include/net/ax25.h	2005-01-05 13:50:05.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/net/ax25.h	2005-01-05 16:55:06.000000000 +0100
@@ -343,8 +343,8 @@
 extern void ax25_register_sysctl(void);
 extern void ax25_unregister_sysctl(void);
 #else
-extern inline void ax25_register_sysctl(void) {};
-extern inline void ax25_unregister_sysctl(void) {};
+static inline void ax25_register_sysctl(void) {};
+static inline void ax25_unregister_sysctl(void) {};
 #endif /* CONFIG_SYSCTL */
 
 #endif
diff -rbNu linux-2.4.25-kdb/include/net/ip.h linux-2.4.25-kdb-trace/include/net/ip.h
--- linux-2.4.25-kdb/include/net/ip.h	2005-01-05 13:53:44.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/net/ip.h	2005-01-05 16:59:00.000000000 +0100
@@ -137,7 +137,7 @@
 void ip_send_reply(struct sock *sk, struct sk_buff *skb, struct ip_reply_arg *arg,
 		   unsigned int len); 
 
-extern __inline__ int ip_finish_output(struct sk_buff *skb);
+extern int ip_finish_output(struct sk_buff *skb);
 
 struct ipv4_config
 {
diff -rbNu linux-2.4.25-kdb/include/net/ip_vs.h linux-2.4.25-kdb-trace/include/net/ip_vs.h
--- linux-2.4.25-kdb/include/net/ip_vs.h	2005-01-05 14:04:47.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/net/ip_vs.h	2005-01-05 17:13:57.000000000 +0100
@@ -760,7 +760,7 @@
  */
 #define IP_VS_FWD_METHOD(cp)  (cp->flags & IP_VS_CONN_F_FWD_MASK)
 
-extern __inline__ char ip_vs_fwd_tag(struct ip_vs_conn *cp)
+static __inline__ char ip_vs_fwd_tag(struct ip_vs_conn *cp)
 {
 	char fwd;
 
@@ -785,7 +785,7 @@
 /*
  *	transport layer header checking
  */
-extern inline int ip_vs_header_check(struct sk_buff *skb, int proto, int ihl)
+static inline int ip_vs_header_check(struct sk_buff *skb, int proto, int ihl)
 {
 	int len;
 
diff -rbNu linux-2.4.25-kdb/include/net/irda/irda_device.h linux-2.4.25-kdb-trace/include/net/irda/irda_device.h
--- linux-2.4.25-kdb/include/net/irda/irda_device.h	2005-01-05 13:55:42.000000000 +0100
+++ linux-2.4.25-kdb-trace/include/net/irda/irda_device.h	2005-01-05 17:01:46.000000000 +0100
@@ -202,7 +202,7 @@
 )
 
 #if 0
-extern inline __u16 irda_get_mtt(struct sk_buff *skb)
+static inline __u16 irda_get_mtt(struct sk_buff *skb)
 {
 	__u16 mtt;
 
@@ -230,7 +230,7 @@
 )
 
 #if 0
-extern inline __u32 irda_get_next_speed(struct sk_buff *skb)
+static inline __u32 irda_get_next_speed(struct sk_buff *skb)
 {
 	__u32 speed;
 
diff -rbNu linux-2.4.25-kdb/include/video/newport.h linux-2.4.25-kdb-trace/include/video/newport.h
--- linux-2.4.25-kdb/include/video/newport.h	2001-04-12 21:20:31.000000000 +0200
+++ linux-2.4.25-kdb-trace/include/video/newport.h	2005-01-05 16:45:38.000000000 +0100
@@ -384,7 +384,7 @@
 #define VC2_IREG_CONTROL       0x10
 #define VC2_IREG_CONFIG        0x20
 
-extern __inline__ void newport_vc2_set(struct newport_regs *regs, unsigned char vc2ireg,
+static __inline__ void newport_vc2_set(struct newport_regs *regs, unsigned char vc2ireg,
 				   unsigned short val)
 {
 	regs->set.dcbmode = (NPORT_DMODE_AVC2 | VC2_REGADDR_INDEX | NPORT_DMODE_W3 |
@@ -392,7 +392,7 @@
 	regs->set.dcbdata0.byword = (vc2ireg << 24) | (val << 8);
 }
 
-extern __inline__ unsigned short newport_vc2_get(struct newport_regs *regs,
+static __inline__ unsigned short newport_vc2_get(struct newport_regs *regs,
 					     unsigned char vc2ireg)
 {
 	regs->set.dcbmode = (NPORT_DMODE_AVC2 | VC2_REGADDR_INDEX | NPORT_DMODE_W1 |
diff -rbNu linux-2.4.25-kdb/ipc/util.h linux-2.4.25-kdb-trace/ipc/util.h
--- linux-2.4.25-kdb/ipc/util.h	2002-11-29 00:53:15.000000000 +0100
+++ linux-2.4.25-kdb-trace/ipc/util.h	2005-01-05 16:45:53.000000000 +0100
@@ -45,12 +45,12 @@
 void* ipc_alloc(int size);
 void ipc_free(void* ptr, int size);
 
-extern inline void ipc_lockall(struct ipc_ids* ids)
+static inline void ipc_lockall(struct ipc_ids* ids)
 {
 	spin_lock(&ids->ary);
 }
 
-extern inline struct kern_ipc_perm* ipc_get(struct ipc_ids* ids, int id)
+static inline struct kern_ipc_perm* ipc_get(struct ipc_ids* ids, int id)
 {
 	struct kern_ipc_perm* out;
 	int lid = id % SEQ_MULTIPLIER;
@@ -61,11 +61,11 @@
 	return out;
 }
 
-extern inline void ipc_unlockall(struct ipc_ids* ids)
+static inline void ipc_unlockall(struct ipc_ids* ids)
 {
 	spin_unlock(&ids->ary);
 }
-extern inline struct kern_ipc_perm* ipc_lock(struct ipc_ids* ids, int id)
+static inline struct kern_ipc_perm* ipc_lock(struct ipc_ids* ids, int id)
 {
 	struct kern_ipc_perm* out;
 	int lid = id % SEQ_MULTIPLIER;
@@ -79,17 +79,17 @@
 	return out;
 }
 
-extern inline void ipc_unlock(struct ipc_ids* ids, int id)
+static inline void ipc_unlock(struct ipc_ids* ids, int id)
 {
 	spin_unlock(&ids->ary);
 }
 
-extern inline int ipc_buildid(struct ipc_ids* ids, int id, int seq)
+static inline int ipc_buildid(struct ipc_ids* ids, int id, int seq)
 {
 	return SEQ_MULTIPLIER*seq + id;
 }
 
-extern inline int ipc_checkid(struct ipc_ids* ids, struct kern_ipc_perm* ipcp, int uid)
+static inline int ipc_checkid(struct ipc_ids* ids, struct kern_ipc_perm* ipcp, int uid)
 {
 	if(uid/SEQ_MULTIPLIER != ipcp->seq)
 		return 1;
diff -rbNu linux-2.4.25-kdb/kdb/Makefile linux-2.4.25-kdb-trace/kdb/Makefile
--- linux-2.4.25-kdb/kdb/Makefile	2005-01-05 13:39:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/kdb/Makefile	2005-01-05 16:09:40.000000000 +0100
@@ -34,6 +34,9 @@
 export-objs	:= kdbmain.o kdb_io.o
 obj-y		:= kdb_bt.o kdb_bp.o kdb_id.o kdbsupport.o gen-kdb_cmds.o kdbmain.o kdb_io.o
 
+obj-$(CONFIG_INSTRUMENT_FUNC) += kdb_tr.o
+CFLAGS_kdb_tr.o += -finline
+
 subdir-$(CONFIG_KDB_MODULES) := modules
 obj-y += $(addsuffix /vmlinux-obj.o, $(subdir-y))
 
diff -rbNu linux-2.4.25-kdb/kdb/kdb_tr.c linux-2.4.25-kdb-trace/kdb/kdb_tr.c
--- linux-2.4.25-kdb/kdb/kdb_tr.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.25-kdb-trace/kdb/kdb_tr.c	2005-01-05 16:09:40.000000000 +0100
@@ -0,0 +1,601 @@
+/*
+ * Copyright (C) 2002 Jim Houston jhouston@ma.ultranet.com
+ *
+ * This software may be used and distributed according to the terms
+ * of the GNU General Public License (GPL), incorporated herein by
+ * reference.
+ *
+ * Its a quick hack to trace the kernel at the function call level
+ * using the -finstrument-functions compiler option. The trace is
+ * stored in a circular buffer.
+ *
+ * Here is a summary of the new commands it adds to kdb:
+ *
+ * tr <trace buffer offset>
+ * Display content of trace buffer.
+ * tre
+ * tre <functions>
+ * Enable tracing of all function calls, or the
+ * specified functions.
+ * trd
+ * tre <functions>
+ * Disable tracing all functions, or the specifed
+ * functions.
+ * trc
+ * trc <function>
+ * Clear list of per function trace requests, or remove
+ * the 'trd' or 'tre' entry for the specified function.
+ * trp
+ * Print list of functions which have been explicity
+ * enabled or disabled for tracing.
+ * trstop
+ * trstart
+ * Global control to disable/re-enable tracing. You
+ * might use trstop to stop tracing so that the trace
+ * could be read with a user level tool.
+ *
+ */
+
+#include <linux/string.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/kdb.h>
+#include <linux/kdbprivate.h>
+#include <linux/smp.h>
+#include <linux/sched.h>
+#include <asm/system.h>
+#include <asm/div64.h>
+#include "kdb_tr.h"
+
+char *trc_tname[] = { "call", "ret ", "user " };
+
+struct trce trc_buf[TRC_SZ];
+struct trc trc = { TRC_ENABLE, TRC_ENABLE, trc_buf, TRC_SZ-1, 0, 0 };
+struct trc *trcp = &trc;
+
+void
+kdb_trc_init()
+{
+ kdb_register_repeat("tr", kdb_tr, "<range>",
+ "Display kernel trace", 0, KDB_REPEAT_NONE);
+ kdb_register_repeat("trp", kdb_trp, "",
+ "Display trace enable/disable status", 0, KDB_REPEAT_NONE);
+ kdb_register_repeat("tre", kdb_tre, "<func>",
+ "Enable trace for function", 0, KDB_REPEAT_NONE);
+ kdb_register_repeat("trd", kdb_trd, "<func>",
+ "Disable trace for function", 0, KDB_REPEAT_NONE);
+ kdb_register_repeat("trc", kdb_trc, "<func>",
+ "Clear per function trace enable/disble", 0, KDB_REPEAT_NONE);
+ kdb_register_repeat("trstop", kdb_trstop, "",
+ "Disable kernel trace", 0, KDB_REPEAT_NONE);
+ kdb_register_repeat("trstart", kdb_trstart, "",
+ "Enable kernel trace", 0, KDB_REPEAT_NONE);
+}
+/*
+ * Simple hash table to control the trace. Each function entry
+ * and exit goes through here so it has to be quick. Its a fixed
+ * sized hash table with the data store directly in the hash table.
+ */
+struct trc_hash trc_hash[TRC_HASH_SZ];
+int trc_hash_cnt = 0;
+
+inline int trc_hashfn(kdb_machreg_t addr)
+{
+ unsigned int i = (unsigned int) addr;
+
+ return((i ^ (i >> 5) ^ (i >> 10) ^ (i >> 15)) % TRC_HASH_SZ);
+}
+
+
+inline int trc_get_flags(kdb_machreg_t addr)
+{
+ unsigned int i, flags;
+
+ i = trc_hashfn(addr);
+ for ( ; (flags = trc_hash[i].flags) ; i = (i+1) % TRC_HASH_SZ)
+ if (trc_hash[i].addr == addr)
+ return(flags);
+ return(0);
+}
+
+
+/*
+ * Create or update a hash table entry.
+ */
+
+void
+trc_set_flags(kdb_machreg_t addr, int flags)
+{
+ int i;
+
+ if (!flags)
+ return;
+ i = trc_hashfn(addr);
+ for ( ; trc_hash[i].flags ; i = (i+1) % TRC_HASH_SZ)
+ if (trc_hash[i].addr == addr) {
+ trc_hash[i].flags = flags;
+ return;
+ }
+ /*
+ * Seaches take literally forever if the table is completly full.
+ * Warn and fail if the table is more than half full.
+ */
+ if (trc_hash_cnt >= TRC_HASH_SZ/2) {
+ kdb_printf("no more entries\n");
+ return;
+ }
+ trc_hash_cnt++;
+ trc_hash[i].addr = addr;
+ trc_hash[i].flags = flags;
+}
+
+void
+trc_clr_flags(kdb_machreg_t addr)
+{
+ int i, flags;
+
+ i = trc_hashfn(addr);
+ for ( ; ; i = (i+1) % TRC_HASH_SZ) {
+ if (!(flags = trc_hash[i].flags))
+ return;
+ if (trc_hash[i].addr == addr)
+ break;
+ }
+
+ /*
+ * Found it. Take it out.
+ */
+ trc_hash[i].addr = 0;
+ trc_hash[i].flags = 0;
+ trc_hash_cnt--;
+ /*
+ * Now check that adjacent entries don't get lost.
+ */
+ i = (i+1) % TRC_HASH_SZ;
+ for ( ; (flags = trc_hash[i].flags); i = (i+1) % TRC_HASH_SZ) {
+ if (i != trc_hashfn(trc_hash[i].addr)) {
+ /*
+ * This entry might want the slot we just
+ * cleared, take it out and put it back in.
+ */
+ addr = trc_hash[i].addr;
+ trc_hash[i].addr = 0;
+ trc_hash[i].flags = 0;
+ trc_set_flags(addr, flags);
+ }
+ }
+}
+
+void
+trc_clr_all_flags( void )
+{
+ int i;
+
+ for (i = 0; i < TRC_HASH_SZ; i++) {
+ trc_hash[i].addr = 0;
+ trc_hash[i].flags = 0;
+ }
+ trc_hash_cnt = 0;
+}
+void
+
+trc_print_hash( void )
+{
+ int i;
+
+ for (i = 0; i < TRC_HASH_SZ; i++) {
+ if (trc_hash[i].flags) {
+ if (trc_hash[i].flags & TRC_ENABLE)
+ kdb_printf("ENABLE ");
+ if (trc_hash[i].flags & TRC_DISABLE)
+ kdb_printf("DISABLE ");
+ kdb_symbol_print(trc_hash[i].addr, NULL, KDB_SP_DEFAULT);
+ kdb_printf("\n");
+ }
+
+ }
+}
+
+/*
+ * Functions to disable/re-enable the trace on entry to kdb.
+ */
+void kdb_trc_disable( void )
+{
+ struct trc *tp;
+
+ tp = trcp;
+ if (!tp)
+ return;
+ tp->enable_save = tp->enable;
+ tp->enable = 0;
+}
+
+void kdb_trc_continue( void )
+{
+ struct trc *tp;
+
+ tp = trcp;
+ if (!tp)
+ return;
+ tp->enable = tp->enable_save;
+}
+
+
+static inline struct trce *next_t(struct trc *tp)
+{
+ unsigned int i;
+
+ /* It would be nice if this was atomic */
+ if ((i = tp->offset++) == ~0)
+ tp->offsetu++;
+ return(&(tp->buf[i & tp->mask]));
+}
+
+void  __cyg_profile_func_enter(kdb_machreg_t  this_fn,  kdb_machreg_t call_site)
+{
+ register unsigned int t1, t2;
+ struct trc *tp;
+ struct trce *t;
+ kdb_machreg_t *fp = __builtin_frame_address(1);
+
+ tp = trcp;
+ if (!tp || tp->enable & TRC_STOP)
+ return;
+ t1 = trc_get_flags((kdb_machreg_t)this_fn);
+ if ((tp->enable | t1) != TRC_ENABLE)
+ return;
+ rdtsc(t1,t2);
+ t = next_t(tp);
+ t->time = t1;
+ t->timeu = t2;
+ t->type = T_ENTER;
+ t->a1 = this_fn;
+ t->a2 = call_site;
+ /*
+ * Save the frame ptr and first 3 args
+ */
+ t->a3 = (kdb_machreg_t)fp;
+ t->a4 = fp[2];
+ t->a5 = fp[3];
+ t->a6 = fp[4];
+}
+
+void   __cyg_profile_func_exit(kdb_machreg_t  this_fn,  kdb_machreg_t call_site)
+{
+ register unsigned int t1, t2;
+ struct trc *tp;
+ struct trce *t;
+
+ tp = trcp;
+ if (!tp || tp->enable & TRC_STOP)
+ return;
+ t1 = trc_get_flags((kdb_machreg_t)this_fn);
+ if ((tp->enable | t1) != TRC_ENABLE)
+ return;
+ rdtsc(t1,t2);
+ t = next_t(tp);
+ t->time = t1;
+ t->timeu = t2;
+ t->type = T_EXIT;
+ t->a1 = this_fn;
+ t->a2 = call_site;
+}
+
+void __trace_user(kdb_machreg_t a1, kdb_machreg_t a2)
+{
+ register unsigned int t1, t2;
+ struct trc *tp;
+ struct trce *t;
+
+ tp = trcp;
+ if (!tp || tp->enable & TRC_STOP)
+ return;
+ rdtsc(t1,t2);
+ t = next_t(tp);
+ t->time = t1;
+ t->timeu = t2;
+ t->type = T_USER;
+ t->a1 = a1;
+ t->a2 = a2;
+}
+
+
+void __trace_stop()
+{
+ struct trc *tp;
+
+ tp = trcp;
+ tp->enable |= TRC_STOP;
+}
+
+/*
+ * Choose format for time, absolute cycles, delta from previous line
+ * or relative to most recent sample.
+ */
+enum tm_format { absolute, delta, relative };
+char *tfname[] = {"absolute", "delta", "relative", 0 };
+
+enum tm_format
+get_time_format(void)
+{
+ enum tm_format i;
+ char *s;
+
+ if ((s = kdbgetenv("TIME_FORMAT")))
+ for (i = absolute; ; i++) {
+ if (tfname[i] && strcmp(tfname[i], s) == 0)
+ return(i);
+ }
+ return(relative);
+}
+
+
+extern unsigned long fast_gettimeoffset_quotient;
+
+char *frac_format[] = { " ", ".%01d ", ".%02d ", ".%03d ", ".%04d ",
+ ".%05d ", ".%06d ", ".%07d ", ".%08d "};
+
+void
+display_time(unsigned long long dt)
+{
+ int n;
+ unsigned int de, frac;
+ char *unit;
+ int n_digits, min_frac;
+ unsigned int cycles;
+ unsigned long long ll;
+
+ ll = 1LL << 32;
+ do_div(ll, fast_gettimeoffset_quotient);
+ cycles = (unsigned int)ll;
+
+ /* guess how many significant digits we have, count the bits */
+ /* and multiply by log10(2) */
+ for (n = 0; n < 63 && dt > (1LL << n); n++) ;
+ n_digits = (n * 1233) >> 12;
+
+ min_frac = 0;
+ if (dt < 1000*cycles) {
+ de = cycles;
+ unit = "us";
+ min_frac = 2;
+ } else if (dt < 1000000*cycles) {
+ de = cycles * 1000;
+ unit = "ms";
+ min_frac = 3;
+ } else {
+ de = cycles * 1000000;
+ unit = "s";
+ }
+ frac = do_div(dt, de);
+ /* Pick number of digits for fraction */
+ for (n = 0; n < 63 && dt > (1LL << n); n++) ;
+ n_digits -= (n * 1233) >> 12;
+ if (n_digits < min_frac)
+ n_digits = min_frac;
+
+ if (n_digits > 7)
+ n_digits = 7;
+ kdb_printf("%d", (unsigned int)dt);
+ dt = frac;
+ for (n = 0; n < n_digits; n++)
+ dt *= 10;
+ dt += de/2;
+ frac = do_div(dt, de);
+ kdb_printf(frac_format[n_digits], (unsigned int)dt);
+ kdb_printf("%s ", unit);
+}
+
+void
+kdb_tr_display(unsigned int from, unsigned int to)
+{
+ unsigned int i;
+ struct trc *tp;
+ struct trce *t;
+ enum tm_format tf;
+ long long t0, t1;
+
+ tp = trcp;
+ if (!tp) {
+ kdb_printf("No trace buffer?\n");
+ return;
+ }
+ if ((from & ~tp->mask) || (to & ~tp->mask)) {
+ kdb_printf("Offset larger than trace buffer?\n");
+ return;
+ }
+ tf =get_time_format();
+
+ if (tf == relative)
+ t = &(tp->buf[(tp->offset-1) & tp->mask]);
+ else
+ t = &(tp->buf[(tp->offset-from-1) & tp->mask]);
+ t0 = (unsigned long long)t->timeu << 32;
+ t0 |= t->time;
+ for (i = from; i <= to; i++) {
+ t = &(tp->buf[(tp->offset-i-1) & tp->mask]);
+ kdb_printf("%3d %s ", i, trc_tname[t->type]);
+ if (tf == absolute)
+ kdb_printf("%6x%08x ", t->timeu, t->time);
+ else {
+ t1 = (unsigned long long)t->timeu << 32;
+ t1 |= t->time;
+ display_time(t0 - t1);
+ if (tf == delta)
+ t0 = t1;
+ }
+ kdb_symbol_print((kdb_machreg_t)t->a1, NULL, KDB_SP_DEFAULT);
+ kdb_printf(" ");
+ kdb_symbol_print((kdb_machreg_t)t->a2, NULL, KDB_SP_DEFAULT);
+ kdb_printf("\n");
+ if (t->type == T_ENTER) {
+ kdb_printf(" fp=%08lx args = %08lx %08lx %08lx\n",
+ t->a3, t->a4, t->a5, t->a6);
+ }
+ }
+}
+
+
+int
+kdb_tr(int argc, const char **argv, const char **envp, struct pt_regs *regs)
+{
+ unsigned int from, to;
+ struct trc *tp;
+
+ tp = trcp;
+ /*
+ * default to display the whole buffer.
+ */
+ from = 0;
+ to = tp->mask;
+ if (argc >= 1)
+ from = simple_strtoul(argv[1], NULL, 10);
+ if (argc >= 2)
+ to = simple_strtoul(argv[2], NULL, 10);
+ kdb_tr_display(from, to);
+ return(0);
+}
+
+int
+kdb_trstop(int  argc,  const  char  **argv, const char **envp, struct pt_regs *regs)
+{
+ struct trc *tp;
+
+ tp = trcp;
+ tp->enable_save |= TRC_STOP;
+ return(0);
+}
+
+int
+kdb_trstart(int  argc,  const  char **argv, const char **envp, struct pt_regs *regs)
+{
+ struct trc *tp;
+
+ tp = trcp;
+ tp->enable_save &= ~TRC_STOP;
+ return(0);
+}
+
+int
+kdb_trd(int  argc,  const  char  **argv,  const  char  **envp, struct pt_regs *regs)
+{
+ int diag, nextarg;
+ kdb_machreg_t addr;
+ long offset;
+ struct trc *tp;
+
+ tp = trcp;
+ if (argc == 0) {
+ tp->enable_save &= ~TRC_ENABLE;
+ } else {
+ nextarg = 1;
+ while (argc >= nextarg) {
+ diag = kdbgetaddrarg(argc, argv, &nextarg,
+ &addr, &offset, NULL, regs);
+ if (diag)
+ return(diag);
+ trc_set_flags(addr, TRC_DISABLE);
+ }
+ }
+ return(0);
+}
+
+int
+kdb_tre(int  argc,  const  char  **argv,  const  char  **envp, struct pt_regs *regs)
+{
+ int diag, nextarg;
+ kdb_machreg_t addr;
+ long offset;
+ struct trc *tp;
+
+ tp = trcp;
+ if (argc == 0) {
+ tp->enable_save |= TRC_ENABLE;
+ } else {
+ nextarg = 1;
+ while (argc >= nextarg) {
+ diag = kdbgetaddrarg(argc, argv, &nextarg,
+ &addr, &offset, NULL, regs);
+ if (diag)
+ return(diag);
+ trc_set_flags(addr, TRC_ENABLE);
+ }
+ }
+ return(0);
+}
+
+int
+kdb_trc(int  argc,  const  char  **argv,  const  char  **envp, struct pt_regs *regs)
+{
+ int diag, nextarg;
+ kdb_machreg_t addr;
+ long offset;
+ struct trc *tp;
+
+ tp = trcp;
+ if (argc == 0) {
+ trc_clr_all_flags();
+ } else {
+ nextarg = 1;
+ while (argc >= nextarg) {
+ diag = kdbgetaddrarg(argc, argv, &nextarg,
+ &addr, &offset, NULL, regs);
+ if (diag)
+ return(diag);
+ trc_clr_flags(addr);
+ }
+ }
+ return(0);
+}
+
+int
+kdb_trp(int  argc,  const  char  **argv,  const  char  **envp, struct pt_regs *regs)
+{
+ struct trc *tp;
+
+ tp = trcp;
+ kdb_printf("Tracing %s by default.\n",
+ tp->enable_save&TRC_ENABLE?"enabled":"disabled");
+ trc_print_hash();
+ return(0);
+}
+
+/*
+ * The calls for these functions are normally not generated because
+ * in the inlined version the compiler eliminates the call as dead
+ * code. When instrument-functions takes the address of the function
+ * forcing a non-inlined version the code is nolonger dead.
+ */
+
+void __br_lock_usage_bug(void)
+{
+ printk(KERN_WARNING "__br_lock_usage_bug called\n");
+}
+
+void __this_fixmap_does_not_exist(void)
+{
+ printk(KERN_WARNING "__this_fixmap_does_not_exist called\n");
+}
+
+void
+kdb_print_trace(void)
+{
+
+ struct trce *t;
+ struct trc *tp;
+ int from, to, i;
+
+ tp = trcp;
+ tp->enable = 0;
+ from = 0;
+ to = 20;
+
+ for (i = from; i <= to; i++) {
+ t = &(tp->buf[(tp->offset-i-1) & tp->mask]);
+ printk("%s %08x ", trc_tname[t->type],
+ t->time);
+ printk("%08lx ", (kdb_machreg_t)t->a1);
+ printk("%08lx ", (kdb_machreg_t)t->a2);
+ printk("\n");
+ }
+}
diff -rbNu linux-2.4.25-kdb/kdb/kdb_tr.h linux-2.4.25-kdb-trace/kdb/kdb_tr.h
--- linux-2.4.25-kdb/kdb/kdb_tr.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.25-kdb-trace/kdb/kdb_tr.h	2005-01-05 16:09:40.000000000 +0100
@@ -0,0 +1,89 @@
+/*
+ * Quick hack to trace the linux kernel at the function call level
+ * using the -finstrument-functions compiler option.
+ *
+ * Copyright (C) 2002 Jim Houston jhouston@ma.ultranet.com
+ *
+  *  This software may be used and distributed according to the termsof the
+   *  GNU  General  Public  License  (GPL),  incorporated  herein  by reference.
+ */
+
+
+#define rdtsc(low,high) \
+ __asm__ __volatile__("rdtsc" : "=a" (low), "=d" (high))
+
+#define TRC_ENABLE 1
+#define TRC_DISABLE 2
+#define TRC_STOP 4
+
+#define TRC_SZ 0x1000
+#define TRC_HASH_SZ 0x100
+
+#define T_ENTER 0
+#define T_EXIT 1
+#define T_USER 2
+
+struct trce {
+ unsigned int type: 8 ;
+ unsigned int timeu : 24 ;
+ unsigned int time;
+ kdb_machreg_t a1, a2, a3, a4, a5, a6;
+};
+
+struct trc {
+ int enable;
+ int enable_save;
+ struct trce *buf;
+ unsigned int mask;
+ unsigned int offset;
+ unsigned int offsetu;
+};
+
+/*
+ * The data collected by the trace is filtered by looking the
+ * called function address up in a simple hash table. The flags
+ * currently only two bits provide explicit enable/disable of
+ * tracing on a per function basis.
+ */
+
+struct trc_hash {
+ kdb_machreg_t addr;
+ int flags;
+};
+
+int trc_hashfn(kdb_machreg_t addr)
+ __attribute__ ((no_instrument_function));
+int trc_get_flags(kdb_machreg_t addr)
+ __attribute__ ((no_instrument_function));
+
+void __cyg_profile_func_enter(kdb_machreg_t , kdb_machreg_t )
+ __attribute__ ((no_instrument_function));
+
+void __cyg_profile_func_exit(kdb_machreg_t , kdb_machreg_t )
+ __attribute__ ((no_instrument_function));
+
+void __trace_user(kdb_machreg_t , kdb_machreg_t )
+ __attribute__ ((no_instrument_function));
+
+void __trace_stop( void )
+ __attribute__ ((no_instrument_function));
+
+void kdb_trc_disable( void )
+ __attribute__ ((no_instrument_function));
+
+void kdb_trc_continue( void )
+ __attribute__ ((no_instrument_function));
+
+static struct trce *next_t(struct trc *)
+ __attribute__ ((no_instrument_function));
+
+void kdb_trc_init(void);
+void kdb_trc_disable(void);
+void kdb_trc_continue(void);
+int kdb_tr(int , const char **, const char **, struct pt_regs *);
+int kdb_trstop(int , const char **, const char **, struct pt_regs *);
+int  kdb_trstart(int  ,  const char **, const char **, struct pt_regs *);
+int kdb_trd(int , const char **, const char **, struct pt_regs *);
+int kdb_tre(int , const char **, const char **, struct pt_regs *);
+int kdb_trc(int , const char **, const char **, struct pt_regs *);
+int kdb_trp(int , const char **, const char **, struct pt_regs *);
diff -rbNu linux-2.4.25-kdb/kdb/kdbmain.c linux-2.4.25-kdb-trace/kdb/kdbmain.c
--- linux-2.4.25-kdb/kdb/kdbmain.c	2005-01-05 13:39:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/kdb/kdbmain.c	2005-01-05 17:58:10.000000000 +0100
@@ -3617,6 +3617,7 @@
 	kdb_inittab();		/* Initialize Command Table */
 	kdb_initbptab();	/* Initialize Breakpoint Table */
 	kdb_id_init();		/* Initialize Disassembler */
+	kdb_trc_init();		/* Initialize Tracer extension */
 	kdba_init();		/* Architecture Dependent Initialization */
 
 	/*
diff -rbNu linux-2.4.25-kdb/kernel/ksyms.c linux-2.4.25-kdb-trace/kernel/ksyms.c
--- linux-2.4.25-kdb/kernel/ksyms.c	2005-01-05 13:39:11.000000000 +0100
+++ linux-2.4.25-kdb-trace/kernel/ksyms.c	2005-01-05 16:11:22.000000000 +0100
@@ -626,6 +626,25 @@
 
 EXPORT_SYMBOL(tasklist_lock);
 EXPORT_SYMBOL(pidhash);
+ 
+#ifdef CONFIG_INSTRUMENT_FUNC
+extern void __br_lock_usage_bug(void);
+extern void __this_fixmap_does_not_exist(void);
+extern void __cyg_profile_func_enter(void *, void *);
+extern void __cyg_profile_func_exit(void *, void *);
+extern void __trace_user(void *, void *);
+extern void __trace_stop();
+extern void *trcp;
+
+EXPORT_SYMBOL(__br_lock_usage_bug);
+EXPORT_SYMBOL(__this_fixmap_does_not_exist);
+EXPORT_SYMBOL_NOVERS(__cyg_profile_func_enter);
+EXPORT_SYMBOL_NOVERS(__cyg_profile_func_exit);
+EXPORT_SYMBOL(__trace_user);
+EXPORT_SYMBOL(__trace_stop);
+EXPORT_SYMBOL(trcp);
+#endif
+
 EXPORT_SYMBOL(unshare_files);
 
 /* debug */
diff -rbNu linux-2.4.25-kdb/net/appletalk/ddp.c linux-2.4.25-kdb-trace/net/appletalk/ddp.c
--- linux-2.4.25-kdb/net/appletalk/ddp.c	2001-09-10 16:57:00.000000000 +0200
+++ linux-2.4.25-kdb-trace/net/appletalk/ddp.c	2005-01-05 16:45:52.000000000 +0100
@@ -106,8 +106,8 @@
 #endif /* APPLETALK_DEBUG */
 
 #ifdef CONFIG_SYSCTL
-extern inline void atalk_register_sysctl(void);
-extern inline void atalk_unregister_sysctl(void);
+extern void atalk_register_sysctl(void);
+extern void atalk_unregister_sysctl(void);
 #endif /* CONFIG_SYSCTL */
 
 struct datalink_proto *ddp_dl, *aarp_dl;
@@ -122,7 +122,7 @@
 static struct sock *atalk_sockets;
 static spinlock_t atalk_sockets_lock = SPIN_LOCK_UNLOCKED;
 
-extern inline void atalk_insert_socket(struct sock *sk)
+static inline void atalk_insert_socket(struct sock *sk)
 {
 	spin_lock_bh(&atalk_sockets_lock);
 	sk->next = atalk_sockets;
@@ -133,7 +133,7 @@
 	spin_unlock_bh(&atalk_sockets_lock);
 }
 
-extern inline void atalk_remove_socket(struct sock *sk)
+static inline void atalk_remove_socket(struct sock *sk)
 {
 	spin_lock_bh(&atalk_sockets_lock);
 	if (sk->pprev) {
@@ -225,7 +225,7 @@
 	}
 }
 
-extern inline void atalk_destroy_socket(struct sock *sk)
+static inline void atalk_destroy_socket(struct sock *sk)
 {
 	atalk_remove_socket(sk);
 	skb_queue_purge(&sk->receive_queue);
diff -rbNu linux-2.4.25-kdb/net/bridge/br_private_timer.h linux-2.4.25-kdb-trace/net/bridge/br_private_timer.h
--- linux-2.4.25-kdb/net/bridge/br_private_timer.h	2000-02-18 23:51:22.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/bridge/br_private_timer.h	2005-01-05 16:45:53.000000000 +0100
@@ -21,12 +21,12 @@
 	unsigned long expires;
 };
 
-extern __inline__ void br_timer_clear(struct br_timer *t)
+static __inline__ void br_timer_clear(struct br_timer *t)
 {
 	t->running = 0;
 }
 
-extern __inline__ unsigned long br_timer_get_residue(struct br_timer *t)
+static __inline__ unsigned long br_timer_get_residue(struct br_timer *t)
 {
 	if (t->running)
 		return jiffies - t->expires;
@@ -34,18 +34,18 @@
 	return 0;
 }
 
-extern __inline__ void br_timer_set(struct br_timer *t, unsigned long x)
+static __inline__ void br_timer_set(struct br_timer *t, unsigned long x)
 {
 	t->expires = x;
 	t->running = 1;
 }
 
-extern __inline__ int br_timer_is_running(struct br_timer *t)
+static __inline__ int br_timer_is_running(struct br_timer *t)
 {
 	return t->running;
 }
 
-extern __inline__ int br_timer_has_expired(struct br_timer *t, unsigned long to)
+static __inline__ int br_timer_has_expired(struct br_timer *t, unsigned long to)
 {
 	return t->running && time_after_eq(jiffies, t->expires + to);
 }
diff -rbNu linux-2.4.25-kdb/net/core/dev.c linux-2.4.25-kdb-trace/net/core/dev.c
--- linux-2.4.25-kdb/net/core/dev.c	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/core/dev.c	2005-01-05 16:45:52.000000000 +0100
@@ -699,7 +699,7 @@
 
 #else
 
-extern inline void dev_load(const char *unused){;}
+static inline void dev_load(const char *unused){;}
 
 #endif
 
diff -rbNu linux-2.4.25-kdb/net/ipv4/fib_hash.c linux-2.4.25-kdb-trace/net/ipv4/fib_hash.c
--- linux-2.4.25-kdb/net/ipv4/fib_hash.c	2003-08-25 13:44:44.000000000 +0200
+++ linux-2.4.25-kdb-trace/net/ipv4/fib_hash.c	2005-01-05 16:45:52.000000000 +0100
@@ -137,12 +137,12 @@
 	return fz->fz_hash[fn_hash(key, fz).datum];
 }
 
-extern __inline__ int fn_key_eq(fn_key_t a, fn_key_t b)
+static __inline__ int fn_key_eq(fn_key_t a, fn_key_t b)
 {
 	return a.datum == b.datum;
 }
 
-extern __inline__ int fn_key_leq(fn_key_t a, fn_key_t b)
+static __inline__ int fn_key_leq(fn_key_t a, fn_key_t b)
 {
 	return a.datum <= b.datum;
 }
@@ -725,7 +725,7 @@
 	return -ESRCH;
 }
 
-extern __inline__ int
+static __inline__ int
 fn_flush_list(struct fib_node ** fp, int z, struct fn_hash *table)
 {
 	int found = 0;
diff -rbNu linux-2.4.25-kdb/net/ipv4/netfilter/ipchains_core.c linux-2.4.25-kdb-trace/net/ipv4/netfilter/ipchains_core.c
--- linux-2.4.25-kdb/net/ipv4/netfilter/ipchains_core.c	2003-06-13 16:51:39.000000000 +0200
+++ linux-2.4.25-kdb-trace/net/ipv4/netfilter/ipchains_core.c	2005-01-05 16:45:52.000000000 +0100
@@ -269,7 +269,7 @@
 #define IP_FW_OUTPUT_CHAIN (ip_fw_chains->next->next)
 
 /* Returns 1 if the port is matched by the range, 0 otherwise */
-extern inline int port_match(__u16 min, __u16 max, __u16 port,
+static inline int port_match(__u16 min, __u16 max, __u16 port,
 			     int frag, int invert)
 {
 	if (frag) /* Fragments fail ANY port test. */
diff -rbNu linux-2.4.25-kdb/net/ipv4/netfilter/ipfwadm_core.c linux-2.4.25-kdb-trace/net/ipv4/netfilter/ipfwadm_core.c
--- linux-2.4.25-kdb/net/ipv4/netfilter/ipfwadm_core.c	2003-06-13 16:51:39.000000000 +0200
+++ linux-2.4.25-kdb-trace/net/ipv4/netfilter/ipfwadm_core.c	2005-01-05 16:45:52.000000000 +0100
@@ -186,7 +186,7 @@
  *	Returns 1 if the port is matched by the vector, 0 otherwise
  */
 
-extern inline int port_match(unsigned short *portptr,int nports,unsigned short port,int range_flag)
+static inline int port_match(unsigned short *portptr,int nports,unsigned short port,int range_flag)
 {
 	if (!nports)
 		return 1;
diff -rbNu linux-2.4.25-kdb/net/ipv4/tcp_input.c linux-2.4.25-kdb-trace/net/ipv4/tcp_input.c
--- linux-2.4.25-kdb/net/ipv4/tcp_input.c	2003-11-28 19:26:21.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/ipv4/tcp_input.c	2005-01-05 16:45:52.000000000 +0100
@@ -2224,14 +2224,14 @@
 	return 1;
 }
 
-extern __inline__ void
+static __inline__ void
 tcp_store_ts_recent(struct tcp_opt *tp)
 {
 	tp->ts_recent = tp->rcv_tsval;
 	tp->ts_recent_stamp = xtime.tv_sec;
 }
 
-extern __inline__ void
+static __inline__ void
 tcp_replace_ts_recent(struct tcp_opt *tp, u32 seq)
 {
 	if (tp->saw_tstamp && !after(seq, tp->rcv_wup)) {
@@ -2290,7 +2290,7 @@
 		(s32)(tp->ts_recent - tp->rcv_tsval) <= (tp->rto*1024)/HZ);
 }
 
-extern __inline__ int tcp_paws_discard(struct tcp_opt *tp, struct sk_buff *skb)
+static __inline__ int tcp_paws_discard(struct tcp_opt *tp, struct sk_buff *skb)
 {
 	return ((s32)(tp->ts_recent - tp->rcv_tsval) > TCP_PAWS_WINDOW &&
 		xtime.tv_sec < tp->ts_recent_stamp + TCP_PAWS_24DAYS &&
diff -rbNu linux-2.4.25-kdb/net/sched/sch_csz.c linux-2.4.25-kdb-trace/net/sched/sch_csz.c
--- linux-2.4.25-kdb/net/sched/sch_csz.c	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/sched/sch_csz.c	2005-01-05 16:45:53.000000000 +0100
@@ -301,7 +301,7 @@
 
 #if 0
 /* Scan forward */
-extern __inline__ void csz_insert_finish(struct csz_head *b,
+static __inline__ void csz_insert_finish(struct csz_head *b,
 					 struct csz_flow *this)
 {
 	struct csz_head *f = b->fnext;
@@ -318,7 +318,7 @@
 }
 #else
 /* Scan backward */
-extern __inline__ void csz_insert_finish(struct csz_head *b,
+static __inline__ void csz_insert_finish(struct csz_head *b,
 					 struct csz_flow *this)
 {
 	struct csz_head *f = b->fprev;
@@ -339,7 +339,7 @@
    flow with greater start number.
  */
 
-extern __inline__ void csz_insert_start(struct csz_head *b,
+static __inline__ void csz_insert_start(struct csz_head *b,
 					struct csz_flow *this)
 {
 	struct csz_head *f = b->snext;
diff -rbNu linux-2.4.25-kdb/net/sched/sch_sfq.c linux-2.4.25-kdb-trace/net/sched/sch_sfq.c
--- linux-2.4.25-kdb/net/sched/sch_sfq.c	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/sched/sch_sfq.c	2005-01-05 16:45:53.000000000 +0100
@@ -166,7 +166,7 @@
 	return sfq_fold_hash(q, h, h2);
 }
 
-extern __inline__ void sfq_link(struct sfq_sched_data *q, sfq_index x)
+static __inline__ void sfq_link(struct sfq_sched_data *q, sfq_index x)
 {
 	sfq_index p, n;
 	int d = q->qs[x].qlen + SFQ_DEPTH;
@@ -178,7 +178,7 @@
 	q->dep[p].next = q->dep[n].prev = x;
 }
 
-extern __inline__ void sfq_dec(struct sfq_sched_data *q, sfq_index x)
+static __inline__ void sfq_dec(struct sfq_sched_data *q, sfq_index x)
 {
 	sfq_index p, n;
 
@@ -193,7 +193,7 @@
 	sfq_link(q, x);
 }
 
-extern __inline__ void sfq_inc(struct sfq_sched_data *q, sfq_index x)
+static __inline__ void sfq_inc(struct sfq_sched_data *q, sfq_index x)
 {
 	sfq_index p, n;
 	int d;
diff -rbNu linux-2.4.25-kdb/net/socket.c linux-2.4.25-kdb-trace/net/socket.c
--- linux-2.4.25-kdb/net/socket.c	2004-02-18 14:36:32.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/socket.c	2005-01-05 16:45:52.000000000 +0100
@@ -373,7 +373,7 @@
 	return fd;
 }
 
-extern __inline__ struct socket *socki_lookup(struct inode *inode)
+static __inline__ struct socket *socki_lookup(struct inode *inode)
 {
 	return &inode->u.socket_i;
 }
@@ -418,7 +418,7 @@
 	return sock;
 }
 
-extern __inline__ void sockfd_put(struct socket *sock)
+static __inline__ void sockfd_put(struct socket *sock)
 {
 	fput(sock->file);
 }
diff -rbNu linux-2.4.25-kdb/net/unix/af_unix.c linux-2.4.25-kdb-trace/net/unix/af_unix.c
--- linux-2.4.25-kdb/net/unix/af_unix.c	2002-11-29 00:53:16.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/unix/af_unix.c	2005-01-05 16:45:52.000000000 +0100
@@ -159,7 +159,7 @@
 	return peer;
 }
 
-extern inline void unix_release_addr(struct unix_address *addr)
+static inline void unix_release_addr(struct unix_address *addr)
 {
 	if (atomic_dec_and_test(&addr->refcnt))
 		kfree(addr);
diff -rbNu linux-2.4.25-kdb/net/unix/garbage.c linux-2.4.25-kdb-trace/net/unix/garbage.c
--- linux-2.4.25-kdb/net/unix/garbage.c	2002-02-25 20:38:16.000000000 +0100
+++ linux-2.4.25-kdb-trace/net/unix/garbage.c	2005-01-05 16:45:52.000000000 +0100
@@ -92,7 +92,7 @@
 atomic_t unix_tot_inflight = ATOMIC_INIT(0);
 
 
-extern inline unix_socket *unix_get_socket(struct file *filp)
+static inline unix_socket *unix_get_socket(struct file *filp)
 {
 	unix_socket * u_sock = NULL;
 	struct inode *inode = filp->f_dentry->d_inode;
@@ -141,19 +141,19 @@
  *	Garbage Collector Support Functions
  */
 
-extern inline unix_socket *pop_stack(void)
+static inline unix_socket *pop_stack(void)
 {
 	unix_socket *p=gc_current;
 	gc_current = p->protinfo.af_unix.gc_tree;
 	return p;
 }
 
-extern inline int empty_stack(void)
+static inline int empty_stack(void)
 {
 	return gc_current == GC_HEAD;
 }
 
-extern inline void maybe_unmark_and_push(unix_socket *x)
+static inline void maybe_unmark_and_push(unix_socket *x)
 {
 	if (x->protinfo.af_unix.gc_tree != GC_ORPHAN)
 		return;
diff -rbNu linux-2.4.25-kdb/scripts/inline-fix.pl linux-2.4.25-kdb-trace/scripts/inline-fix.pl
--- linux-2.4.25-kdb/scripts/inline-fix.pl	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.25-kdb-trace/scripts/inline-fix.pl	2005-01-05 16:09:40.000000000 +0100
@@ -0,0 +1,91 @@
+#!/usr/bin/perl
+#
+# This script changes "extern inline" to "static inline" in header
+# files. I did this so that I could use -finstrument-functions to
+# trace Linux kernel code. The script is pretty stupid if it finds
+# extern and inline togther its likely to make a change. It removes
+# the inline from forward references and changes extern to static
+# for definitions.
+
+open(FIND,  "find  .  -name  \*.[ch] |") || die "couldn't run find on *.[ch]\n";
+while ($f = <FIND>) {
+ chop $f;
+ if (!open(FILE, $f)) {
+ print STDERR "Can't open $f\n";
+ next;
+ }
+# print STDERR "scanning $f\n";
+ undef $file_content;
+ $file_content = "";
+ $modified = 0;
+OUT:
+ while ($line = <FILE>) {
+ # check for comment, ignore lines that start with
+ # a comment. Ignore block comments
+ if ($line =~ /^\s*\/\*.*\*\//) {
+ $file_content .= $line;
+ next;
+ }
+ if ($line =~ /^\s*\/\*/) {
+ $file_content .= $line;
+ while ($line = <FILE>) {
+ $file_content .= $line;
+ if ($line =~ /\*\//) {
+ next OUT;
+ }
+ }
+ print STDERR "??? $f: end of file in comment?";
+
+ }
+ if ($line =~ /extern\s+(.*)(inline|__inline|__inline__)\s/) {
+ $extra = 0;
+ if ($line =~ /^#define/) {
+ # Alpha & ARM have defines
+ # for extern inline which I'm
+ #ignoring for now.
+ $file_content .= $line;
+ next;
+ }
+ while (!($line =~ /;|{/)) {
+ if (!($nl = <FILE>)) {
+ die "hit EOF... file=$f\n";
+ }
+ if (++$extra > 8) {
+ print STDERR "??? $f: $line";
+ last;
+ }
+ $line .= $nl;
+ }
+ if ($line =~ /{/) {
+ $line =~ s/extern/static/;
+ $modified = 1;
+ } elsif ($line =~ /;/) {
+ $line =~ s/[ ]*__inline__[ ]*/ /;
+ $line =~ s/[ ]*__inline[ ]*/ /;
+ $line =~ s/[ ]*inline[ ]*/ /;
+ $modified = 1;
+ }
+ }
+ $file_content .= $line;
+ }
+ close(FILE);
+ $name = $f . ".orig";
+ if ($modified && -e $name) {
+ print STDERR "$name already exists - no changes made\n";
+ next;
+ }
+ if ($modified) {
+ if (link($f, $name)) {
+ unlink($f);
+ } else {
+ print STDERR "Can't move $f to $name\n";
+ next;
+ }
+ if (!open(FILE, ">$f")) {
+ prinf STDERR "Can't open $f for output\n";
+ next;
+ }
+ print FILE $file_content;
+ close(FILE);
+ }
+}
