diff -rbNu linux-2.4.19/Documentation/Configure.help linux-2.4.19-ltt/Documentation/Configure.help
--- linux-2.4.19/Documentation/Configure.help	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/Documentation/Configure.help	2004-12-28 22:39:46.000000000 +0100
@@ -20527,6 +20527,44 @@
 
   "Area6" will work for most boards. For ADX, select "Area5".
 
+Kernel events tracing support
+CONFIG_TRACE
+  It is possible for the kernel to log important events to a tracing
+  driver. Doing so, enables the use of the generated traces in order
+  to reconstruct the dynamic behavior of the kernel, and hence the
+  whole system.
+
+  The tracing process contains 4 parts :
+      1) The logging of events by key parts of the kernel.
+      2) The trace driver that keeps the events in a data buffer.
+      3) A trace daemon that opens the trace driver and is notified
+         every time there is a certain quantity of data to read
+         from the trace driver (using SIG_IO).
+      4) A trace event data decoder that reads the accumulated data
+         and formats it in a human-readable format.
+
+  If you say Y or M here, the first part of the tracing process will
+  always take place. That is, critical parts of the kernel will call
+  upon the kernel tracing function. The data generated doesn't go
+  any further until a trace driver registers himself as such with the
+  kernel. Therefore, if you answer Y, then the driver will be part of
+  the kernel and the events will always proceed onto the driver and
+  if you say M, then the events will only proceed onto the driver when
+  it's module is loaded. Note that event's aren't logged in the driver
+  until the profiling daemon opens the device, configures it and
+  issues the "start" command through ioctl().
+
+  The impact of a fully functionnal system (kernel event logging +
+  driver event copying + active trace daemon) is of 2.5% for core events.
+  This means that for a task that took 100 seconds on a normal system, it
+  will take 102.5 seconds on a traced system. This is very low compared
+  to other profiling or tracing methods.
+
+  For more information on kernel tracing, the trace daemon or the event
+  decoder, please check the following address :
+       http://www.opersys.com/LTT
+
+
 #
 # m68k-specific kernel options
 # Documented by Chris Lawrence <mailto:quango@themall.net> et al.
diff -rbNu linux-2.4.19/Makefile linux-2.4.19-ltt/Makefile
--- linux-2.4.19/Makefile	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/Makefile	2004-12-28 23:11:16.000000000 +0100
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 4
 SUBLEVEL = 19
-EXTRAVERSION =
+EXTRAVERSION =-ltt
 
 KERNELRELEASE=$(VERSION).$(PATCHLEVEL).$(SUBLEVEL)$(EXTRAVERSION)
 
@@ -188,6 +188,7 @@
 DRIVERS-$(CONFIG_BLUEZ) += drivers/bluetooth/bluetooth.o
 DRIVERS-$(CONFIG_HOTPLUG_PCI) += drivers/hotplug/vmlinux-obj.o
 DRIVERS-$(CONFIG_ISDN_BOOL) += drivers/isdn/vmlinux-obj.o
+DRIVERS-$(CONFIG_TRACE) += drivers/trace/trace_driver.o
 
 DRIVERS := $(DRIVERS-y)
 
diff -rbNu linux-2.4.19/arch/arm/config.in linux-2.4.19-ltt/arch/arm/config.in
--- linux-2.4.19/arch/arm/config.in	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/arm/config.in	2004-12-28 22:39:46.000000000 +0100
@@ -632,6 +632,11 @@
 source net/bluetooth/Config.in
 
 mainmenu_option next_comment
+comment 'Kernel tracing'
+tristate 'Kernel events tracing support' CONFIG_TRACE
+endmenu
+
+mainmenu_option next_comment
 comment 'Kernel hacking'
 
 # RMK wants arm kernels compiled with frame pointers so hardwire this to y.  If
diff -rbNu linux-2.4.19/arch/arm/kernel/entry-common.S linux-2.4.19-ltt/arch/arm/kernel/entry-common.S
--- linux-2.4.19/arch/arm/kernel/entry-common.S	2002-02-25 20:37:52.000000000 +0100
+++ linux-2.4.19-ltt/arch/arm/kernel/entry-common.S	2004-12-28 22:39:46.000000000 +0100
@@ -34,6 +34,11 @@
  * stack.
  */
 ret_fast_syscall:
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	mov	r7, r0				@ save returned r0
+	bl	SYMBOL_NAME(trace_real_syscall_exit)
+	mov	r0, r7
+#endif
 	ldr	r1, [tsk, #TSK_NEED_RESCHED]
 	ldr	r2, [tsk, #TSK_SIGPENDING]
 	teq	r1, #0				@ need_resched || sigpending
@@ -131,6 +136,16 @@
 	mcr	p15, 0, ip, c1, c0		@ update control register
 #endif
 	enable_irqs ip
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	/* zzz note that validity of scno is not yet checked.
+	 * zzz The visualizer checks it.
+	 */
+	add	r1, sp, #S_R0			@ pointer to regs
+	mov	r0, scno  		        @ syscall number
+	bl	SYMBOL_NAME(trace_real_syscall_entry)
+	add	r1, sp, #S_R0			@ pointer to regs
+	ldmia	r1, {r0 - r3}			@ have to reload r0 - r3
+#endif
 
 	str	r4, [sp, #-S_OFF]!		@ push fifth arg
 
@@ -171,6 +186,9 @@
 
 __sys_trace_return:
 	str	r0, [sp, #S_R0 + S_OFF]!	@ save returned r0
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	bl	SYMBOL_NAME(trace_real_syscall_exit)
+#endif
 	mov	r1, sp
 	mov	r0, #1				@ trace exit [IP = 1]
 	bl	SYMBOL_NAME(syscall_trace)
diff -rbNu linux-2.4.19/arch/arm/kernel/irq.c linux-2.4.19-ltt/arch/arm/kernel/irq.c
--- linux-2.4.19/arch/arm/kernel/irq.c	2001-07-04 23:56:44.000000000 +0200
+++ linux-2.4.19-ltt/arch/arm/kernel/irq.c	2004-12-28 22:39:46.000000000 +0100
@@ -28,6 +28,7 @@
 #include <linux/random.h>
 #include <linux/smp.h>
 #include <linux/init.h>
+#include <linux/trace.h>
 
 #include <asm/irq.h>
 #include <asm/system.h>
@@ -167,6 +168,8 @@
 
 	desc = irq_desc + irq;
 
+	TRACE_IRQ_ENTRY(irq, !(user_mode(regs)));
+
 	spin_lock(&irq_controller_lock);
 	desc->mask_ack(irq);
 	spin_unlock(&irq_controller_lock);
@@ -216,6 +219,8 @@
 
 	irq_exit(cpu, irq);
 
+	TRACE_IRQ_EXIT();
+
 	if (softirq_pending(cpu))
 		do_softirq();
 	return;
diff -rbNu linux-2.4.19/arch/arm/kernel/process.c linux-2.4.19-ltt/arch/arm/kernel/process.c
--- linux-2.4.19/arch/arm/kernel/process.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/arm/kernel/process.c	2004-12-28 22:39:46.000000000 +0100
@@ -23,6 +23,7 @@
 #include <linux/reboot.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
+#include <linux/trace.h>
 
 #include <asm/leds.h>
 #include <asm/system.h>
@@ -385,6 +386,10 @@
         : "=r" (__ret)
         : "Ir" (flags), "I" (CLONE_VM), "r" (fn), "r" (arg)
 	: "r0", "r1", "lr");
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	if (__ret > 0)
+		TRACE_PROCESS(TRACE_EV_PROCESS_KTHREAD, __ret, (int) fn);
+#endif
 	return __ret;
 }
 
diff -rbNu linux-2.4.19/arch/arm/kernel/sys_arm.c linux-2.4.19-ltt/arch/arm/kernel/sys_arm.c
--- linux-2.4.19/arch/arm/kernel/sys_arm.c	2001-07-04 23:56:44.000000000 +0200
+++ linux-2.4.19-ltt/arch/arm/kernel/sys_arm.c	2004-12-28 22:39:46.000000000 +0100
@@ -24,6 +24,7 @@
 #include <linux/fs.h>
 #include <linux/file.h>
 #include <linux/utsname.h>
+#include <linux/trace.h>
 
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
@@ -167,6 +168,8 @@
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+
 	switch (call) {
 	case SEMOP:
 		return sys_semop (first, (struct sembuf *)ptr, second);
diff -rbNu linux-2.4.19/arch/arm/kernel/traps.c linux-2.4.19-ltt/arch/arm/kernel/traps.c
--- linux-2.4.19/arch/arm/kernel/traps.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/arm/kernel/traps.c	2004-12-28 22:39:46.000000000 +0100
@@ -24,6 +24,7 @@
 #include <linux/elf.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
+#include <linux/trace.h>
 
 #include <asm/pgtable.h>
 #include <asm/system.h>
@@ -148,6 +149,72 @@
 	}
 }
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+asmlinkage void trace_real_syscall_entry(int scno,struct pt_regs * regs)
+{
+	int			depth = 0;
+	unsigned long           end_code;
+	unsigned long		*fp;			/* frame pointer */
+	unsigned long		lower_bound;
+	unsigned long		lr;			/* link register */
+	unsigned long		*prev_fp;
+	int			seek_depth;
+	unsigned long           start_code;
+	unsigned long           *start_stack;
+	trace_syscall_entry	trace_syscall_event;
+	unsigned long		upper_bound;
+	int			use_bounds;
+	int			use_depth;
+
+	trace_syscall_event.syscall_id = (uint8_t)scno;
+	trace_syscall_event.address    = instruction_pointer(regs);
+	
+	if (! (user_mode(regs) ))
+		goto trace_syscall_end;
+
+	if (trace_get_config(&use_depth,
+			     &use_bounds,
+			     &seek_depth,
+			     (void*)&lower_bound,
+			     (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	if ((use_depth == 1) || (use_bounds == 1)) {
+		fp          = (unsigned long *)regs->ARM_fp;
+		end_code    = current->mm->end_code;
+		start_code  = current->mm->start_code;
+		start_stack = (unsigned long *)current->mm->start_stack;
+
+		while (!__get_user(lr, (unsigned long *)(fp - 1))) {
+			if ((lr > start_code) && (lr < end_code)) {
+				if (((use_depth == 1) && (depth >= seek_depth)) ||
+				    ((use_bounds == 1) && (lr > lower_bound) && (lr < upper_bound))) {
+					trace_syscall_event.address = lr;
+					goto trace_syscall_end;
+				} else {
+					depth++;
+				}
+			}
+
+			if ((__get_user((unsigned long)prev_fp, (fp - 3))) ||
+			    (prev_fp > start_stack) ||
+			    (prev_fp <= fp)) {
+				goto trace_syscall_end;
+			}
+			fp = prev_fp;
+		}
+	}
+
+trace_syscall_end:
+	trace_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
+
+asmlinkage void trace_real_syscall_exit(void)
+{
+        trace_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */
+
 spinlock_t die_lock = SPIN_LOCK_UNLOCKED;
 
 /*
@@ -223,8 +290,12 @@
 	info.si_code  = ILL_ILLOPC;
 	info.si_addr  = pc;
 
+	TRACE_TRAP_ENTRY(current->thread.trap_no, (uint32_t)pc);
+
 	force_sig_info(SIGILL, &info, current);
 
+	TRACE_TRAP_EXIT();
+
 	die_if_kernel("Oops - undefined instruction", regs, mode);
 }
 
@@ -247,8 +318,12 @@
 	info.si_code  = BUS_ADRERR;
 	info.si_addr  = (void *)address;
 
+	TRACE_TRAP_ENTRY(current->thread.trap_no, instruction_pointer(regs));
+
 	force_sig_info(SIGBUS, &info, current);
 
+	TRACE_TRAP_EXIT();
+
 	die_if_kernel("Oops - address exception", regs, mode);
 }
 #endif
@@ -369,7 +444,12 @@
 		info.si_addr  = (void *)instruction_pointer(regs) -
 				 (thumb_mode(regs) ? 2 : 4);
 
+        	TRACE_TRAP_ENTRY(1, (uint32_t)info.si_addr);	/* debug */
+
 		force_sig_info(SIGTRAP, &info, current);
+
+		TRACE_TRAP_EXIT();
+
 		return regs->ARM_r0;
 
 #ifdef CONFIG_CPU_32
@@ -472,7 +552,12 @@
 	info.si_code  = ILL_ILLOPC;
 	info.si_addr  = (void *)addr;
 
+	TRACE_TRAP_ENTRY(18, addr);	/* machine check */
+
 	force_sig_info(SIGILL, &info, current);
+
+	TRACE_TRAP_EXIT();
+
 	die_if_kernel("unknown data abort code", regs, instr);
 }
 
diff -rbNu linux-2.4.19/arch/arm/mm/fault-common.c linux-2.4.19-ltt/arch/arm/mm/fault-common.c
--- linux-2.4.19/arch/arm/mm/fault-common.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/arm/mm/fault-common.c	2004-12-28 22:39:46.000000000 +0100
@@ -21,6 +21,7 @@
 #include <linux/interrupt.h>
 #include <linux/proc_fs.h>
 #include <linux/init.h>
+#include <linux/trace.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
@@ -252,6 +253,8 @@
 	if (in_interrupt() || !mm)
 		goto no_context;
 
+	TRACE_TRAP_ENTRY(14, instruction_pointer(regs));
+
 	down_read(&mm->mmap_sem);
 	fault = __do_page_fault(mm, addr, error_code, tsk);
 	up_read(&mm->mmap_sem);
@@ -259,8 +262,10 @@
 	/*
 	 * Handle the "normal" case first
 	 */
-	if (fault > 0)
+	if (fault > 0) {
+		TRACE_TRAP_EXIT();
 		return 0;
+	}
 
 	/*
 	 * We had some memory, but were unable to
@@ -286,6 +291,7 @@
 	} else
 		__do_user_fault(tsk, addr, error_code, fault == -1 ?
 				SEGV_ACCERR : SEGV_MAPERR, regs);
+	TRACE_TRAP_EXIT();
 	return 0;
 
 
@@ -308,11 +314,14 @@
 #endif
 
 	/* Kernel mode? Handle exceptions or die */
-	if (user_mode(regs))
+	if (user_mode(regs)) {
+		TRACE_TRAP_EXIT();
 		return 0;
+	}
 
 no_context:
 	__do_kernel_fault(mm, addr, error_code, regs);
+	TRACE_TRAP_EXIT();
 	return 0;
 }
 
diff -rbNu linux-2.4.19/arch/i386/config.in linux-2.4.19-ltt/arch/i386/config.in
--- linux-2.4.19/arch/i386/config.in	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/i386/config.in	2004-12-28 22:39:46.000000000 +0100
@@ -413,6 +413,11 @@
 source net/bluetooth/Config.in
 
 mainmenu_option next_comment
+comment 'Kernel tracing'
+tristate 'Kernel events tracing support' CONFIG_TRACE
+endmenu
+
+mainmenu_option next_comment
 comment 'Kernel hacking'
 
 bool 'Kernel debugging' CONFIG_DEBUG_KERNEL
diff -rbNu linux-2.4.19/arch/i386/kernel/entry.S linux-2.4.19-ltt/arch/i386/kernel/entry.S
--- linux-2.4.19/arch/i386/kernel/entry.S	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/i386/kernel/entry.S	2004-12-28 22:39:46.000000000 +0100
@@ -199,8 +199,30 @@
 	jne tracesys
 	cmpl $(NR_syscalls),%eax
 	jae badsys
+
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	movl SYMBOL_NAME(syscall_entry_trace_active), %eax
+	cmpl $1, %eax                   # are we tracing system call entries
+	jne no_syscall_entry_trace
+	movl %esp, %eax                 # copy the stack pointer
+	pushl %eax                      # pass the stack pointer copy
+	call SYMBOL_NAME(trace_real_syscall_entry)
+	addl $4,%esp                    # return stack to state before pass
+no_syscall_entry_trace:
+	movl ORIG_EAX(%esp),%eax	# restore eax to it's original content
+#endif
+
 	call *SYMBOL_NAME(sys_call_table)(,%eax,4)
 	movl %eax,EAX(%esp)		# save the return value
+
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	movl SYMBOL_NAME(syscall_exit_trace_active), %eax
+	cmpl $1, %eax                   # are we tracing system call exits
+	jne no_syscall_exit_trace
+	call SYMBOL_NAME(trace_real_syscall_exit)
+no_syscall_exit_trace:	
+#endif
+
 ENTRY(ret_from_sys_call)
 	cli				# need_resched and signals atomic test
 	cmpl $0,need_resched(%ebx)
diff -rbNu linux-2.4.19/arch/i386/kernel/irq.c linux-2.4.19-ltt/arch/i386/kernel/irq.c
--- linux-2.4.19/arch/i386/kernel/irq.c	2001-10-25 22:53:46.000000000 +0200
+++ linux-2.4.19-ltt/arch/i386/kernel/irq.c	2004-12-28 22:39:46.000000000 +0100
@@ -33,6 +33,8 @@
 #include <linux/irq.h>
 #include <linux/proc_fs.h>
 
+#include <linux/trace.h>
+
 #include <asm/atomic.h>
 #include <asm/io.h>
 #include <asm/smp.h>
@@ -441,6 +443,8 @@
 
 	irq_enter(cpu, irq);
 
+	TRACE_IRQ_ENTRY(irq, !(user_mode(regs)));
+
 	status = 1;	/* Force the "do bottom halves" bit */
 
 	if (!(action->flags & SA_INTERRUPT))
@@ -457,6 +461,8 @@
 
 	irq_exit(cpu, irq);
 
+	TRACE_IRQ_EXIT();
+
 	return status;
 }
 
diff -rbNu linux-2.4.19/arch/i386/kernel/process.c linux-2.4.19-ltt/arch/i386/kernel/process.c
--- linux-2.4.19/arch/i386/kernel/process.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/i386/kernel/process.c	2004-12-28 22:39:46.000000000 +0100
@@ -34,6 +34,8 @@
 #include <linux/init.h>
 #include <linux/mc146818rtc.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
 #include <asm/system.h>
@@ -508,6 +510,10 @@
 		 "r" (arg), "r" (fn),
 		 "b" (flags | CLONE_VM)
 		: "memory");
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	if (retval > 0)
+	  TRACE_PROCESS(TRACE_EV_PROCESS_KTHREAD, retval, (int) fn);
+#endif
 	return retval;
 }
 
diff -rbNu linux-2.4.19/arch/i386/kernel/semaphore.c linux-2.4.19-ltt/arch/i386/kernel/semaphore.c
--- linux-2.4.19/arch/i386/kernel/semaphore.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/i386/kernel/semaphore.c	2004-12-28 23:33:10.000000000 +0100
@@ -257,36 +257,3 @@
 	"ret"
 );
 
-/*
- * rw spinlock fallbacks
- */
-#if defined(CONFIG_SMP)
-asm(
-"
-.align	4
-.globl	__write_lock_failed
-__write_lock_failed:
-	" LOCK "addl	$" RW_LOCK_BIAS_STR ",(%eax)
-1:	rep; nop
-	cmpl	$" RW_LOCK_BIAS_STR ",(%eax)
-	jne	1b
-
-	" LOCK "subl	$" RW_LOCK_BIAS_STR ",(%eax)
-	jnz	__write_lock_failed
-	ret
-
-
-.align	4
-.globl	__read_lock_failed
-__read_lock_failed:
-	lock ; incl	(%eax)
-1:	rep; nop
-	cmpl	$1,(%eax)
-	js	1b
-
-	lock ; decl	(%eax)
-	js	__read_lock_failed
-	ret
-"
-);
-#endif
diff -rbNu linux-2.4.19/arch/i386/kernel/sys_i386.c linux-2.4.19-ltt/arch/i386/kernel/sys_i386.c
--- linux-2.4.19/arch/i386/kernel/sys_i386.c	2001-03-19 21:35:09.000000000 +0100
+++ linux-2.4.19-ltt/arch/i386/kernel/sys_i386.c	2004-12-28 22:39:46.000000000 +0100
@@ -19,6 +19,8 @@
 #include <linux/file.h>
 #include <linux/utsname.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
 
@@ -137,6 +139,8 @@
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+
 	switch (call) {
 	case SEMOP:
 		return sys_semop (first, (struct sembuf *)ptr, second);
diff -rbNu linux-2.4.19/arch/i386/kernel/traps.c linux-2.4.19-ltt/arch/i386/kernel/traps.c
--- linux-2.4.19/arch/i386/kernel/traps.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/i386/kernel/traps.c	2004-12-28 22:39:46.000000000 +0100
@@ -25,6 +25,8 @@
 #include <linux/interrupt.h>
 #include <linux/highmem.h>
 
+#include <linux/trace.h>
+
 #ifdef CONFIG_MCA
 #include <linux/mca.h>
 #include <asm/processor.h>
@@ -272,6 +274,82 @@
 	printk("Kernel BUG\n");
 }
 
+/* Trace related code */
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+asmlinkage void trace_real_syscall_entry(struct pt_regs * regs)
+{
+        int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+        int                 seek_depth;
+        unsigned long       lower_bound;
+        unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+        /* Set the syscall ID */
+        trace_syscall_event.syscall_id = (uint8_t) regs->orig_eax;
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = regs->eip;
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!(regs->xcs & 3))
+	  /* Don't go diging anywhere */
+	  goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(trace_get_config(&use_depth,
+			    &use_bounds,
+			    &seek_depth,
+			    (void*)&lower_bound,
+			    (void*)&upper_bound) < 0)
+	  goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	  {
+	  /* Start at the top of the stack (bottom address since stacks grow downward) */
+	  stack = (unsigned long*) regs->esp;
+
+	  /* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+	  while(!get_user(addr, stack))
+	    {
+	    /* Does this LOOK LIKE an address in the program */
+	    if((addr > current->mm->start_code)
+             &&(addr < current->mm->end_code))
+	      {
+	      /* Does this address fit the description */
+	      if(((use_depth == 1) && (depth == seek_depth))
+               ||((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound)))
+		{
+		/* Set the address */
+		trace_syscall_event.address = addr;
+
+		/* We're done */
+		goto trace_syscall_end;
+		}
+	      else
+		/* We're one depth more */
+		depth++;
+	      }
+	    /* Go on to the next address */
+	    stack++;
+	    }
+	  }
+
+trace_syscall_end:
+	/* Trace the event */
+	trace_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
+
+asmlinkage void trace_real_syscall_exit(void)
+{
+        trace_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */
+
 spinlock_t die_lock = SPIN_LOCK_UNLOCKED;
 
 void die(const char * str, struct pt_regs * regs, long err)
@@ -305,6 +383,8 @@
 static void inline do_trap(int trapnr, int signr, char *str, int vm86,
 			   struct pt_regs * regs, long error_code, siginfo_t *info)
 {
+        TRACE_TRAP_ENTRY(trapnr, regs->eip);
+
 	if (vm86 && regs->eflags & VM_MASK)
 		goto vm86_trap;
 	if (!(regs->xcs & 3))
@@ -318,6 +398,7 @@
 			force_sig_info(signr, info, tsk);
 		else
 			force_sig(signr, tsk);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
@@ -327,14 +408,17 @@
 			regs->eip = fixup;
 		else	
 			die(str, regs, error_code);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
 	vm86_trap: {
 		int ret = handle_vm86_trap((struct kernel_vm86_regs *) regs, error_code, trapnr);
 		if (ret) goto trap_signal;
+		TRACE_TRAP_EXIT();
 		return;
 	}
+	TRACE_TRAP_EXIT();
 }
 
 #define DO_ERROR(trapnr, signr, str, name) \
@@ -394,11 +478,15 @@
 
 	current->thread.error_code = error_code;
 	current->thread.trap_no = 13;
+        TRACE_TRAP_ENTRY(13, regs->eip);
 	force_sig(SIGSEGV, current);
+        TRACE_TRAP_EXIT();
 	return;
 
 gp_in_vm86:
+        TRACE_TRAP_ENTRY(13, regs->eip);
 	handle_vm86_fault((struct kernel_vm86_regs *) regs, error_code);
+        TRACE_TRAP_EXIT();
 	return;
 
 gp_in_kernel:
@@ -458,6 +546,11 @@
 {
 	unsigned char reason = inb(0x61);
 
+#ifndef CONFIG_X86_LOCAL_APIC /* On an machine with APIC enabled NMIs are used to implement a
+				 watchdog and will hang the machine if traced. */
+        TRACE_TRAP_ENTRY(2, regs->eip);
+#endif
+
 	++nmi_count(smp_processor_id());
 
 	if (!(reason & 0xc0)) {
@@ -468,10 +561,12 @@
 		 */
 		if (nmi_watchdog) {
 			nmi_watchdog_tick(regs);
+			TRACE_TRAP_EXIT();
 			return;
 		}
 #endif
 		unknown_nmi_error(reason, regs);
+	        TRACE_TRAP_EXIT();
 		return;
 	}
 	if (reason & 0x80)
@@ -486,6 +581,8 @@
 	inb(0x71);		/* dummy */
 	outb(0x0f, 0x70);
 	inb(0x71);		/* dummy */
+
+        TRACE_TRAP_EXIT();
 }
 
 /*
@@ -559,7 +656,9 @@
 	 */
 	info.si_addr = ((regs->xcs & 3) == 0) ? (void *)tsk->thread.eip : 
 	                                        (void *)regs->eip;
+        TRACE_TRAP_ENTRY(1, regs->eip);
 	force_sig_info(SIGTRAP, &info, tsk);
+        TRACE_TRAP_EXIT();
 
 	/* Disable additional traps. They'll be re-enabled when
 	 * the signal is delivered.
@@ -571,7 +670,9 @@
 	return;
 
 debug_vm86:
+        TRACE_TRAP_ENTRY(1, regs->eip);
 	handle_vm86_trap((struct kernel_vm86_regs *) regs, error_code, 1);
+        TRACE_TRAP_EXIT();
 	return;
 
 clear_TF:
@@ -721,10 +822,12 @@
 asmlinkage void do_spurious_interrupt_bug(struct pt_regs * regs,
 					  long error_code)
 {
+        TRACE_TRAP_ENTRY(16, regs->eip);
 #if 0
 	/* No need to warn about this any longer. */
 	printk("Ignoring P6 Local APIC Spurious Interrupt Bug...\n");
 #endif
+        TRACE_TRAP_EXIT();	
 }
 
 /*
@@ -752,8 +855,10 @@
 {
 	printk("math-emulation not enabled and no coprocessor found.\n");
 	printk("killing %s.\n",current->comm);
+        TRACE_TRAP_ENTRY(7, 0);
 	force_sig(SIGFPE,current);
 	schedule();
+        TRACE_TRAP_EXIT();
 }
 
 #endif /* CONFIG_MATH_EMULATION */
@@ -804,7 +909,6 @@
 	 "3" ((char *) (addr)),"2" (__KERNEL_CS << 16)); \
 } while (0)
 
-
 /*
  * This needs to use 'idt_table' rather than 'idt', and
  * thus use the _nonmapped_ version of the IDT, as the
diff -rbNu linux-2.4.19/arch/i386/mm/fault.c linux-2.4.19-ltt/arch/i386/mm/fault.c
--- linux-2.4.19/arch/i386/mm/fault.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.19-ltt/arch/i386/mm/fault.c	2004-12-28 22:39:46.000000000 +0100
@@ -20,6 +20,8 @@
 #include <linux/tty.h>
 #include <linux/vt_kern.h>		/* For unblank_screen() */
 
+#include <linux/trace.h>
+
 #include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/pgalloc.h>
@@ -177,6 +179,8 @@
 	mm = tsk->mm;
 	info.si_code = SEGV_MAPERR;
 
+	TRACE_TRAP_ENTRY(14, regs->eip);
+
 	/*
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
@@ -259,6 +263,7 @@
 			tsk->thread.screen_bitmap |= 1 << bit;
 	}
 	up_read(&mm->mmap_sem);
+        TRACE_TRAP_EXIT();
 	return;
 
 /*
@@ -278,6 +283,7 @@
 		/* info.si_code has been set above */
 		info.si_addr = (void *)address;
 		force_sig_info(SIGSEGV, &info, tsk);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
@@ -291,6 +297,7 @@
 
 		if (nr == 6) {
 			do_invalid_op(regs, 0);
+			TRACE_TRAP_EXIT();
 			return;
 		}
 	}
@@ -299,6 +306,7 @@
 	/* Are we prepared to handle this kernel fault?  */
 	if ((fixup = search_exception_table(regs->eip)) != 0) {
 		regs->eip = fixup;
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
@@ -365,6 +373,7 @@
 	/* Kernel mode? Handle exceptions or die */
 	if (!(error_code & 4))
 		goto no_context;
+        TRACE_TRAP_EXIT();
 	return;
 
 vmalloc_fault:
@@ -398,6 +407,8 @@
 		pte_k = pte_offset(pmd_k, address);
 		if (!pte_present(*pte_k))
 			goto no_context;
+		TRACE_TRAP_EXIT();
 		return;
 	}
+	TRACE_TRAP_EXIT();
 }
diff -rbNu linux-2.4.19/arch/mips/baget/irq.c linux-2.4.19-ltt/arch/mips/baget/irq.c
--- linux-2.4.19/arch/mips/baget/irq.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/baget/irq.c	2004-12-28 22:39:46.000000000 +0100
@@ -17,6 +17,7 @@
 #include <linux/slab.h>
 #include <linux/random.h>
 #include <linux/delay.h>
+#include <linux/trace.h>
 
 #include <asm/bitops.h>
 #include <asm/bootinfo.h>
@@ -177,6 +178,8 @@
 	struct irqaction *action;
 	int do_random, cpu;
 
+	TRACE_IRQ_ENTRY(irq, !user_mode(regs));
+
 	cpu = smp_processor_id();
 	irq_enter(cpu, irq);
 	kstat.irqs[cpu][irq]++;
@@ -202,6 +205,8 @@
 	unmask_irq(irq);
 	irq_exit(cpu, irq);
 
+	TRACE_IRQ_EXIT();
+
 	/* unmasking and bottom half handling is done magically for us. */
 }
 
diff -rbNu linux-2.4.19/arch/mips/config.in linux-2.4.19-ltt/arch/mips/config.in
--- linux-2.4.19/arch/mips/config.in	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/config.in	2004-12-28 22:39:46.000000000 +0100
@@ -619,6 +619,11 @@
 source drivers/input/Config.in
 
 mainmenu_option next_comment
+comment 'Kernel tracing'
+tristate 'Kernel events tracing support' CONFIG_TRACE
+endmenu
+
+mainmenu_option next_comment
 comment 'Kernel hacking'
 
 bool 'Are you using a crosscompiler' CONFIG_CROSSCOMPILE
diff -rbNu linux-2.4.19/arch/mips/dec/irq.c linux-2.4.19-ltt/arch/mips/dec/irq.c
--- linux-2.4.19/arch/mips/dec/irq.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/dec/irq.c	2004-12-28 22:39:46.000000000 +0100
@@ -15,6 +15,7 @@
 #include <linux/timex.h>
 #include <linux/slab.h>
 #include <linux/random.h>
+#include <linux/trace.h>
 
 #include <asm/bitops.h>
 #include <asm/bootinfo.h>
@@ -130,6 +131,8 @@
 	struct irqaction *action;
 	int do_random, cpu;
 
+	TRACE_IRQ_ENTRY(irq, !user_mode(regs));
+
 	cpu = smp_processor_id();
 	irq_enter(cpu, irq);
 	kstat.irqs[cpu][irq]++;
@@ -153,6 +156,8 @@
 	}
 	irq_exit(cpu, irq);
 
+	TRACE_IRQ_EXIT();
+
 	if (softirq_pending(cpu))
 		do_softirq();
 }
diff -rbNu linux-2.4.19/arch/mips/kernel/i8259.c linux-2.4.19-ltt/arch/mips/kernel/i8259.c
--- linux-2.4.19/arch/mips/kernel/i8259.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/kernel/i8259.c	2004-12-28 22:39:46.000000000 +0100
@@ -14,6 +14,7 @@
 #include <linux/interrupt.h>
 #include <linux/kernel.h>
 #include <linux/spinlock.h>
+#include <linux/trace.h>
 
 #include <asm/io.h>
 
@@ -265,6 +266,9 @@
 asmlinkage void i8259_do_irq(int irq, struct pt_regs regs)
 {
 	panic("i8259_do_irq: I want to be implemented");
+
+	TRACE_IRQ_ENTRY(irq, !user_mode(regs));
+	TRACE_IRQ_EXIT();
 }
 
 /*
diff -rbNu linux-2.4.19/arch/mips/kernel/ipc.c linux-2.4.19-ltt/arch/mips/kernel/ipc.c
--- linux-2.4.19/arch/mips/kernel/ipc.c	2000-02-25 07:52:30.000000000 +0100
+++ linux-2.4.19-ltt/arch/mips/kernel/ipc.c	2004-12-28 22:39:46.000000000 +0100
@@ -13,6 +13,7 @@
 #include <linux/sem.h>
 #include <linux/msg.h>
 #include <linux/shm.h>
+#include <linux/trace.h>
 
 #include <asm/ipc.h>
 #include <asm/uaccess.h>
@@ -30,6 +31,8 @@
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+
 	switch (call) {
 	case SEMOP:
 		return sys_semop (first, (struct sembuf *)ptr, second);
diff -rbNu linux-2.4.19/arch/mips/kernel/irq.c linux-2.4.19-ltt/arch/mips/kernel/irq.c
--- linux-2.4.19/arch/mips/kernel/irq.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/kernel/irq.c	2004-12-28 22:39:46.000000000 +0100
@@ -20,6 +20,7 @@
 #include <linux/mm.h>
 #include <linux/random.h>
 #include <linux/sched.h>
+#include <linux/trace.h>
 
 #include <asm/atomic.h>
 #include <asm/system.h>
@@ -427,6 +428,8 @@
 	struct irqaction * action;
 	unsigned int status;
 
+	TRACE_IRQ_ENTRY(irq, !user_mode(regs));
+
 	kstat.irqs[cpu][irq]++;
 	spin_lock(&desc->lock);
 	desc->handler->ack(irq);
@@ -486,6 +489,8 @@
 	desc->handler->end(irq);
 	spin_unlock(&desc->lock);
 
+        TRACE_IRQ_EXIT();
+
 	if (softirq_pending(cpu))
 		do_softirq();
 	return 1;
diff -rbNu linux-2.4.19/arch/mips/kernel/scall_o32.S linux-2.4.19-ltt/arch/mips/kernel/scall_o32.S
--- linux-2.4.19/arch/mips/kernel/scall_o32.S	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/kernel/scall_o32.S	2004-12-28 22:39:46.000000000 +0100
@@ -46,6 +46,19 @@
 
 stack_done:
         sw      a3, PT_R26(sp)          # save for syscall restart
+
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	sw	t2, PT_R1(sp)
+	move	a0, sp
+	jal	trace_real_syscall_entry
+	lw	t2, PT_R1(sp)
+
+	lw	a0, PT_R4(sp)		# Restore argument registers
+	lw	a1, PT_R5(sp)
+	lw	a2, PT_R6(sp)
+	lw	a3, PT_R7(sp)
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */	
+
 	lw	t0, TASK_PTRACE($28)	# syscall tracing enabled?
 	andi	t0, PT_TRACESYS
 	bnez	t0, trace_a_syscall
@@ -61,6 +74,10 @@
 	sw	v0, PT_R0(sp)		# set flag for syscall restarting
 1:	sw	v0, PT_R2(sp)		# result
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	jal	trace_real_syscall_exit
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */	
+
 EXPORT(o32_ret_from_sys_call)
 	mfc0	t0, CP0_STATUS		# need_resched and signals atomic test
 	ori	t0, t0, 1
@@ -116,6 +133,10 @@
 	sw	v0, PT_R0(sp)		# set flag for syscall restarting
 1:	sw	v0, PT_R2(sp)		# result
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	jal	trace_real_syscall_exit
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */	
+
 	jal	syscall_trace
 	j	ret_from_sys_call
 
diff -rbNu linux-2.4.19/arch/mips/kernel/time.c linux-2.4.19-ltt/arch/mips/kernel/time.c
--- linux-2.4.19/arch/mips/kernel/time.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/kernel/time.c	2004-12-28 22:39:46.000000000 +0100
@@ -21,6 +21,7 @@
 #include <linux/kernel_stat.h>
 #include <linux/spinlock.h>
 #include <linux/interrupt.h>
+#include <linux/trace.h>
 
 #include <asm/bootinfo.h>
 #include <asm/cpu.h>
@@ -413,6 +414,8 @@
 {
 	int cpu = smp_processor_id();
 
+	TRACE_TRAP_ENTRY(irq, CAUSE_EPC(regs));
+
 	irq_enter(cpu, irq);
 	kstat.irqs[cpu][irq]++;
 
@@ -421,6 +424,8 @@
 	
 	irq_exit(cpu, irq);
 
+	TRACE_IRQ_EXIT();
+
 	if (softirq_pending(cpu))
 		do_softirq();
 }
diff -rbNu linux-2.4.19/arch/mips/kernel/traps.c linux-2.4.19-ltt/arch/mips/kernel/traps.c
--- linux-2.4.19/arch/mips/kernel/traps.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/kernel/traps.c	2004-12-28 22:39:46.000000000 +0100
@@ -20,6 +20,7 @@
 #include <linux/smp.h>
 #include <linux/smp_lock.h>
 #include <linux/spinlock.h>
+#include <linux/trace.h>
 
 #include <asm/bootinfo.h>
 #include <asm/branch.h>
@@ -36,6 +37,7 @@
 #include <asm/traps.h>
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
+#include <asm/unistd.h>
 
 /*
  * Machine specific interrupt handlers
@@ -425,6 +427,8 @@
 	int data = regs->cp0_cause & 4;
 	int action = MIPS_BE_FATAL;
 
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+
 	if (data && !user_mode(regs))
 		fixup = search_dbe_table(regs->cp0_epc);
 
@@ -436,12 +440,14 @@
 
 	switch (action) {
 	case MIPS_BE_DISCARD:
+		TRACE_TRAP_EXIT();
 		return;
 	case MIPS_BE_FIXUP:
 		if (fixup) {
 			new_epc = fixup_exception(dpf_reg, fixup,
 						  regs->cp0_epc);
 			regs->cp0_epc = new_epc;
+			TRACE_TRAP_EXIT();
 			return;
 		}
 		break;
@@ -457,14 +463,20 @@
 	       regs->cp0_epc, regs->regs[31]);
 	die_if_kernel("Oops", regs);
 	force_sig(SIGBUS, current);
+
+	TRACE_TRAP_EXIT();
 }
 
 asmlinkage void do_ov(struct pt_regs *regs)
 {
-	if (compute_return_epc(regs))
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+	if (compute_return_epc(regs)) {
+		TRACE_TRAP_EXIT();
 		return;
+	}
 
 	force_sig(SIGFPE, current);
+	TRACE_TRAP_EXIT();
 }
 
 /*
@@ -472,6 +484,7 @@
  */
 asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 {
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	if (fcr31 & FPU_CSR_UNI_X) {
 		extern void save_fp(struct task_struct *);
 		extern void restore_fp(struct task_struct *);
@@ -512,12 +525,16 @@
 			force_sig(sig, current);
 		}
 
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
-	if (compute_return_epc(regs))
+	if (compute_return_epc(regs)){
+		TRACE_TRAP_EXIT();
 		return;
+	}
 	force_sig(SIGFPE, current);
+	TRACE_TRAP_EXIT();
 }
 
 static inline int get_insn_opcode(struct pt_regs *regs, unsigned int *opcode)
@@ -539,6 +556,8 @@
 	unsigned int opcode, bcode;
 	unsigned int *epc;
 
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+
 	epc = (unsigned int *) regs->cp0_epc +
 	      ((regs->cp0_cause & CAUSEF_BD) != 0);
 	if (get_user(opcode, epc))
@@ -572,10 +591,12 @@
 	default:
 		force_sig(SIGTRAP, current);
 	}
+	TRACE_TRAP_EXIT();
 	return;
 
 sigsegv:
 	force_sig(SIGSEGV, current);
+	TRACE_TRAP_EXIT();
 }
 
 asmlinkage void do_tr(struct pt_regs *regs)
@@ -584,6 +605,8 @@
 	unsigned int opcode, bcode;
 	unsigned *epc;
 
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+
 	epc = (unsigned int *) regs->cp0_epc +
 	      ((regs->cp0_cause & CAUSEF_BD) != 0);
 	if (get_user(opcode, epc))
@@ -612,10 +635,12 @@
 	default:
 		force_sig(SIGTRAP, current);
 	}
+	TRACE_TRAP_EXIT();
 	return;
 
 sigsegv:
 	force_sig(SIGSEGV, current);
+	TRACE_TRAP_EXIT();
 }
 
 /*
@@ -630,6 +655,7 @@
 	if (!user_mode(regs))
 		BUG();
 
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 #ifndef CONFIG_CPU_HAS_LLSC
 
 #ifdef CONFIG_SMP
@@ -642,19 +668,24 @@
 	if (!get_insn_opcode(regs, &opcode)) {
 		if ((opcode & OPCODE) == LL) {
 			simulate_ll(regs, opcode);
+			TRACE_TRAP_EXIT();
 			return;
 		}
 		if ((opcode & OPCODE) == SC) {
 			simulate_sc(regs, opcode);
+			TRACE_TRAP_EXIT();
 			return;
 		}
 	}
 	}
 #endif /* CONFIG_CPU_HAS_LLSC */
 
-	if (compute_return_epc(regs))
+	if (compute_return_epc(regs)) {
+		TRACE_TRAP_EXIT();
 		return;
+	}
 	force_sig(SIGILL, current);
+	TRACE_TRAP_EXIT();
 }
 
 asmlinkage void do_cpu(struct pt_regs *regs)
@@ -666,6 +697,8 @@
 	void fpu_emulator_init_fpu(void);
 	int sig;
 
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+
 	cpid = (regs->cp0_cause >> CAUSEB_CE) & 3;
 	if (cpid != 1)
 		goto bad_cid;
@@ -674,8 +707,10 @@
 		goto fp_emul;
 
 	regs->cp0_status |= ST0_CU1;
-	if (last_task_used_math == current)
+	if (last_task_used_math == current) {
+		TRACE_TRAP_EXIT();
 		return;
+	}
 
 	if (current->used_math) {		/* Using the FPU again.  */
 		lazy_fpu_switch(last_task_used_math);
@@ -686,7 +721,7 @@
 		current->used_math = 1;
 	}
 	last_task_used_math = current;
-
+	TRACE_TRAP_EXIT();
 	return;
 
 fp_emul:
@@ -707,6 +742,7 @@
 		compute_return_epc(regs);
 		force_sig(sig, current);
 	}
+	TRACE_TRAP_EXIT();
 	return;
 
 bad_cid:
@@ -715,11 +751,13 @@
 	case CPU_TX3927:
 	case CPU_TX39XX:
 		do_ri(regs);
+	TRACE_TRAP_EXIT();
 		return;
 	}
 #endif
 	compute_return_epc(regs);
 	force_sig(SIGILL, current);
+	TRACE_TRAP_EXIT();
 }
 
 asmlinkage void do_watch(struct pt_regs *regs)
@@ -730,14 +768,18 @@
 	 * We use the watch exception where available to detect stack
 	 * overflows.
 	 */
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	dump_tlb_all();
 	show_regs(regs);
+	TRACE_TRAP_EXIT();
 	panic("Caught WATCH exception - probably caused by stack overflow.");
 }
 
 asmlinkage void do_mcheck(struct pt_regs *regs)
 {
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	show_regs(regs);
+	TRACE_TRAP_EXIT();
 	panic("Caught Machine Check exception - probably caused by multiple "
 	      "matching entries in the TLB.");
 }
@@ -1068,3 +1110,75 @@
 	current_cpu_data.asid_cache = ASID_FIRST_VERSION;
 	TLBMISS_HANDLER_SETUP();
 }
+
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+asmlinkage void trace_real_syscall_entry(struct pt_regs * regs)
+{
+	unsigned long       addr;
+	int                 depth = 0;
+	unsigned long       end_code;
+	unsigned long       lower_bound;
+	int                 seek_depth;
+	unsigned long       *stack;
+	unsigned long       start_code;
+	unsigned long       *start_stack;
+	trace_syscall_entry trace_syscall_event;
+	unsigned long       upper_bound;
+	int                 use_bounds;
+	int                 use_depth;
+
+	/* syscall_id will be negative for SVR4, IRIX5, BSD43, and POSIX
+	 * syscalls -- these are not supported at this point by LTT
+	 */
+	trace_syscall_event.syscall_id = (uint8_t) (regs->regs[2] - __NR_Linux);
+
+	trace_syscall_event.address  = regs->cp0_epc;
+
+	if (!user_mode(regs))
+		goto trace_syscall_end;
+
+	if (trace_get_config(&use_depth,
+			     &use_bounds,
+			     &seek_depth,
+			     (void*)&lower_bound,
+			     (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	/* Heuristic that might work:
+	 * (BUT DOESN'T WORK for any of the cases I tested...) zzz
+	 * Search through stack until a value is found that is within the
+	 * range start_code .. end_code.  (This is looking for a return
+	 * pointer to where a shared library was called from.)  If a stack
+	 * variable contains a valid code address then an incorrect
+	 * result will be generated.
+	 */
+	if ((use_depth == 1) || (use_bounds == 1)) {
+		stack       = (unsigned long*) regs->regs[29];
+		end_code    = current->mm->end_code;
+		start_code  = current->mm->start_code;
+		start_stack = (unsigned long *)current->mm->start_stack;
+
+		while ((stack <= start_stack) && (!__get_user(addr, stack))) {
+			if ((addr > start_code) && (addr < end_code)) {
+				if (((use_depth  == 1) && (depth == seek_depth)) ||
+				    ((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound))) {
+					trace_syscall_event.address = addr;
+					goto trace_syscall_end;
+				} else {
+					depth++;
+				}
+			}
+		stack++;
+		}
+	}
+
+trace_syscall_end:
+	trace_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
+
+asmlinkage void trace_real_syscall_exit(void)
+{
+        trace_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */
diff -rbNu linux-2.4.19/arch/mips/kernel/unaligned.c linux-2.4.19-ltt/arch/mips/kernel/unaligned.c
--- linux-2.4.19/arch/mips/kernel/unaligned.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/kernel/unaligned.c	2004-12-28 22:39:46.000000000 +0100
@@ -77,6 +77,7 @@
 #include <linux/signal.h>
 #include <linux/smp.h>
 #include <linux/smp_lock.h>
+#include <linux/trace.h>
 
 #include <asm/asm.h>
 #include <asm/branch.h>
@@ -368,6 +369,8 @@
 	unsigned long pc;
 	extern int do_dsemulret(struct pt_regs *);
 
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+
 	/* 
 	 * Address errors may be deliberately induced
 	 * by the FPU emulator to take retake control
@@ -375,8 +378,10 @@
 	 * in the delay slot of an emulated branch.
 	 */
 	/* Terminate if exception was recognized as a delay slot return */
-	if (do_dsemulret(regs))
+	if (do_dsemulret(regs)) {
+		TRACE_TRAP_EXIT();
 		return;
+	}
 
 	/* Otherwise handle as normal */
 
@@ -403,6 +408,7 @@
 	unaligned_instructions++;
 #endif
 
+	TRACE_TRAP_EXIT();
 	return;
 
 sigbus:
@@ -413,5 +419,6 @@
 	 * XXX On return from the signal handler we should advance the epc
 	 */
 
+	TRACE_TRAP_EXIT();
 	return;
 }
diff -rbNu linux-2.4.19/arch/mips/mm/fault.c linux-2.4.19-ltt/arch/mips/mm/fault.c
--- linux-2.4.19/arch/mips/mm/fault.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/mips/mm/fault.c	2004-12-28 22:39:46.000000000 +0100
@@ -19,6 +19,7 @@
 #include <linux/smp.h>
 #include <linux/smp_lock.h>
 #include <linux/version.h>
+#include <linux/trace.h>
 
 #include <asm/branch.h>
 #include <asm/hardirq.h>
@@ -27,6 +28,7 @@
 #include <asm/softirq.h>
 #include <asm/system.h>
 #include <asm/uaccess.h>
+#include <asm/mipsregs.h>
 
 #define development_version (LINUX_VERSION_CODE & 0x100)
 
@@ -82,6 +84,8 @@
 	unsigned long fixup;
 	siginfo_t info;
 
+	TRACE_TRAP_ENTRY(CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+
 	/*
 	 * We fault-in kernel-space virtual memory on-demand. The
 	 * 'reference' page table is init_mm.pgd.
@@ -150,6 +154,7 @@
 	}
 
 	up_read(&mm->mmap_sem);
+	TRACE_TRAP_EXIT();
 	return;
 
 /*
@@ -178,6 +183,7 @@
 		/* info.si_code has been set above */
 		info.si_addr = (void *) address;
 		force_sig_info(SIGSEGV, &info, tsk);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
@@ -193,6 +199,7 @@
 			printk(KERN_DEBUG "%s: Exception at [<%lx>] (%lx)\n",
 			       tsk->comm, regs->cp0_epc, new_epc);
 		regs->cp0_epc = new_epc;
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
@@ -241,6 +248,7 @@
 	if (!user_mode(regs))
 		goto no_context;
 
+	TRACE_TRAP_EXIT();
 	return;
 
 vmalloc_fault:
@@ -270,4 +278,5 @@
 			goto bad_area_nosemaphore;
 		set_pmd(pmd, *pmd_k);
 	}
+	TRACE_TRAP_EXIT();
 }
diff -rbNu linux-2.4.19/arch/ppc/config.in linux-2.4.19-ltt/arch/ppc/config.in
--- linux-2.4.19/arch/ppc/config.in	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/ppc/config.in	2004-12-28 22:39:46.000000000 +0100
@@ -396,6 +396,11 @@
 source net/bluetooth/Config.in
 
 mainmenu_option next_comment
+comment 'Kernel tracing'
+tristate 'Kernel events tracing support' CONFIG_TRACE
+endmenu
+
+mainmenu_option next_comment
 comment 'Kernel hacking'
 
 bool 'Magic SysRq key' CONFIG_MAGIC_SYSRQ
diff -rbNu linux-2.4.19/arch/ppc/kernel/entry.S linux-2.4.19-ltt/arch/ppc/kernel/entry.S
--- linux-2.4.19/arch/ppc/kernel/entry.S	2002-02-25 20:37:55.000000000 +0100
+++ linux-2.4.19-ltt/arch/ppc/kernel/entry.S	2004-12-28 22:39:46.000000000 +0100
@@ -41,6 +41,32 @@
 	.long	-1
 #endif
 
+/* LTT stuff */
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+#define TRACE_REAL_ASM_SYSCALL_ENTRY	\
+	addi	r3,r1,STACK_FRAME_OVERHEAD;  	/* Put pointer to registers into r3 */	\
+	mflr	r29;				/* Save LR */ \
+	bl	trace_real_syscall_entry;	/* Call real trace function */ \
+	mtlr	r29;				/* Restore LR */ \
+	lwz	r0,GPR0(r1);			/* Restore original registers */ \
+	lwz	r3,GPR3(r1);	\
+	lwz	r4,GPR4(r1);	\
+	lwz	r5,GPR5(r1);	\
+	lwz	r6,GPR6(r1);	\
+	lwz	r7,GPR7(r1);	\
+	lwz	r8,GPR8(r1);
+#define TRACE_REAL_ASM_SYSCALL_EXIT \
+	bl	trace_real_syscall_exit;	/* Call real trace function */ \
+	lwz	r0,GPR0(r1);			/* Restore original registers */ \
+	lwz	r3,RESULT(r1); \
+	lwz	r4,GPR4(r1); \
+	lwz	r5,GPR5(r1); \
+	lwz	r6,GPR6(r1); \
+	lwz	r7,GPR7(r1); \
+	lwz	r8,GPR8(r1); \
+	addi	r9,r1,STACK_FRAME_OVERHEAD;
+#endif
+
 /*
  * Handle a system call.
  */
@@ -98,11 +124,17 @@
 	cmpi	0,r10,0
 	beq-	66f
 	mtlr	r10
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	TRACE_REAL_ASM_SYSCALL_ENTRY ;
+#endif
 	addi	r9,r1,STACK_FRAME_OVERHEAD
 	blrl			/* Call handler */
 	.globl	ret_from_syscall_1
 ret_from_syscall_1:
 20:	stw	r3,RESULT(r1)	/* Save result */
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	TRACE_REAL_ASM_SYSCALL_EXIT ; 
+#endif
 #ifdef SHOW_SYSCALLS
 #ifdef SHOW_SYSCALLS_TASK
 	cmp	0,r2,r31
@@ -160,11 +192,17 @@
 	cmpi	0,r10,0
 	beq-	66f
 	mtlr	r10
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	TRACE_REAL_ASM_SYSCALL_ENTRY ;
+#endif
 	addi	r9,r1,STACK_FRAME_OVERHEAD
 	blrl			/* Call handler */
 	.globl	ret_from_syscall_2
 ret_from_syscall_2:
 	stw	r3,RESULT(r1)	/* Save result */	
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	TRACE_REAL_ASM_SYSCALL_EXIT ; 
+#endif
 	stw	r3,GPR0(r1)	/* temporary gross hack to make strace work */
 	li	r10,-_LAST_ERRNO
 	cmpl	0,r3,r10
diff -rbNu linux-2.4.19/arch/ppc/kernel/irq.c linux-2.4.19-ltt/arch/ppc/kernel/irq.c
--- linux-2.4.19/arch/ppc/kernel/irq.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/ppc/kernel/irq.c	2004-12-28 22:39:46.000000000 +0100
@@ -48,6 +48,8 @@
 #include <linux/proc_fs.h>
 #include <linux/random.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/bitops.h>
 #include <asm/hydra.h>
@@ -455,6 +457,8 @@
 	int cpu = smp_processor_id();
 	irq_desc_t *desc = irq_desc + irq;
 
+	TRACE_IRQ_ENTRY(irq, !(user_mode(regs)));
+
 	kstat.irqs[cpu][irq]++;
 	spin_lock(&desc->lock);
 	ack_irq(irq);	
@@ -532,6 +536,8 @@
 			irq_desc[irq].handler->enable(irq);
 	}
 	spin_unlock(&desc->lock);
+
+	TRACE_IRQ_EXIT();
 }
 
 int do_IRQ(struct pt_regs *regs)
diff -rbNu linux-2.4.19/arch/ppc/kernel/misc.S linux-2.4.19-ltt/arch/ppc/kernel/misc.S
--- linux-2.4.19/arch/ppc/kernel/misc.S	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/ppc/kernel/misc.S	2004-12-28 22:39:46.000000000 +0100
@@ -896,7 +896,11 @@
  * Create a kernel thread
  *   kernel_thread(fn, arg, flags)
  */
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+_GLOBAL(original_kernel_thread)
+#else
 _GLOBAL(kernel_thread)
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */
 	mr	r6,r3		/* function */
 	ori	r3,r5,CLONE_VM	/* flags */
 	li	r0,__NR_clone
diff -rbNu linux-2.4.19/arch/ppc/kernel/process.c linux-2.4.19-ltt/arch/ppc/kernel/process.c
--- linux-2.4.19/arch/ppc/kernel/process.c	2001-11-26 14:29:17.000000000 +0100
+++ linux-2.4.19-ltt/arch/ppc/kernel/process.c	2004-12-28 22:39:46.000000000 +0100
@@ -35,6 +35,8 @@
 #include <linux/elf.h>
 #include <linux/init.h>
 
+#include <linux/trace.h>
+
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -294,6 +296,19 @@
 	print_backtrace((unsigned long *)regs->gpr[1]);
 }
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+long original_kernel_thread(int (*fn) (void *), void* arg, unsigned long flags);
+long kernel_thread(int (*fn) (void *), void* arg, unsigned long flags)
+{
+        long   retval;
+
+	retval = original_kernel_thread(fn, arg, flags);
+	if (retval > 0)
+	        TRACE_PROCESS(TRACE_EV_PROCESS_KTHREAD, retval, (int) fn);
+	return retval;
+}
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */
+
 void exit_thread(void)
 {
 	if (last_task_used_math == current)
diff -rbNu linux-2.4.19/arch/ppc/kernel/syscalls.c linux-2.4.19-ltt/arch/ppc/kernel/syscalls.c
--- linux-2.4.19/arch/ppc/kernel/syscalls.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/ppc/kernel/syscalls.c	2004-12-28 22:39:46.000000000 +0100
@@ -39,6 +39,8 @@
 #include <linux/utsname.h>
 #include <linux/file.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
 #include <asm/semaphore.h>
@@ -85,6 +87,8 @@
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+
 	ret = -EINVAL;
 	switch (call) {
 	case SEMOP:
diff -rbNu linux-2.4.19/arch/ppc/kernel/time.c linux-2.4.19-ltt/arch/ppc/kernel/time.c
--- linux-2.4.19/arch/ppc/kernel/time.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/ppc/kernel/time.c	2004-12-28 22:39:46.000000000 +0100
@@ -60,6 +60,8 @@
 #include <linux/time.h>
 #include <linux/init.h>
 
+#include <linux/trace.h>
+
 #include <asm/segment.h>
 #include <asm/io.h>
 #include <asm/processor.h>
@@ -151,6 +153,8 @@
 	if (atomic_read(&ppc_n_lost_interrupts) != 0)
 		do_IRQ(regs);
 
+	TRACE_TRAP_ENTRY(regs->trap, instruction_pointer(regs));
+
 	hardirq_enter(cpu);
 	
 	while ((next_dec = tb_ticks_per_jiffy - tb_delta(&jiffy_stamp)) < 0) {
@@ -209,6 +213,8 @@
 	if (softirq_pending(cpu))
 		do_softirq();
 
+	TRACE_TRAP_EXIT();
+
 	return 1; /* lets ret_from_int know we can do checks */
 }
 
diff -rbNu linux-2.4.19/arch/ppc/kernel/traps.c linux-2.4.19-ltt/arch/ppc/kernel/traps.c
--- linux-2.4.19/arch/ppc/kernel/traps.c	2001-11-03 02:43:54.000000000 +0100
+++ linux-2.4.19-ltt/arch/ppc/kernel/traps.c	2004-12-28 22:39:46.000000000 +0100
@@ -33,6 +33,8 @@
 #include <linux/config.h>
 #include <linux/init.h>
 
+#include <linux/trace.h>
+
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -99,7 +101,9 @@
 #endif
 		die("Exception in kernel mode", regs, signr);
 	}
+	TRACE_TRAP_ENTRY(regs->trap, instruction_pointer(regs));
 	force_sig(signr, current);
+	TRACE_TRAP_EXIT();
 }
 
 void
@@ -352,6 +356,89 @@
 	panic("kernel stack overflow");
 }
 
+/* Trace related code */
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+asmlinkage void trace_real_syscall_entry(struct pt_regs * regs)
+{
+        int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+        int                 seek_depth;
+        unsigned long       lower_bound;
+        unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+        /* Set the syscall ID */
+	trace_syscall_event.syscall_id = (uint8_t) regs->gpr[0];
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = instruction_pointer(regs);
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!user_mode(regs))
+	  /* Don't go digining anywhere */
+	  goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(trace_get_config(&use_depth,
+			    &use_bounds,
+			    &seek_depth,
+			    (void*)&lower_bound,
+			    (void*)&upper_bound) < 0)
+	  goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	  {
+	  /* Start at the top of the stack (bottom address since stacks grow downward) */
+	  stack = (unsigned long*) regs->gpr[1];
+
+	  /* Skip over first stack frame as the return address isn't valid */
+	  if(get_user(addr, stack))
+	    goto trace_syscall_end;
+	  stack = (unsigned long*) addr;
+
+	  /* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+	  while(!get_user(addr, stack + 1)) /* "stack + 1", since this is where the IP is */
+	    {
+	    /* Does this LOOK LIKE an address in the program */
+	    if((addr > current->mm->start_code)
+             &&(addr < current->mm->end_code))
+	      {
+	      /* Does this address fit the description */
+	      if(((use_depth == 1) && (depth == seek_depth))
+               ||((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound)))
+		{
+		/* Set the address */
+		trace_syscall_event.address = addr;
+
+		/* We're done */
+		goto trace_syscall_end;
+		}
+	      else
+		/* We're one depth more */
+		depth++;
+	      }
+	    /* Go on to the next address */
+	    if(get_user(addr, stack))
+	      goto trace_syscall_end;
+	    stack = (unsigned long*) addr;
+	    }
+	  }
+
+trace_syscall_end:
+	/* Trace the event */
+	trace_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
+
+asmlinkage void trace_real_syscall_exit(void)
+{
+        trace_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */
+
 void
 trace_syscall(struct pt_regs *regs)
 {
diff -rbNu linux-2.4.19/arch/ppc/mm/fault.c linux-2.4.19-ltt/arch/ppc/mm/fault.c
--- linux-2.4.19/arch/ppc/mm/fault.c	2001-10-02 18:12:44.000000000 +0200
+++ linux-2.4.19-ltt/arch/ppc/mm/fault.c	2004-12-28 22:39:46.000000000 +0100
@@ -30,6 +30,8 @@
 #include <linux/mm.h>
 #include <linux/interrupt.h>
 
+#include <linux/trace.h>
+
 #include <asm/page.h>
 #include <asm/pgtable.h>
 #include <asm/mmu.h>
@@ -85,22 +87,28 @@
 		is_write = error_code & 0x02000000;
 #endif /* CONFIG_4xx */
 
+	TRACE_TRAP_ENTRY(regs->trap, instruction_pointer(regs));
+
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
 	if (debugger_fault_handler && regs->trap == 0x300) {
 		debugger_fault_handler(regs);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 #if !defined(CONFIG_4xx)
 	if (error_code & 0x00400000) {
 		/* DABR match */
-		if (debugger_dabr_match(regs))
+   	        if (debugger_dabr_match(regs)){
+		        TRACE_TRAP_EXIT();
 			return;
 	}
+	}
 #endif /* !CONFIG_4xx */
 #endif /* CONFIG_XMON || CONFIG_KGDB */
 
 	if (in_interrupt() || mm == NULL) {
 		bad_page_fault(regs, address, SIGSEGV);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 	down_read(&mm->mmap_sem);
@@ -171,6 +179,7 @@
 	 * -- Cort
 	 */
 	pte_misses++;
+	TRACE_TRAP_EXIT();
 	return;
 
 bad_area:
@@ -184,10 +193,12 @@
 		info.si_code = code;
 		info.si_addr = (void *) address;
 		force_sig_info(SIGSEGV, &info, current);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
 	bad_page_fault(regs, address, SIGSEGV);
+	TRACE_TRAP_EXIT();
 	return;
 
 /*
@@ -206,6 +217,7 @@
 	if (user_mode(regs))
 		do_exit(SIGKILL);
 	bad_page_fault(regs, address, SIGKILL);
+	TRACE_TRAP_EXIT();
 	return;
 
 do_sigbus:
@@ -217,6 +229,7 @@
 	force_sig_info (SIGBUS, &info, current);
 	if (!user_mode(regs))
 		bad_page_fault(regs, address, SIGBUS);
+	TRACE_TRAP_EXIT();
 }
 
 /*
diff -rbNu linux-2.4.19/arch/s390/config.in linux-2.4.19-ltt/arch/s390/config.in
--- linux-2.4.19/arch/s390/config.in	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/s390/config.in	2004-12-28 22:39:46.000000000 +0100
@@ -66,6 +66,11 @@
 source fs/Config.in
 
 mainmenu_option next_comment
+comment 'Kernel tracing'                             
+tristate 'Kernel events tracing support' CONFIG_TRACE
+endmenu                                              
+
+mainmenu_option next_comment
 comment 'Kernel hacking'
 
 #bool 'Debug kmalloc/kfree' CONFIG_DEBUG_MALLOC
diff -rbNu linux-2.4.19/arch/s390/kernel/entry.S linux-2.4.19-ltt/arch/s390/kernel/entry.S
--- linux-2.4.19/arch/s390/kernel/entry.S	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/s390/kernel/entry.S	2004-12-28 22:39:46.000000000 +0100
@@ -7,6 +7,7 @@
  *    Author(s): Martin Schwidefsky (schwidefsky@de.ibm.com),
  *               Hartmut Penner (hp@de.ibm.com),
  *               Denis Joseph Barrow (djbarrow@de.ibm.com,barrow_dj@yahoo.com),
+ *  Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  */
 
 #include <linux/sys.h>
@@ -179,6 +180,14 @@
         sll     %r8,2
         GET_CURRENT               # load pointer to task_struct to R9
         stosm   24(%r15),0x03     # reenable interrupts
+/* call to ltt trace done here.  R8 has the syscall (svc) number to trace */
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE) /* tjh - ltt port */              
+        /* add call to trace_real_syscall_entry */                          
+        la      %r2,SP_PTREGS(%r15)   # load pt_regs as first parameter     
+        l       %r1,BASED(.Ltracesysent)                                    
+        basr    %r14,%r1                                                    
+        lm      %r0,%r6,SP_R0(%r15) /* restore call clobbered regs tjh */   
+#endif
         l       %r8,sys_call_table-entry_base(%r8,%r13) # get system call addr.
         tm      __TASK_ptrace+3(%r9),0x02 # PT_TRACESYS
         bnz     BASED(sysc_tracesys)
@@ -187,6 +196,13 @@
                                   # ATTENTION: check sys_execve_glue before
                                   # changing anything here !!
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE) /* tjh - ltt port *            
+        /* add call to trace_real_syscall_exit */ 
+        la      %r2,SP_PTREGS(%r15)   # load pt_regs as first parameter  
+        l       %r1,BASED(.Ltracesysext)                                 
+        basr    %r14,%r1                                                 
+        lm      %r0,%r6,SP_R0(%r15) /* restore call clobbered regs */
+#endif                                                                   
 sysc_return:
         tm      SP_PSW+1(%r15),0x01 # returning to user ?
         bno     BASED(sysc_leave) # no-> skip resched & signal
@@ -866,6 +882,8 @@
 .Lsigaltstack: .long  sys_sigaltstack
 .Ltrace:       .long  syscall_trace
 .Lvfork:       .long  sys_vfork
+.Ltracesysent: .long  trace_real_syscall_entry
+.Ltracesysext: .long  trace_real_syscall_exit 
 
 .Lschedtail:   .long  schedule_tail
 
diff -rbNu linux-2.4.19/arch/s390/kernel/process.c linux-2.4.19-ltt/arch/s390/kernel/process.c
--- linux-2.4.19/arch/s390/kernel/process.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/s390/kernel/process.c	2004-12-28 22:39:46.000000000 +0100
@@ -36,6 +36,7 @@
 #include <linux/delay.h>
 #include <linux/reboot.h>
 #include <linux/init.h>
+#include <linux/trace.h>
 
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
@@ -129,6 +130,10 @@
                 : "d" (clone_arg), "i" (__NR_clone), "i" (__NR_exit),
                   "d" (arg), "d" (fn), "i" (__LC_KERNEL_STACK) , "i" (-STACK_FRAME_OVERHEAD)
                 : "2", "3", "4" );
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)                           
+        if (retval > 0)                                             
+          TRACE_PROCESS(TRACE_EV_PROCESS_KTHREAD, retval, (int) fn);
+#endif
         return retval;
 }
 
diff -rbNu linux-2.4.19/arch/s390/kernel/sys_s390.c linux-2.4.19-ltt/arch/s390/kernel/sys_s390.c
--- linux-2.4.19/arch/s390/kernel/sys_s390.c	2001-03-19 21:35:11.000000000 +0100
+++ linux-2.4.19-ltt/arch/s390/kernel/sys_s390.c	2004-12-28 22:39:46.000000000 +0100
@@ -24,6 +24,7 @@
 #include <linux/mman.h>
 #include <linux/file.h>
 #include <linux/utsname.h>
+#include <linux/trace.h>
 
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
@@ -145,6 +146,8 @@
         struct ipc_kludge tmp;
 	int ret;
 
+        TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+
         switch (call) {
         case SEMOP:
                 return sys_semop (first, (struct sembuf *)ptr, second);
diff -rbNu linux-2.4.19/arch/s390/kernel/traps.c linux-2.4.19-ltt/arch/s390/kernel/traps.c
--- linux-2.4.19/arch/s390/kernel/traps.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/s390/kernel/traps.c	2004-12-28 22:39:46.000000000 +0100
@@ -5,6 +5,7 @@
  *    Copyright (C) 1999,2000 IBM Deutschland Entwicklung GmbH, IBM Corporation
  *    Author(s): Martin Schwidefsky (schwidefsky@de.ibm.com),
  *               Denis Joseph Barrow (djbarrow@de.ibm.com,barrow_dj@yahoo.com),
+ *  Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  *
  *  Derived from "arch/i386/kernel/traps.c"
  *    Copyright (C) 1991, 1992 Linus Torvalds
@@ -28,6 +29,8 @@
 #include <linux/delay.h>
 #include <linux/module.h>
 
+#include <linux/trace.h>
+
 #include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/io.h>
@@ -274,12 +277,18 @@
 static void inline do_trap(long interruption_code, int signr, char *str,
                            struct pt_regs *regs, siginfo_t *info)
 {
+        trapid_t ltt_interruption_code; 
+        char * ic_ptr = (char *) &ltt_interruption_code;
+
 	/*
 	 * We got all needed information from the lowcore and can
 	 * now safely switch on interrupts.
 	 */
         if (regs->psw.mask & PSW_PROBLEM_STATE)
 		__sti();
+        memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+        memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+        TRACE_TRAP_ENTRY(ltt_interruption_code, (regs->psw.addr & PSW_ADDR_MASK));
 
         if (regs->psw.mask & PSW_PROBLEM_STATE) {
                 struct task_struct *tsk = current;
@@ -309,6 +318,7 @@
                 else
                         die(str, regs, interruption_code);
         }
+	TRACE_TRAP_EXIT();
 }
 
 static inline void *get_check_address(struct pt_regs *regs)
@@ -406,6 +416,8 @@
 {
         __u8 opcode[6];
 	__u16 *location;
+        trapid_t ltt_interruption_code;
+        char * ic_ptr = (char *) &ltt_interruption_code;
 	int signal = 0;
 
 	location = (__u16 *)(regs->psw.addr-S390_lowcore.pgm_ilc);
@@ -416,6 +428,9 @@
 	 */
 	if (regs->psw.mask & PSW_PROBLEM_STATE)
 		__sti();
+        memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+        memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+        TRACE_TRAP_ENTRY(ltt_interruption_code, (regs->psw.addr & PSW_ADDR_MASK));
 
 	if (regs->psw.mask & PSW_PROBLEM_STATE)
 		get_user(*((__u16 *) opcode), location);
@@ -457,6 +472,7 @@
         else if (signal)
 		do_trap(interruption_code, signal,
 			"illegal operation", regs, NULL);
+        TRACE_TRAP_EXIT();
 }
 
 
@@ -467,6 +483,8 @@
 {
         __u8 opcode[6];
 	__u16 *location = NULL;
+        trapid_t ltt_interruption_code;
+        char * ic_ptr = (char *) &ltt_interruption_code;
 	int signal = 0;
 
 	location = (__u16 *) get_check_address(regs);
@@ -477,6 +495,9 @@
 	 */
 	if (regs->psw.mask & PSW_PROBLEM_STATE)
 		__sti();
+        memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+        memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+        TRACE_TRAP_ENTRY(ltt_interruption_code, (regs->psw.addr & PSW_ADDR_MASK));
 		
         if (regs->psw.mask & PSW_PROBLEM_STATE) {
 		get_user(*((__u16 *) opcode), location);
@@ -521,6 +542,7 @@
 		do_trap(interruption_code, signal, 
 			"specification exception", regs, &info);
 	}
+        TRACE_TRAP_EXIT();
 }
 #else
 DO_ERROR_INFO(SIGILL, "specification exception", specification_exception,
@@ -531,6 +553,8 @@
 {
         __u8 opcode[6];
 	__u16 *location;
+        trapid_t ltt_interruption_code;
+        char * ic_ptr = (char *) &ltt_interruption_code;
 	int signal = 0;
 
 	location = (__u16 *) get_check_address(regs);
@@ -541,6 +565,9 @@
 	 */
 	if (regs->psw.mask & PSW_PROBLEM_STATE)
 		__sti();
+        memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+        memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+        TRACE_TRAP_ENTRY(ltt_interruption_code, (regs->psw.addr & PSW_ADDR_MASK));
 
 	if (MACHINE_HAS_IEEE)
 		__asm__ volatile ("stfpc %0\n\t" 
@@ -616,6 +643,7 @@
 		do_trap(interruption_code, signal, 
 			"data exception", regs, &info);
 	}
+        TRACE_TRAP_EXIT();
 }
 
 
@@ -668,6 +696,11 @@
 
 void handle_per_exception(struct pt_regs *regs)
 {
+        trapid_t ltt_interruption_code;
+        char * ic_ptr = (char *) &ltt_interruption_code;
+        memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+        memcpy(ic_ptr+6,&S390_lowcore.pgm_code,2); /* copy the interrupt code */
+        TRACE_TRAP_ENTRY(ltt_interruption_code,(regs->psw.addr & PSW_ADDR_MASK));
 	if(regs->psw.mask&PSW_PROBLEM_STATE)
 	{
 		per_struct *per_info=&current->thread.per_info;
@@ -684,5 +717,91 @@
 		/* Hopefully switching off per tracing will help us survive */
 		regs->psw.mask &= ~PSW_PER_MASK;
 	}
+        TRACE_TRAP_EXIT();
 }
 
+/* ltt - Trace related code  */                                
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)                      
+asmlinkage void trace_real_syscall_entry(struct pt_regs * regs)
+{                                                              
+        int                 use_depth;                         
+        int                 use_bounds;                        
+        int                 depth = 0;                         
+        int                 seek_depth;                        
+        unsigned long       lower_bound;                       
+        unsigned long       upper_bound;                       
+        unsigned long       addr;                              
+        unsigned long*      stack;
+        unsigned long       temp_stack;
+        trace_syscall_entry trace_syscall_event;               
+        /* Set the syscall ID                               */ 
+        /* Register 8 is setup just prior to the call       */ 
+        /* This instruction is just following linkage       */ 
+        /* so it's ok.  If moved and chance of R8 being     */ 
+        /* clobbered, would need to dig it out of the stack */ 
+        __asm__ volatile(                                      
+        "  stc  8,%0\n\t"                                      
+        : "=m" (trace_syscall_event.syscall_id));              
+        /* get the psw address */                              
+        trace_syscall_event.address  = regs->psw.addr;         
+        /* and off the hi-order bit */                                          
+        trace_syscall_event.address &= PSW_ADDR_MASK;                           
+        if(!(user_mode(regs))) /* if kernel mode, return */                     
+           goto trace_syscall_end;                                              
+        /* Get the trace configuration - if none, return */                     
+        if(trace_get_config(&use_depth,                                         
+                            &use_bounds,                                        
+                            &seek_depth,                                        
+                            (void*)&lower_bound,                                
+                            (void*)&upper_bound) < 0)                           
+          goto trace_syscall_end;                                               
+        /* Do we have to search for an instruction pointer address range */     
+        if((use_depth == 1) || (use_bounds == 1))                               
+        {                                                                       
+          /* Start at the top of the stack */                                   
+          /* stack pointer is register 15 */                                    
+          stack = (unsigned long*) regs->gprs[15]; /* stack pointer */      
+          /* Keep on going until we reach the end of the process' stack limit */
+          do
+          {
+            get_user(addr,stack+14);  /* get the program address +0x38 */ 
+            /* and off the hi-order bit */
+            addr &= PSW_ADDR_MASK;                                
+            /* Does this LOOK LIKE an address in the program */
+            if ((addr > current->mm->start_code)               
+               &&(addr < current->mm->end_code))               
+            { 
+              /* Does this address fit the description */      
+              if(((use_depth == 1) && (depth == seek_depth))   
+                ||((use_bounds == 1) && (addr > lower_bound)   
+                && (addr < upper_bound)))
+                {
+                  /* Set the address */   
+                  trace_syscall_event.address = addr; 
+                  /* We're done */                             
+                  goto trace_syscall_end;                      
+                }                                              
+              else                                             
+                /* We're one depth more */                     
+                depth++; 
+            }
+            /* Go on to the next address */
+            get_user(temp_stack,stack); /* get contents of stack */
+            temp_stack &= PSW_ADDR_MASK; /* and off hi order bit */
+            stack = (unsigned long *)temp_stack; /* move into stack */
+            /* stack may or may not go to zero when end hit               */
+            /* using 0x7fffffff-_STK_LIM to validate that the address is  */
+            /* within the range of a valid stack address                  */
+            /* If outside that range, exit the loop, stack end must have  */
+            /* been hit.                                                  */
+          } while (stack >= (unsigned long *)(0x7fffffff-_STK_LIM));
+        }                                                         
+trace_syscall_end:                                                
+        /* Trace the event */                                     
+        trace_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}                                                                 
+asmlinkage void trace_real_syscall_exit(void)                     
+{                                                                 
+  trace_event(TRACE_EV_SYSCALL_EXIT, NULL);                       
+}                                                                 
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */                
diff -rbNu linux-2.4.19/arch/s390/mm/fault.c linux-2.4.19-ltt/arch/s390/mm/fault.c
--- linux-2.4.19/arch/s390/mm/fault.c	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/s390/mm/fault.c	2004-12-28 22:39:46.000000000 +0100
@@ -5,6 +5,7 @@
  *    Copyright (C) 1999 IBM Deutschland Entwicklung GmbH, IBM Corporation
  *    Author(s): Hartmut Penner (hp@de.ibm.com)
  *               Ulrich Weigand (uweigand@de.ibm.com)
+ *  Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  *
  *  Derived from "arch/i386/mm/fault.c"
  *    Copyright (C) 1995  Linus Torvalds
@@ -25,6 +26,7 @@
 #include <linux/compatmac.h>
 #include <linux/init.h>
 #include <linux/console.h>
+#include <linux/trace.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
@@ -154,6 +156,8 @@
 	int user_address;
         unsigned long fixup;
 	int si_code = SEGV_MAPERR;
+        trapid_t ltt_interruption_code;                 
+        char * ic_ptr = (char *) &ltt_interruption_code; 
 
         tsk = current;
         mm = tsk->mm;
@@ -201,6 +205,9 @@
 	 */
 	__sti();
 
+        memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+        memcpy(ic_ptr+4,&error_code,sizeof(error_code));
+        TRACE_TRAP_ENTRY(ltt_interruption_code,(regs->psw.addr & PSW_ADDR_MASK));
         down_read(&mm->mmap_sem);
 
         vma = find_vma(mm, address);
@@ -247,6 +254,7 @@
 	}
 
         up_read(&mm->mmap_sem);
+        TRACE_TRAP_EXIT();
         return;
 
 /*
@@ -261,6 +269,7 @@
                 tsk->thread.prot_addr = address;
                 tsk->thread.trap_no = error_code;
 		force_sigsegv(regs, error_code, si_code, address);
+                TRACE_TRAP_EXIT();
                 return;
 	}
 
@@ -268,6 +277,7 @@
         /* Are we prepared to handle this kernel fault?  */
         if ((fixup = search_exception_table(regs->psw.addr)) != 0) {
                 regs->psw.addr = fixup;
+                TRACE_TRAP_EXIT();
                 return;
         }
 
@@ -317,6 +327,8 @@
 	/* Kernel mode? Handle exceptions or die */
 	if (!(regs->psw.mask & PSW_PROBLEM_STATE))
 		goto no_context;
+
+	TRACE_TRAP_EXIT();
 }
 
 void do_protection_exception(struct pt_regs *regs, unsigned long error_code)
diff -rbNu linux-2.4.19/arch/sh/config.in linux-2.4.19-ltt/arch/sh/config.in
--- linux-2.4.19/arch/sh/config.in	2002-02-25 20:37:56.000000000 +0100
+++ linux-2.4.19-ltt/arch/sh/config.in	2004-12-28 22:39:46.000000000 +0100
@@ -385,4 +385,10 @@
 if [ "$CONFIG_SH_STANDARD_BIOS" = "y" ]; then
    bool 'Early printk support' CONFIG_SH_EARLY_PRINTK
 fi
+
+mainmenu_option next_comment
+comment 'Kernel tracing'
+tristate 'Kernel events tracing support' CONFIG_TRACE
+endmenu
+
 endmenu
diff -rbNu linux-2.4.19/arch/sh/kernel/entry.S linux-2.4.19-ltt/arch/sh/kernel/entry.S
--- linux-2.4.19/arch/sh/kernel/entry.S	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/arch/sh/kernel/entry.S	2004-12-28 22:39:46.000000000 +0100
@@ -371,6 +371,20 @@
 	mov.l	r10, @r14		! set syscall_nr
 	STI()
 	!
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	! TODO: for i386 this code only happens when not ptrace'd
+	mov 	r15, r4     	    	! pass pt_regs* as first arg
+	mov.l	__trsen, r11 	    	! Call trace_real_syscall_entry()
+	jsr	@r11	    	    	! (will chomp R[0-7])
+	 nop
+	!   	    	    	    	Reload R4-R7 from kernel stack
+	mov.l	@(OFF_R4,r15), r4   ! arg0
+	mov.l	@(OFF_R5,r15), r5
+	mov.l	@(OFF_R6,r15), r6
+	mov.l	@(OFF_R7,r15), r7   ! arg3
+	mov.l	@(OFF_R3,r15), r3   ! syscall_nr
+#endif
+
 	stc	k_current, r11
 	mov.l	@(tsk_ptrace,r11), r10	! Is current PTRACE_SYSCALL'd?
 	mov	#PT_TRACESYS, r11
@@ -422,6 +436,14 @@
 	! In case of trace
 syscall_ret_trace:
 	mov.l	r0, @(OFF_R0,r15)		! save the return value
+
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+    	! TODO: for i386 this code only happens when not ptrace'd
+	mov.l	__trsex, r1 	    	! Call trace_real_syscall_exit()
+	jsr	@r1
+	 nop
+#endif
+
 	mov.l	__syscall_trace, r1
 	mova	SYMBOL_NAME(ret_from_syscall), r0
 	jmp	@r1    	! Call syscall_trace() which notifies superior
@@ -505,6 +527,14 @@
 	.long	syscall_ret_trace
 __syscall_ret:
 	.long	syscall_ret
+	
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+__trsen:
+	.long	SYMBOL_NAME(trace_real_syscall_entry)
+__trsex:
+	.long	SYMBOL_NAME(trace_real_syscall_exit)
+#endif
+
 __INV_IMASK:
 	.long	0xffffff0f	! ~(IMASK)
 
@@ -537,6 +567,14 @@
 #endif
 syscall_ret:
 	mov.l	r0, @(OFF_R0,r15)	! save the return value
+
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	! TODO: for i386 this code only happens when not ptrace'd
+	mov.l	__trsex2, r1 	    	! Call trace_real_syscall_exit()
+	jsr	@r1
+	 nop
+#endif
+
 	/* fall through */
 
 ENTRY(ret_from_syscall)
@@ -564,6 +602,10 @@
 	.long	SYMBOL_NAME(do_signal)
 __irq_stat:
 	.long	SYMBOL_NAME(irq_stat)
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+__trsex2:
+	.long	SYMBOL_NAME(trace_real_syscall_exit)
+#endif
 
 	.align 2
 restore_all:
diff -rbNu linux-2.4.19/arch/sh/kernel/irq.c linux-2.4.19-ltt/arch/sh/kernel/irq.c
--- linux-2.4.19/arch/sh/kernel/irq.c	2001-09-08 21:29:09.000000000 +0200
+++ linux-2.4.19-ltt/arch/sh/kernel/irq.c	2004-12-28 22:39:46.000000000 +0100
@@ -28,6 +28,8 @@
 #include <linux/smp_lock.h>
 #include <linux/init.h>
 
+#include <linux/trace.h>
+
 #include <asm/system.h>
 #include <asm/io.h>
 #include <asm/bitops.h>
@@ -126,6 +128,12 @@
 
 	irq_enter(cpu, irq);
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+    	if (irq != TIMER_IRQ) { /* avoid double-reporting the timer IRQ */
+		TRACE_IRQ_ENTRY(irq, !(user_mode(regs)));
+	}
+#endif
+
 	status = 1;	/* Force the "do bottom halves" bit */
 
 	if (!(action->flags & SA_INTERRUPT))
@@ -142,6 +150,12 @@
 
 	irq_exit(cpu, irq);
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+    	if (irq != TIMER_IRQ) { /* avoid double-reporting the timer IRQ */
+		TRACE_IRQ_EXIT();
+	}
+#endif
+
 	return status;
 }
 
diff -rbNu linux-2.4.19/arch/sh/kernel/process.c linux-2.4.19-ltt/arch/sh/kernel/process.c
--- linux-2.4.19/arch/sh/kernel/process.c	2001-10-15 22:36:48.000000000 +0200
+++ linux-2.4.19-ltt/arch/sh/kernel/process.c	2004-12-28 22:39:46.000000000 +0100
@@ -14,6 +14,8 @@
 #include <linux/unistd.h>
 #include <linux/slab.h>
 
+#include <linux/trace.h>
+
 #include <asm/io.h>
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -140,7 +142,16 @@
 		: "i" (__NR_exit), "r" (__sc3), "r" (__sc4), "r" (__sc5), 
 		  "r" (__sc8), "r" (__sc9)
 		: "memory", "t");
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	{
+		volatile unsigned long retval = __sc0;
+		if (retval > 0)
+			TRACE_PROCESS(TRACE_EV_PROCESS_KTHREAD, retval, (int) fn);
+		return retval;
+	}
+#else
 	return __sc0;
+#endif
 }
 
 /*
diff -rbNu linux-2.4.19/arch/sh/kernel/sys_sh.c linux-2.4.19-ltt/arch/sh/kernel/sys_sh.c
--- linux-2.4.19/arch/sh/kernel/sys_sh.c	2001-10-15 22:36:48.000000000 +0200
+++ linux-2.4.19-ltt/arch/sh/kernel/sys_sh.c	2004-12-28 22:39:46.000000000 +0100
@@ -21,6 +21,8 @@
 #include <linux/file.h>
 #include <linux/utsname.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
 
@@ -139,6 +141,8 @@
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+
 	if (call <= SEMCTL)
 		switch (call) {
 		case SEMOP:
diff -rbNu linux-2.4.19/arch/sh/kernel/traps.c linux-2.4.19-ltt/arch/sh/kernel/traps.c
--- linux-2.4.19/arch/sh/kernel/traps.c	2002-02-25 20:37:56.000000000 +0100
+++ linux-2.4.19-ltt/arch/sh/kernel/traps.c	2004-12-28 22:39:46.000000000 +0100
@@ -25,6 +25,8 @@
 #include <linux/delay.h>
 #include <linux/spinlock.h>
 
+#include <linux/trace.h>
+
 #include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/io.h>
@@ -42,7 +44,9 @@
 	sti(); \
 	tsk->thread.error_code = error_code; \
 	tsk->thread.trap_no = trapnr; \
+	TRACE_TRAP_ENTRY(trapnr, regs.pc); \
 	force_sig(signr, tsk); \
+	TRACE_TRAP_EXIT(); \
 	die_if_no_fixup(str,&regs,error_code); \
 }
 
@@ -443,6 +447,8 @@
 
 	asm volatile("stc       r2_bank,%0": "=r" (error_code));
 
+	TRACE_TRAP_ENTRY(error_code >> 5, regs->pc);
+
 	oldfs = get_fs();
 
 	if (user_mode(regs)) {
@@ -466,8 +472,10 @@
 		tmp = handle_unaligned_access(instruction, regs);
 		set_fs(oldfs);
 
-		if (tmp==0)
+		if (tmp==0) {
+			TRACE_TRAP_EXIT();
 			return; /* sorted */
+		}
 
 	uspace_segv:
 		printk(KERN_NOTICE "Killing process \"%s\" due to unaligned access\n", current->comm);
@@ -488,6 +496,7 @@
 		handle_unaligned_access(instruction, regs);
 		set_fs(oldfs);
 	}
+	TRACE_TRAP_EXIT();
 }
 
 DO_ERROR(12, SIGILL,  "reserved instruction", reserved_inst, current)
@@ -565,3 +574,78 @@
 {
 	printk("Backtrace not yet implemented for SH.\n");
 }
+
+/* Trace related code */
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+asmlinkage void trace_real_syscall_entry(struct pt_regs * regs)
+{
+	int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+	int                 seek_depth;
+	unsigned long       lower_bound;
+	unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+	/* Set the syscall ID */
+	trace_syscall_event.syscall_id = (uint8_t) regs->regs[REG_REG0+3];
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = regs->pc;
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!user_mode(regs))
+		/* Don't go digining anywhere */
+		goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(trace_get_config(&use_depth, &use_bounds, &seek_depth,
+	   (void*)&lower_bound, (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	{
+		/* Start at the top of the stack (bottom address since stacks grow downward) */
+		stack = (unsigned long*) regs->regs[REG_REG15];
+
+		/* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+		while(!get_user(addr, stack))
+		{
+			/* Does this LOOK LIKE an address in the program */
+			/* TODO: does this work with shared libraries?? - Greg Banks */
+			if((addr > current->mm->start_code) &&(addr < current->mm->end_code))
+			{
+				/* Does this address fit the description */
+				if(((use_depth == 1) && (depth == seek_depth))
+				   ||((use_bounds == 1) && (addr > lower_bound)
+				   && (addr < upper_bound)))
+				{
+					/* Set the address */
+					trace_syscall_event.address = addr;
+
+					/* We're done */
+					goto trace_syscall_end;
+				}
+				else
+					/* We're one depth more */
+					depth++;
+			}
+			/* Go on to the next address */
+			stack++;
+		}
+	}
+
+trace_syscall_end:
+	/* Trace the event */
+	trace_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
+
+asmlinkage void trace_real_syscall_exit(void)
+{
+	trace_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+#endif /* (CONFIG_TRACE || CONFIG_TRACE_MODULE) */
+
diff -rbNu linux-2.4.19/arch/sh/lib/checksum.S linux-2.4.19-ltt/arch/sh/lib/checksum.S
--- linux-2.4.19/arch/sh/lib/checksum.S	2001-09-08 21:29:09.000000000 +0200
+++ linux-2.4.19-ltt/arch/sh/lib/checksum.S	2004-12-28 22:39:46.000000000 +0100
@@ -172,7 +172,6 @@
 	.long 9999b, 6002f	;	\
 	.previous
 
-!
 ! r4:	const char *SRC
 ! r5:	char *DST
 ! r6:	int LEN
diff -rbNu linux-2.4.19/arch/sh/mm/fault.c linux-2.4.19-ltt/arch/sh/mm/fault.c
--- linux-2.4.19/arch/sh/mm/fault.c	2001-10-15 22:36:48.000000000 +0200
+++ linux-2.4.19-ltt/arch/sh/mm/fault.c	2004-12-28 22:39:46.000000000 +0100
@@ -20,6 +20,8 @@
 #include <linux/smp_lock.h>
 #include <linux/interrupt.h>
 
+#include <linux/trace.h>
+
 #include <asm/system.h>
 #include <asm/io.h>
 #include <asm/uaccess.h>
@@ -98,6 +100,14 @@
 	tsk = current;
 	mm = tsk->mm;
 
+#if (CONFIG_TRACE || CONFIG_TRACE_MODULE)
+	{
+		unsigned long trapnr;
+		asm volatile("stc       r2_bank,%0": "=r" (trapnr));
+		TRACE_TRAP_ENTRY(trapnr >> 5, regs->pc);  /* trap 4,5 or 6 */
+	}
+#endif
+
 	/*
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
@@ -149,6 +159,7 @@
 	}
 
 	up_read(&mm->mmap_sem);
+	TRACE_TRAP_EXIT();
 	return;
 
 /*
@@ -162,6 +173,7 @@
 		tsk->thread.address = address;
 		tsk->thread.error_code = writeaccess;
 		force_sig(SIGSEGV, tsk);
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
@@ -170,6 +182,7 @@
 	fixup = search_exception_table(regs->pc);
 	if (fixup != 0) {
 		regs->pc = fixup;
+		TRACE_TRAP_EXIT();
 		return;
 	}
 
@@ -232,6 +245,8 @@
 	/* Kernel mode? Handle exceptions or die */
 	if (!user_mode(regs))
 		goto no_context;
+
+	TRACE_TRAP_EXIT();
 }
 
 /*
diff -rbNu linux-2.4.19/drivers/Makefile linux-2.4.19-ltt/drivers/Makefile
--- linux-2.4.19/drivers/Makefile	2002-08-03 02:39:43.000000000 +0200
+++ linux-2.4.19-ltt/drivers/Makefile	2004-12-28 22:39:46.000000000 +0100
@@ -39,6 +39,7 @@
 subdir-$(CONFIG_ISDN_BOOL)	+= isdn
 subdir-$(CONFIG_ATM)		+= atm
 subdir-$(CONFIG_FC4)		+= fc4
+subdir-$(CONFIG_TRACE)		+= trace
 
 # CONFIG_HAMRADIO can be set without CONFIG_NETDEVICE being set  -- ch
 subdir-$(CONFIG_HAMRADIO)	+= net/hamradio
diff -rbNu linux-2.4.19/drivers/ide/ide-cd.h linux-2.4.19-ltt/drivers/ide/ide-cd.h
--- linux-2.4.19/drivers/ide/ide-cd.h	2002-08-03 02:39:44.000000000 +0200
+++ linux-2.4.19-ltt/drivers/ide/ide-cd.h	2004-12-28 23:28:08.000000000 +0100
@@ -437,7 +437,7 @@
 
 	byte     curlba[3];
 	byte     nslots;
-	__u8 short slot_tablelen;
+	__u8     slot_tablelen;
 };
 
 
diff -rbNu linux-2.4.19/drivers/input/mousedev.c linux-2.4.19-ltt/drivers/input/mousedev.c
--- linux-2.4.19/drivers/input/mousedev.c	2001-09-30 21:26:05.000000000 +0200
+++ linux-2.4.19-ltt/drivers/input/mousedev.c	2004-12-28 22:39:46.000000000 +0100
@@ -82,6 +82,10 @@
 static int xres = CONFIG_INPUT_MOUSEDEV_SCREEN_X;
 static int yres = CONFIG_INPUT_MOUSEDEV_SCREEN_Y;
 
+#ifdef CONFIG_MAC_EMUMOUSEBTN
+extern int mac_hid_mouse_emulate_buttons(int caller, unsigned int keycode, int down);
+#endif
+
 static void mousedev_event(struct input_handle *handle, unsigned int type, unsigned int code, int value)
 {
 	struct mousedev *mousedevs[3] = { handle->private, &mousedev_mix, NULL };
@@ -137,6 +141,11 @@
 						case BTN_MIDDLE: index = 2; break;	
 						default: return;
 					}
+
+#ifdef CONFIG_MAC_EMUMOUSEBTN
+				        index = mac_hid_mouse_emulate_buttons(2, index, 0);
+#endif
+
 					switch (value) {
 						case 0: clear_bit(index, &list->buttons); break;
 						case 1: set_bit(index, &list->buttons); break;
diff -rbNu linux-2.4.19/drivers/s390/s390io.c linux-2.4.19-ltt/drivers/s390/s390io.c
--- linux-2.4.19/drivers/s390/s390io.c	2002-08-03 02:39:44.000000000 +0200
+++ linux-2.4.19-ltt/drivers/s390/s390io.c	2004-12-28 22:39:46.000000000 +0100
@@ -44,6 +44,7 @@
 #include <linux/smp_lock.h>
 #include <linux/init.h>
 #include <linux/bootmem.h>
+#include <linux/trace.h>
 #ifdef CONFIG_PROC_FS
 #include <linux/proc_fs.h>
 #endif 
@@ -2385,9 +2386,11 @@
 			}
 	
 			irq_enter(cpu, irq);
+                        TRACE_IRQ_ENTRY(irq, !(((regs).psw.mask&PSW_PROBLEM_STATE) != 0));
 			s390irq_spin_lock( irq );
 			s390_process_IRQ( irq );
 			s390irq_spin_unlock( irq );
+                        TRACE_IRQ_EXIT();
 			irq_exit(cpu, irq);
 		}
 
diff -rbNu linux-2.4.19/drivers/s390/s390mach.c linux-2.4.19-ltt/drivers/s390/s390mach.c
--- linux-2.4.19/drivers/s390/s390mach.c	2001-11-09 23:05:02.000000000 +0100
+++ linux-2.4.19-ltt/drivers/s390/s390mach.c	2004-12-28 22:39:46.000000000 +0100
@@ -6,12 +6,14 @@
  *  S390 version
  *    Copyright (C) 2000 IBM Deutschland Entwicklung GmbH, IBM Corporation
  *    Author(s): Ingo Adlung (adlung@de.ibm.com)
+ *  Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  */
 
 #include <linux/config.h>
 #include <linux/spinlock.h>
 #include <linux/init.h>
 #include <linux/slab.h>
+#include <linux/trace.h>
 #ifdef CONFIG_SMP
 #include <linux/smp.h>
 #endif
@@ -133,6 +135,8 @@
 {
 	int      crw_count;
 	mcic_t   mcic;
+        trapid_t ltt_interruption_code;
+        uint32_t ltt_old_psw;
 
 #ifdef S390_MACHCHK_DEBUG
 	printk( "s390_do_machine_check : starting ...\n");
@@ -141,6 +145,14 @@
 	memcpy( &mcic,
 	        &S390_lowcore.mcck_interruption_code,
 	        sizeof(__u64));
+	memcpy( &ltt_interruption_code,
+	        &S390_lowcore.mcck_interruption_code,
+	        sizeof(__u64));
+	memcpy( &ltt_old_psw,
+	        &S390_lowcore.mcck_old_psw,
+	        sizeof(uint32_t));
+        ltt_old_psw &=  PSW_ADDR_MASK;
+        TRACE_TRAP_ENTRY(ltt_interruption_code,ltt_old_psw);
  		
 	if ( mcic.mcc.mcd.cp )	// CRW pending ?
 	{
diff -rbNu linux-2.4.19/drivers/trace/Makefile linux-2.4.19-ltt/drivers/trace/Makefile
--- linux-2.4.19/drivers/trace/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.19-ltt/drivers/trace/Makefile	2004-12-28 22:39:46.000000000 +0100
@@ -0,0 +1,17 @@
+#
+# Makefile for the kernel tracing drivers.
+#
+# Note! Dependencies are done automagically by 'make dep', which also
+# removes any old dependencies. DON'T put your own dependencies here
+# unless it's something special (ie not a .c file).
+#
+# Note 2! The CFLAGS definitions are now inherited from the
+# parent makes..
+#
+
+O_TARGET := trace_driver.o
+
+# Is it loaded as a module or as part of the kernel
+obj-$(CONFIG_TRACE) = tracer.o
+
+include $(TOPDIR)/Rules.make
diff -rbNu linux-2.4.19/drivers/trace/tracer.c linux-2.4.19-ltt/drivers/trace/tracer.c
--- linux-2.4.19/drivers/trace/tracer.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.19-ltt/drivers/trace/tracer.c	2004-12-28 23:18:34.000000000 +0100
@@ -0,0 +1,1421 @@
+/*****************************************************************
+ * File : tracer.c
+ * Description :
+ *    Contains the code for the kernel tracing driver (tracer
+ *    for short).
+ * Author :
+ *    Karim Yaghmour
+ * Date :
+ *    03/12/01, Added user event support.
+ *    05/01/01, Modified PPC bit manipulation functions for
+ *              x86 compatibility.  (andy_lowe@mvista.com)
+ *    15/11/00, Finally fixed memory allocation and remapping
+ *              method. Now using BTTV-driver-inspired code.
+ *    13/03/00, Modified tracer so that the daemon mmaps the 
+ *              tracer's buffers in it's address space rather
+ *              than use "read".
+ *    26/01/00, Added support for standardized buffer sizes and
+ *              extensibility of events.
+ *    01/10/99, Modified tracer in order to used double-buffering.
+ *    28/09/99, Adding tracer configuration support.
+ *    09/09/99, Chaging the format of an event record in order to
+ *              reduce the size of the traces.
+ *    04/03/99, Initial typing.
+ * Note :
+ *    The sizes of the variables used to store the details of an
+ *    event are planned for a system who gets at least one clock
+ *    tick every 10milli-seconds. There has to be at least one
+ *    event every 2^32-1 microseconds, otherwise the size of the
+ *    variable holding the time doesn't work anymore.
+ *****************************************************************/
+
+/* Module and initialization stuff */
+#include <linux/module.h>
+#include <linux/init.h>
+
+/* Necessary includes */
+#include <linux/fs.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/time.h>
+#include <linux/trace.h>
+#include <linux/wrapper.h>
+#include <linux/vmalloc.h>
+
+#include <asm/io.h>
+#include <asm/current.h>
+#include <asm/uaccess.h>
+#include <asm/bitops.h>
+#include <asm/pgtable.h>
+
+/* Local defintions */
+#include "tracer.h"
+
+/* Module information */
+MODULE_AUTHOR     ("Karim Yaghmour (karym@opersys.com)");
+MODULE_DESCRIPTION("Linux Trace Toolkit (LTT) kernel tracing driver");
+MODULE_LICENSE    ("GPL");
+
+/* Local variables */
+/*  Driver */
+static int                    sMajorNumber;          /* Major number of the tracer */
+static int                    sOpenCount;            /* Number of times device is open */
+/*  Locking */
+static int                    sTracLock;             /* Tracer lock used to lock primary buffer */
+static spinlock_t             sSpinLock;             /* Spinlock in order to lock kernel */
+/*  Daemon */
+static int                    sSignalSent;           /* A signal has been sent to the daemon */
+static struct task_struct*    sDaemonTaskStruct;     /* Task structure of the tracer daemon */
+/*  Tracer configuration */
+static int                    sTracerStarted;        /* Is the tracer started */
+static trace_event_mask       sTracedEvents;         /* Bit-field of events being traced */
+static trace_event_mask       sLogEventDetailsMask;  /* Log the details of the events mask */
+static int                    sLogCPUID;             /* Log the CPUID associated with each event */
+static int                    sUseSyscallEIPBounds;  /* Use adress bounds to fetch the EIP where call is made */
+static int                    sLowerEIPBoundSet;     /* The lower bound EIP has been set */
+static int                    sUpperEIPBoundSet;     /* The upper bound EIP has been set */
+static void*                  sLowerEIPBound;        /* The lower bound EIP */
+static void*                  sUpperEIPBound;        /* The upper bound EIP */
+static int                    sTracingPID;           /* Tracing only the events for one pid */
+static int                    sTracingPGRP;          /* Tracing only the events for one process group */
+static int                    sTracingGID;           /* Tracing only the events for one gid */
+static int                    sTracingUID;           /* Tracing only the events for one uid */
+static pid_t                  sTracedPID;            /* PID being traced */
+static pid_t                  sTracedPGRP;           /* Process group being traced */
+static gid_t                  sTracedGID;            /* GID being traced */
+static uid_t                  sTracedUID;            /* UID being traced */
+static int                    sSyscallEIPDepthSet;   /* The call depth at which to fetch EIP has been set */
+static int                    sSyscallEIPDepth;      /* The call depth at which to fetch the EIP */
+/*  Event data buffers */
+static int                    sBufReadComplete;      /* Number of buffers completely filled */
+static int                    sSizeReadIncomplete;   /* Quantity of data read from incomplete buffers */
+static int                    sEventsLost;           /* Number of events lost because of lack of buffer space */
+static uint32_t               sBufSize;              /* Buffer sizes */
+static uint32_t               sAllocSize;            /* Size of buffers allocated */
+static uint32_t               sBufferID;             /* Unique buffer ID */
+static char*                  sTracBuf = NULL;       /* Trace buffer */
+static char*                  sWritBuf = NULL;       /* Buffer used for writting */
+static char*                  sReadBuf = NULL;       /* Buffer used for reading */
+static char*                  sWritBufEnd;           /* End of write buffer */
+static char*                  sReadBufEnd;           /* End of read buffer */
+static char*                  sWritPos;              /* Current position for writting */
+static char*                  sReadLimit;            /* Limit at which read should stop */
+static char*                  sWritLimit;            /* Limit at which write should stop */
+/*  Time */
+static struct timeval         sBufferStartTime;      /* The time at which the buffer was started */
+/*  Large data components allocated at load time */
+static char*                  sUserEventData = NULL; /* The data associated with a user event */
+
+
+/* The size of the structures used to describe the events */
+static int sEventStructSize[TRACE_EV_MAX + 1] =
+{
+  sizeof(trace_start)             /* TRACE_START */,
+  sizeof(trace_syscall_entry)     /* TRACE_SYSCALL_ENTRY */,
+  0                               /* TRACE_SYSCALL_EXIT */,
+  sizeof(trace_trap_entry)        /* TRACE_TRAP_ENTRY */,
+  0                               /* TRACE_TRAP_EXIT */,
+  sizeof(trace_irq_entry)         /* TRACE_IRQ_ENTRY */,
+  0                               /* TRACE_IRQ_EXIT */,
+  sizeof(trace_schedchange)       /* TRACE_SCHEDCHANGE */,
+  0                               /* TRACE_KERNEL_TIMER */,
+  sizeof(trace_soft_irq)          /* TRACE_SOFT_IRQ */,
+  sizeof(trace_process)           /* TRACE_PROCESS */,
+  sizeof(trace_file_system)       /* TRACE_FILE_SYSTEM */,
+  sizeof(trace_timer)             /* TRACE_TIMER */,
+  sizeof(trace_memory)            /* TRACE_MEMORY */,
+  sizeof(trace_socket)            /* TRACE_SOCKET */,
+  sizeof(trace_ipc)               /* TRACE_IPC */,
+  sizeof(trace_network)           /* TRACE_NETWORK */,
+  sizeof(trace_buffer_start)      /* TRACE_BUFFER_START */,
+  0                               /* TRACE_BUFFER_END */,
+  sizeof(trace_new_event)         /* TRACE_NEW_EVENT */,
+  sizeof(trace_custom)            /* TRACE_CUSTOM */,
+  sizeof(trace_change_mask)       /* TRACE_CHANGE_MASK */
+};
+
+/* The file operations available for the tracer */
+static struct file_operations sTracerFileOps =
+{
+  owner:            THIS_MODULE,
+  ioctl:            tracer_ioctl,
+  mmap:             tracer_mmap,
+  open:             tracer_open,
+  release:          tracer_release,
+  fsync:            tracer_fsync,
+};
+
+/************************************************************************************************************/
+/************************************** Code inspired from BTTV driver **************************************/
+/************************************************************************************************************/
+#define FIX_SIZE(x) (((x) - 1) & PAGE_MASK) + PAGE_SIZE /* This inspired by rtai/shmem */
+
+/* Given PGD from the address space's page table, return the kernel
+ * virtual mapping of the physical memory mapped at ADR.
+ */
+static inline unsigned long uvirt_to_kva(pgd_t *pgd, unsigned long adr)
+{
+        unsigned long ret = 0UL;
+	pmd_t *pmd;
+	pte_t *ptep, pte;
+  
+	if (!pgd_none(*pgd)) {
+                pmd = pmd_offset(pgd, adr);
+                if (!pmd_none(*pmd)) {
+                        ptep = pte_offset(pmd, adr);
+                        pte = *ptep;
+                        if(pte_present(pte)) {
+				ret = (unsigned long) page_address(pte_page(pte));
+                                ret |= (adr & (PAGE_SIZE - 1));
+			}
+                }
+        }
+	return ret;
+}
+
+/* Here we want the physical address of the memory.
+ * This is used when initializing the contents of the
+ * area and marking the pages as reserved.
+ */
+static inline unsigned long kvirt_to_pa(unsigned long adr) 
+{
+        unsigned long va, kva, ret;
+
+        va = VMALLOC_VMADDR(adr);
+        kva = uvirt_to_kva(pgd_offset_k(va), va);
+	ret = __pa(kva);
+        return ret;
+}
+
+static void * rvmalloc(signed long size)
+{
+	void * mem;
+	unsigned long adr, page;
+
+	mem=vmalloc_32(size);
+	if (mem) 
+	{
+		memset(mem, 0, size); /* Clear the ram out, no junk to the user */
+	        adr=(unsigned long) mem;
+		while (size > 0) 
+                {
+	                page = kvirt_to_pa(adr);
+			mem_map_reserve(virt_to_page(__va(page)));
+			adr+=PAGE_SIZE;
+			size-=PAGE_SIZE;
+		}
+	}
+	return mem;
+}
+
+static void rvfree(void * mem, signed long size)
+{
+        unsigned long adr, page;
+        
+	if (mem) 
+	{
+	        adr=(unsigned long) mem;
+		while (size > 0) 
+                {
+	                page = kvirt_to_pa(adr);
+			mem_map_unreserve(virt_to_page(__va(page)));
+			adr+=PAGE_SIZE;
+			size-=PAGE_SIZE;
+		}
+		vfree(mem);
+	}
+}
+
+static int tracer_mmap_region(const char *adr, const char *start_pos, unsigned long size)
+{
+        unsigned long start=(unsigned long) adr;
+	unsigned long page,pos;
+
+	pos=(unsigned long) start_pos;
+	while (size > 0) 
+	{
+	        page = kvirt_to_pa(pos);
+		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED))
+		        return -EAGAIN;
+		start+=PAGE_SIZE;
+		pos+=PAGE_SIZE;
+		size-=PAGE_SIZE;    
+	}
+	return 0;
+}
+/************************************************************************************************************/
+/************************************************************************************************************/
+/************************************************************************************************************/
+
+/**************************************************************
+ * Macro : tracer_write_to_buffer()
+ * Description :
+ *     Writes data to the destination buffer and updates the
+ *     begining the buffer write position.
+ **************************************************************/
+#define tracer_write_to_buffer(DEST, SRC, SIZE) \
+do\
+{\
+   memcpy(DEST, SRC, SIZE);\
+   DEST += SIZE;\
+} while(0);
+
+/**************************************************************
+ * Function : trace()
+ * Description : Tracing function per se.
+ * Parameters :
+ *     pmEventID, ID of event as defined in linux/trace.h
+ *     pmEventStruct, struct describing the event
+ * Return values : 
+ *     0, if everything went OK (event got registered)
+ *     -ENODEV, no tracing daemon opened the driver.
+ *     -ENOMEM, no more memory to store events.
+ *     -EBUSY, tracer not started yet.
+ * Note :
+ *     The kernel has to be locked here because trace() could
+ *     be called from an interrupt handling routine and from 
+ *     a process service routine.
+ **************************************************************/
+int trace(uint8_t   pmEventID,
+	  void*     pmEventStruct)
+{
+  int                 lVarDataLen = 0;          /* Length of variable length data to be copied, if any */
+  void*               lVarDataBeg = NULL;       /* Begining of variable length data to be copied */
+  int                 lSendSignal = FALSE;      /* Should the daemon be summoned */
+  uint8_t             lCPUID;                   /* CPUID of currently runing process */
+  uint16_t            lDataSize;                /* Size of tracing data */
+  struct siginfo      lSigInfo;                 /* Signal information */
+  struct timeval      lTime;                    /* Event time */
+  unsigned long int   lFlags;                   /* CPU flags for lock */
+  trace_time_delta    lTimeDelta;               /* The time elapsed between now and the last event */
+  struct task_struct* pIncomingProcess = NULL;  /* Pointer to incoming process */
+
+  /* Is there a tracing daemon */
+  if(sDaemonTaskStruct == NULL)
+    return -ENODEV;
+
+  /* Is this the exit of a process? */
+  if((pmEventID == TRACE_EV_PROCESS) &&
+     (pmEventStruct != NULL) &&
+     ((((trace_process*) pmEventStruct)->event_sub_id) == TRACE_EV_PROCESS_EXIT))
+    trace_destroy_owners_events(current->pid);
+
+  /* Do we trace the event */
+  if((sTracerStarted == TRUE) || (pmEventID == TRACE_EV_START) || (pmEventID == TRACE_EV_BUFFER_START))
+    goto TraceEvent;
+
+  /* We can't continue */
+  return -EBUSY;
+
+TraceEvent:
+
+  /* Are we monitoring this event */
+  if(!ltt_test_bit(pmEventID, &sTracedEvents))
+    return 0;
+
+  /* Always let the start event pass, whatever the IDs */
+  if((pmEventID != TRACE_EV_START) && (pmEventID != TRACE_EV_BUFFER_START))
+    {
+    /* Is this a scheduling change */
+    if(pmEventID == TRACE_EV_SCHEDCHANGE)
+      {
+      /* Get pointer to incoming process */
+      pIncomingProcess = (struct task_struct*) (((trace_schedchange*) pmEventStruct)->in);
+
+      /* Set PID information in schedchange event */
+      (((trace_schedchange*) pmEventStruct)->in) = pIncomingProcess->pid;
+      }
+
+    /* Are we monitoring a particular process */
+    if((sTracingPID == TRUE) && (current->pid != sTracedPID))
+      {
+      /* Record this event if it is the scheduling change bringing in the traced PID */
+      if(pIncomingProcess == NULL)
+	return 0;
+      else if (pIncomingProcess->pid != sTracedPID)
+	return 0;
+      }
+
+    /* Are we monitoring a particular process group */
+    if((sTracingPGRP == TRUE) && (current->pgrp != sTracedPGRP))
+      {
+      /* Record this event if it is the scheduling change bringing in a process of the traced PGRP */
+      if(pIncomingProcess == NULL)
+	return 0;
+      else if (pIncomingProcess->pgrp != sTracedPGRP)
+	return 0;
+      }
+
+    /* Are we monitoring the processes of a given group of users */
+    if((sTracingGID == TRUE) && (current->egid != sTracedGID))
+      {
+      /* Record this event if it is the scheduling change bringing in a process of the traced GID */
+      if(pIncomingProcess == NULL)
+	return 0;
+      else if (pIncomingProcess->egid != sTracedGID)
+	return 0;
+      }
+
+    /* Are we monitoring the processes of a given user */
+    if((sTracingUID == TRUE) && (current->euid != sTracedUID))
+      {
+      /* Record this event if it is the scheduling change bringing in a process of the traced UID */
+      if(pIncomingProcess == NULL)
+	return 0;
+      else if (pIncomingProcess->euid != sTracedUID)
+	return 0;
+      }
+    }
+
+  /* Compute size of tracing data */
+  lDataSize = sizeof(pmEventID) + sizeof(lTimeDelta) + sizeof(lDataSize);
+
+  /* Do we log the event details */
+  if(ltt_test_bit(pmEventID, &sLogEventDetailsMask))
+    {
+    /* Update the size of the data entry */
+    lDataSize += sEventStructSize[pmEventID];
+
+    /* Some events have variable length */
+    switch(pmEventID)
+      {
+      /* Is there a file name in this */
+      case TRACE_EV_FILE_SYSTEM:
+	if((((trace_file_system*) pmEventStruct)->event_sub_id == TRACE_EV_FILE_SYSTEM_EXEC)
+	|| (((trace_file_system*) pmEventStruct)->event_sub_id == TRACE_EV_FILE_SYSTEM_OPEN))
+	  {
+	  /* Remember the string's begining and update size variables */
+	  lVarDataBeg = ((trace_file_system*) pmEventStruct)->file_name;
+	  lVarDataLen = ((trace_file_system*) pmEventStruct)->event_data2 + 1;
+	  lDataSize += (uint16_t) lVarDataLen;
+	  }
+	break;
+
+      /* Logging of a custom event */
+      case TRACE_EV_CUSTOM:
+	lVarDataBeg = ((trace_custom*) pmEventStruct)->data;
+	lVarDataLen = ((trace_custom*) pmEventStruct)->data_size;
+	lDataSize += (uint16_t) lVarDataLen;
+	break;
+      }
+    }
+
+  /* Do we record the CPUID */
+  if((sLogCPUID == TRUE) && (pmEventID != TRACE_EV_START) && (pmEventID != TRACE_EV_BUFFER_START))
+    {
+    /* Remember the CPUID */
+    lCPUID = smp_processor_id();
+
+    /* Update the size of the data entry */
+    lDataSize += sizeof(lCPUID);
+    }
+
+  /* Lock the kernel */
+  spin_lock_irqsave(&sSpinLock, lFlags);
+
+  /* The following time calculations have to be done within the spinlock because
+     otherwise the event order could be inverted. */
+
+  /* Get the time of the event */
+  do_gettimeofday(&lTime);
+
+  /* Compute the time delta between this event and the time at which this buffer was started */
+  lTimeDelta = (lTime.tv_sec - sBufferStartTime.tv_sec) * 1000000
+             + (lTime.tv_usec - sBufferStartTime.tv_usec);
+
+  /* Is there enough space left in the write buffer */
+  if(sWritPos + lDataSize > sWritLimit)
+    {
+    /* Have we already switched buffers and informed the daemon of it */
+    if(sSignalSent == TRUE)
+      {
+      /* We've lost another event */
+      sEventsLost++;
+
+      /* Bye, bye, now */
+      spin_unlock_irqrestore(&sSpinLock, lFlags);
+      return -ENOMEM;
+      }
+
+    /* We need to inform the daemon */
+    lSendSignal = TRUE;
+
+    /* Switch buffers */
+    tracer_switch_buffers(lTime);
+
+    /* Recompute the time delta since sBufferStartTime has changed because of the buffer change */
+    lTimeDelta = (lTime.tv_sec - sBufferStartTime.tv_sec) * 1000000
+               + (lTime.tv_usec - sBufferStartTime.tv_usec);
+    }
+
+  /* Write the CPUID to the tracing buffer, if required */
+  if((sLogCPUID == TRUE)  && (pmEventID != TRACE_EV_START) && (pmEventID != TRACE_EV_BUFFER_START))
+    tracer_write_to_buffer(sWritPos,
+			   &lCPUID,
+			   sizeof(lCPUID));
+
+  /* Write event type to tracing buffer */
+  tracer_write_to_buffer(sWritPos,
+			 &pmEventID,
+			 sizeof(pmEventID));
+
+  /* Write event time delta to tracing buffer */
+  tracer_write_to_buffer(sWritPos,
+			 &lTimeDelta,
+			 sizeof(lTimeDelta));
+
+  /* Do we log event details */
+  if(ltt_test_bit(pmEventID, &sLogEventDetailsMask))
+    {
+    /* Write event structure */
+    tracer_write_to_buffer(sWritPos,
+			   pmEventStruct,
+			   sEventStructSize[pmEventID]);
+
+    /* Write string if any */
+    if(lVarDataLen)
+      tracer_write_to_buffer(sWritPos,
+			     lVarDataBeg,
+			     lVarDataLen);
+    }
+
+  /* Write the length of the event description */
+  tracer_write_to_buffer(sWritPos,
+			 &lDataSize,
+			 sizeof(lDataSize));
+
+  /* Should the tracing daemon be notified  */
+  if(lSendSignal == TRUE)
+    {
+    /* Remember that a signal has been sent */
+    sSignalSent = TRUE;
+
+    /* Unlock the kernel */
+    spin_unlock_irqrestore(&sSpinLock, lFlags);
+
+    /* Setup signal information */
+    lSigInfo.si_signo = SIGIO;
+    lSigInfo.si_errno = 0;
+    lSigInfo.si_code  = SI_KERNEL;
+
+    /* DEBUG */
+#if 0
+    printk("<1> Sending SIGIO to %d \n", sDaemonTaskStruct->pid);
+#endif
+
+    /* Signal the tracing daemon */
+    send_sig_info(SIGIO, &lSigInfo, sDaemonTaskStruct);
+    }
+  else
+    /* Unlock the kernel */
+    spin_unlock_irqrestore(&sSpinLock, lFlags);
+  
+  /* Indicate to the caller that everything is OK */
+  return 0;
+}
+
+/*************************************************************
+ * Function : tracer_switch_buffers()
+ * Description :
+ *     Put the current write buffer to be read and reset put
+ *     the old read buffer to be written to. Set the tracer
+ *     variables in consequence.
+ * Parameters :
+ *     pmTime, current time
+ * Return values :
+ *     NONE
+ * Note :
+ *     This should be called from within a spin_lock.
+ *************************************************************/
+void tracer_switch_buffers(struct timeval pmTime)
+{
+  char*               lTempBuf;              /* Temporary buffer pointer */
+  char*               lTempBufEnd;           /* Temporary buffer end pointer */
+  char*               lInitWritPos;          /* Initial write position */
+  uint8_t             lEventID;              /* Event ID of last event */
+  uint8_t             lCPUID;                /* CPUID of currently runing process */
+  uint16_t            lDataSize;             /* Size of tracing data */
+  uint32_t            lSizeLost;             /* Size delta between last event and end of buffer */
+  trace_time_delta    lTimeDelta;            /* The time elapsed between now and the last event */
+  trace_buffer_start  lStartBufferEvent;     /* Start of the new buffer event */
+
+  /* Remember initial write position */
+  lInitWritPos = sWritPos;
+
+  /* Write the end event at the write of the buffer */
+
+  /* Write the CPUID to the tracing buffer, if required */
+  if(sLogCPUID == TRUE)
+    {
+    lCPUID = smp_processor_id();
+    tracer_write_to_buffer(sWritPos,
+			   &lCPUID,
+			   sizeof(lCPUID));
+    }
+
+  /* Write event type to tracing buffer */
+  lEventID = TRACE_EV_BUFFER_END;
+  tracer_write_to_buffer(sWritPos,
+			 &lEventID,
+			 sizeof(lEventID));
+
+  /* Write event time delta to tracing buffer */
+  lTimeDelta = 0;
+  tracer_write_to_buffer(sWritPos,
+			 &lTimeDelta,
+			 sizeof(lTimeDelta));
+
+  /* Get size lost */
+  lSizeLost = sWritBufEnd - lInitWritPos;
+
+  /* Write size lost at the end of the buffer */
+  *((uint32_t*) (sWritBufEnd - sizeof(lSizeLost))) = lSizeLost;
+
+  /* Switch buffers */
+  lTempBuf = sReadBuf;
+  sReadBuf = sWritBuf;
+  sWritBuf = lTempBuf;
+
+  /* Set buffer ends */
+  lTempBufEnd = sReadBufEnd;
+  sReadBufEnd = sWritBufEnd;
+  sWritBufEnd = lTempBufEnd;
+
+  /* Set read limit */
+  sReadLimit = sReadBufEnd;
+
+  /* Set write limit */
+  sWritLimit = sWritBufEnd - TRACER_LAST_EVENT_SIZE;
+
+  /* Set write position */
+  sWritPos = sWritBuf;
+
+  /* Increment buffer ID */
+  sBufferID++;
+
+  /* Set the time of begining of this buffer */
+  sBufferStartTime = pmTime;
+
+  /* Write the start of buffer event */
+  lStartBufferEvent.ID   = sBufferID;
+  lStartBufferEvent.Time = pmTime;
+
+  /* Write event type to tracing buffer */
+  lEventID = TRACE_EV_BUFFER_START;
+  tracer_write_to_buffer(sWritPos,
+			 &lEventID,
+			 sizeof(lEventID));
+
+  /* Write event time delta to tracing buffer */
+  lTimeDelta = 0;
+  tracer_write_to_buffer(sWritPos,
+			 &lTimeDelta,
+			 sizeof(lTimeDelta));
+
+  /* Write event structure */
+  tracer_write_to_buffer(sWritPos,
+			 &lStartBufferEvent,
+			 sizeof(lStartBufferEvent));
+
+  /* Compute the data size */
+  lDataSize = sizeof(lEventID)
+            + sizeof(lTimeDelta)
+            + sizeof(lStartBufferEvent)
+            + sizeof(lDataSize);
+
+  /* Write the length of the event description */
+  tracer_write_to_buffer(sWritPos,
+			 &lDataSize,
+			 sizeof(lDataSize));
+}
+
+/*************************************************************
+ * Function : tracer_ioctl()
+ * Description : "Ioctl" file op
+ * Parameters :
+ *     pmInode, the inode associated with the device
+ *     pmFile, file structure given to the acting process
+ *     pmCmd, command given by the caller
+ *     pmArg, arguments to the command
+ * Return values :
+ *     >0, In case the caller requested the number of events
+ *         lost.
+ *     0, Everything went OK
+ *     -ENOSYS, no such command
+ *     -EINVAL, tracer not properly configured
+ *     -EBUSY, tracer can't be reconfigured while in operation
+ *     -ENOMEM, no more memory
+ *     -EFAULT, unable to access user space memory
+ * Note :
+ *     In the future, this function should check to make sure
+ *     that it's the server that make thes ioctl.
+ *************************************************************/
+int tracer_ioctl(struct inode* pmInode,
+		 struct file*  pmFile,
+		 unsigned int  pmCmd,
+		 unsigned long pmArg)
+{
+  int                    lRetValue;             /* Function return value */
+  int                    lDevMinor;             /* Device minor number */
+  int                    lNewUserEventID;       /* ID of newly created user event */
+  trace_start            lStartEvent;           /* Event marking the begining of the trace */
+  unsigned long int      lFlags;                /* CPU flags for lock */
+  trace_custom           lUserEvent;            /* The user event to be logged */
+  trace_change_mask      lTraceMask;            /* Event mask */
+  trace_new_event        lNewUserEvent;         /* The event to be created for the user */
+  trace_buffer_start     lStartBufferEvent;     /* Start of the new buffer event */
+
+#if 0
+  printk("Tracer: Command %d \n", pmCmd);
+#endif
+
+  /* Get device's minor number */
+  lDevMinor = MINOR(pmInode->i_rdev) & 0xf;
+
+  /* If the tracer is started, the daemon can't modify the configuration */
+  if((lDevMinor == 0)
+   && (sTracerStarted == TRUE) && (pmCmd != TRACER_STOP) && (pmCmd != TRACER_DATA_COMITTED))
+    return -EBUSY;
+
+  /* Only some operation are permitted to user processes trying to log events */
+  if((lDevMinor == 1)
+     && (pmCmd != TRACER_CREATE_USER_EVENT)
+     && (pmCmd != TRACER_DESTROY_USER_EVENT)
+     && (pmCmd != TRACER_TRACE_USER_EVENT)
+     && (pmCmd != TRACER_SET_EVENT_MASK)
+     && (pmCmd != TRACER_GET_EVENT_MASK))
+    return -ENOSYS;
+
+  /* Depending on the command executed */
+  switch(pmCmd)
+    {
+    /* Start the tracer */
+    case TRACER_START :
+      /* Check if the device has been properly set up */
+      if(((sUseSyscallEIPBounds == TRUE)
+        &&(sSyscallEIPDepthSet  == TRUE))
+       ||((sUseSyscallEIPBounds == TRUE)
+        &&((sLowerEIPBoundSet != TRUE)
+         ||(sUpperEIPBoundSet != TRUE)))
+       ||((sTracingPID  == TRUE)
+        &&(sTracingPGRP == TRUE)))
+	return -EINVAL;
+
+      /* Set the kernel-side trace configuration */
+      if(trace_set_config(trace,
+			  sSyscallEIPDepthSet,
+			  sUseSyscallEIPBounds,
+			  sSyscallEIPDepth,
+			  sLowerEIPBound,
+			  sUpperEIPBound) < 0)
+	return -EINVAL;
+
+      /* Always log the start event and the buffer start event */
+      ltt_set_bit(TRACE_EV_BUFFER_START, &sTracedEvents);
+      ltt_set_bit(TRACE_EV_BUFFER_START, &sLogEventDetailsMask);
+      ltt_set_bit(TRACE_EV_START, &sTracedEvents);
+      ltt_set_bit(TRACE_EV_START, &sLogEventDetailsMask);
+      ltt_set_bit(TRACE_EV_CHANGE_MASK, &sTracedEvents);
+      ltt_set_bit(TRACE_EV_CHANGE_MASK, &sLogEventDetailsMask);
+
+      /* Get the time of start */
+      do_gettimeofday(&sBufferStartTime);
+
+      /* Set the event description */
+      lStartBufferEvent.ID   = sBufferID;
+      lStartBufferEvent.Time = sBufferStartTime;
+
+      /* Set the event description */
+      lStartEvent.MagicNumber   = TRACER_MAGIC_NUMBER;
+#ifdef __i386__
+      lStartEvent.ArchType      = TRACE_ARCH_TYPE_I386;
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_NONE;
+#endif
+#ifdef __powerpc__
+      lStartEvent.ArchType      = TRACE_ARCH_TYPE_PPC;
+#if defined(CONFIG_4xx)
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_PPC_4xx;
+#elif defined(CONFIG_6xx)
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_PPC_6xx;
+#elif defined(CONFIG_8xx)
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_PPC_8xx;
+#elif defined(CONFIG_PPC_ISERIES)
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_PPC_ISERIES;
+#endif
+#endif
+#ifdef __sh__
+      lStartEvent.ArchType      = TRACE_ARCH_TYPE_SH;
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_NONE;
+#endif
+#ifdef __s390__
+      lStartEvent.ArchType      = TRACE_ARCH_TYPE_S390;      
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_NONE;
+#endif
+#ifdef __mips__
+      lStartEvent.ArchType      = TRACE_ARCH_TYPE_MIPS;      
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_NONE;
+#endif
+#if defined(CONFIG_ARM)
+      lStartEvent.ArchType      = TRACE_ARCH_TYPE_ARM;
+      lStartEvent.ArchVariant   = TRACE_ARCH_VARIANT_NONE;
+#endif
+      lStartEvent.SystemType    = TRACE_SYS_TYPE_VANILLA_LINUX;
+      lStartEvent.MajorVersion  = TRACER_VERSION_MAJOR;
+      lStartEvent.MinorVersion  = TRACER_VERSION_MINOR;
+      lStartEvent.BufferSize    = sBufSize;
+      lStartEvent.EventMask     = sTracedEvents;
+      lStartEvent.DetailsMask   = sLogEventDetailsMask;
+      lStartEvent.LogCPUID      = sLogCPUID;
+
+      /* Trace the buffer start event */
+      trace(TRACE_EV_BUFFER_START, &lStartBufferEvent);
+
+      /* Trace the start event */
+      trace(TRACE_EV_START, &lStartEvent);
+
+      /* Start tapping into Linux's syscall flow */
+      syscall_entry_trace_active = ltt_test_bit(TRACE_EV_SYSCALL_ENTRY, &sTracedEvents);
+      syscall_exit_trace_active  = ltt_test_bit(TRACE_EV_SYSCALL_EXIT, &sTracedEvents);
+
+      /* We can start tracing */
+      sTracerStarted = TRUE;
+
+      /* Reregister custom trace events created earlier */
+      trace_reregister_custom_events();
+      break;
+
+    /* Stop the tracer */
+    case TRACER_STOP :
+      /* Stop tracing */
+      sTracerStarted = FALSE;
+
+      /* Stop interrupting the normal flow of system calls */
+      syscall_entry_trace_active = 0;
+      syscall_exit_trace_active  = 0;
+
+      /* Acquire the lock to avoid SMP case of where another CPU is writing a trace
+         while buffer is being switched */
+      spin_lock_irqsave(&sSpinLock, lFlags);
+
+      /* Switch the buffers to ensure that the end of the buffer mark is set (time isn't important) */
+      tracer_switch_buffers(sBufferStartTime);
+
+      /* Release lock */
+      spin_unlock_irqrestore(&sSpinLock, lFlags);
+      break;
+
+    /* Set the tracer to the default configuration */
+    case TRACER_CONFIG_DEFAULT :
+      tracer_set_default_config();
+      break;
+
+    /* Set the memory buffers the daemon wants us to use */
+    case TRACER_CONFIG_MEMORY_BUFFERS :
+      /* Is the given size "reasonnable" */
+      if(pmArg < TRACER_MIN_BUF_SIZE)
+	return -EINVAL;
+
+      /* Set the buffer's size */
+      return tracer_set_buffer_size(pmArg);
+      break;
+
+    /* Trace the given events */
+    case TRACER_CONFIG_EVENTS :
+      if(copy_from_user(&sTracedEvents, (void*) pmArg, sizeof(sTracedEvents)))
+	return -EFAULT;
+      break;
+
+    /* Record the details of the event, or not */
+    case TRACER_CONFIG_DETAILS :
+      if(copy_from_user(&sLogEventDetailsMask, (void*) pmArg, sizeof(sLogEventDetailsMask)))
+	return -EFAULT;
+      break;
+      
+    /* Record the CPUID associated with the event */
+    case TRACER_CONFIG_CPUID :
+      sLogCPUID = TRUE;
+      break;
+
+    /* Trace only one process */
+    case TRACER_CONFIG_PID :
+      sTracingPID = TRUE;
+      sTracedPID  = pmArg;
+      break;
+
+    /* Trace only the given process group */
+    case TRACER_CONFIG_PGRP :
+      sTracingPGRP = TRUE;
+      sTracedPGRP  = pmArg;
+      break;
+
+    /* Trace the processes of a given group of users */
+    case TRACER_CONFIG_GID :
+      sTracingGID = TRUE;
+      sTracedGID  = pmArg;
+      break;
+
+    /* Trace the processes of a given user */
+    case TRACER_CONFIG_UID :
+      sTracingUID = TRUE;
+      sTracedUID  = pmArg;
+      break;
+
+    /* Set the call depth a which the EIP should be fetched on syscall */
+    case TRACER_CONFIG_SYSCALL_EIP_DEPTH :
+      sSyscallEIPDepthSet = TRUE;
+      sSyscallEIPDepth    = pmArg;
+      break;
+
+    /* Set the lowerbound address from which EIP is recorded on syscall */
+    case TRACER_CONFIG_SYSCALL_EIP_LOWER :
+      /* We are using bounds for fetching the EIP where syscall was made */
+      sUseSyscallEIPBounds = TRUE;
+
+      /* Set the lower bound */
+      sLowerEIPBound = (void*) pmArg;
+
+      /* The lower bound has been set */
+      sLowerEIPBoundSet = TRUE;
+      break;
+
+    /* Set the upperbound address from which EIP is recorded on syscall */
+    case TRACER_CONFIG_SYSCALL_EIP_UPPER :
+      /* We are using bounds for fetching the EIP where syscall was made */
+      sUseSyscallEIPBounds = TRUE;
+
+      /* Set the lower bound */
+      sUpperEIPBound = (void*) pmArg;
+
+      /* The lower bound has been set */
+      sUpperEIPBoundSet = TRUE;
+      break;
+
+    /* The daemon has comitted the last trace */
+    case TRACER_DATA_COMITTED :
+#if 0
+      printk("Tracer: Data has been comitted \n");
+#endif
+
+      /* Safely set the signal sent flag to FALSE */
+      spin_lock_irqsave(&sSpinLock, lFlags);
+      sSignalSent = FALSE;
+      spin_unlock_irqrestore(&sSpinLock, lFlags);
+      break;
+
+    /* Get the number of events lost */
+    case TRACER_GET_EVENTS_LOST :
+      return sEventsLost;
+      break;
+
+    /* Create a user event */
+    case TRACER_CREATE_USER_EVENT :
+      /* Copy the information from user space */
+      if(copy_from_user(&lNewUserEvent, (void*) pmArg, sizeof(lNewUserEvent)))
+	return -EFAULT;
+
+      /* Create the event */
+      lNewUserEventID = trace_create_owned_event(lNewUserEvent.type,
+						 lNewUserEvent.desc,
+						 lNewUserEvent.format_type,
+						 lNewUserEvent.form,
+						 current->pid);
+
+      /* Has the operation succeded */
+      if(lNewUserEventID >= 0)
+	{
+	/* Set the event ID */
+	lNewUserEvent.id = lNewUserEventID;
+
+	/* Copy the event information back to user space */
+	if(copy_to_user((void*) pmArg, &lNewUserEvent, sizeof(lNewUserEvent)))
+	  {
+	  /* Since we were unable to tell the user about the event, destroy it */
+	  trace_destroy_event(lNewUserEventID);
+	  return -EFAULT;
+	  }
+	}
+      else
+	/* Forward trace_create_event()'s error code */
+	return lNewUserEventID;
+      break;
+
+    /* Destroy a user event */
+    case TRACER_DESTROY_USER_EVENT :
+      /* Pass on the user's request */
+      trace_destroy_event((int) pmArg);
+      break;
+
+    /* Trace a user event */
+    case TRACER_TRACE_USER_EVENT :
+      /* Copy the information from user space */
+      if(copy_from_user(&lUserEvent, (void*) pmArg, sizeof(lUserEvent)))
+	return -EFAULT;
+
+      /* Copy the user event data */
+      if(copy_from_user(sUserEventData, lUserEvent.data, lUserEvent.data_size))
+	return -EFAULT;
+
+      /* Log the raw event */
+      lRetValue = trace_raw_event(lUserEvent.id,
+				  lUserEvent.data_size,
+				  sUserEventData);
+
+      /* Has the operation failed */
+      if(lRetValue < 0)
+	/* Forward trace_create_event()'s error code */
+	return lRetValue;
+      break;
+
+    /* Set event mask */
+    case TRACER_SET_EVENT_MASK :
+      /* Copy the information from user space */
+      if(copy_from_user(&(lTraceMask.mask), (void*) pmArg, sizeof(lTraceMask.mask)))
+	return -EFAULT;
+
+      /* Trace the event */
+      lRetValue = trace(TRACE_EV_CHANGE_MASK, &lTraceMask);
+
+      /* Change the event mask. (This has to be done second or else may loose the
+       information if the user decides to stop logging "change mask" events) */
+      memcpy(&sTracedEvents, &(lTraceMask.mask), sizeof(lTraceMask.mask));
+      syscall_entry_trace_active = ltt_test_bit(TRACE_EV_SYSCALL_ENTRY, &sTracedEvents);
+      syscall_exit_trace_active  = ltt_test_bit(TRACE_EV_SYSCALL_EXIT, &sTracedEvents);
+
+      /* Always trace the buffer start, the trace start and the change mask */
+      ltt_set_bit(TRACE_EV_BUFFER_START, &sTracedEvents);
+      ltt_set_bit(TRACE_EV_START, &sTracedEvents);
+      ltt_set_bit(TRACE_EV_CHANGE_MASK, &sTracedEvents);
+
+      /* Forward trace()'s error code */
+      return lRetValue;
+      break;
+
+    /* Get event mask */
+    case TRACER_GET_EVENT_MASK :
+      /* Copy the information to user space */
+      if(copy_to_user((void*) pmArg, &sTracedEvents, sizeof(sTracedEvents)))
+	return -EFAULT;
+      break;
+
+    /* Unknow command */
+    default :
+      return -ENOSYS;
+    }
+
+  /* Everything went OK */
+  return 0;
+}
+
+/*************************************************************
+ * Function : tracer_mmap()
+ * Description : "Mmap" file op
+ * Parameters :
+ *     pmInode, the inode associated with the device
+ *     pmFile, file structure given to the acting process
+ *     pmVmArea, Virtual memory area description structure
+ * Return values :
+ *     0 if ok
+ *     -EAGAIN, when remap failed
+ *     -EACCESS, permission denied
+ ************************************************************/
+int tracer_mmap(struct file*            pmFile,
+		struct vm_area_struct*  pmVmArea)
+{
+  int      lRetValue;     /* Function's return value */
+
+  /* Only the trace daemon is allowed access to mmap */
+  if(current != sDaemonTaskStruct)
+    return -EACCES;
+
+  /* Remap trace buffer into the process's memory space */
+  lRetValue = tracer_mmap_region((char*) pmVmArea->vm_start,
+				 sTracBuf,
+				 pmVmArea->vm_end - pmVmArea->vm_start);
+
+#if 0
+  printk("Tracer: Trace buffer virtual address                  => 0x%08X \n", (uint32_t)sTracBuf);
+  printk("Tracer: Trace buffer physical address                 => 0x%08X \n", (uint32_t)virt_to_phys(sTracBuf));
+  printk("Tracer: Trace buffer virtual address in daemon space  => 0x%08X \n", (uint32_t)pmVmArea->vm_start);
+  printk("Tracer: Trace buffer physical address in daemon space => 0x%08X \n", (uint32_t)virt_to_phys((void*)pmVmArea->vm_start));
+#endif
+
+  /* Tell the caller that the memory mapping worked OK */
+  return lRetValue;
+}
+
+/*************************************************************
+ * Function : tracer_open()
+ * Description : "Open" file op
+ * Parameters : 
+ *     pmInode, the inode associated with the device
+ *     pmFile, file structure given to the acting process
+ * Return values :
+ *     0, everything went OK
+ *     -ENODEV, no such device.
+ *     -EBUSY, daemon channel (minor number 0) already in use.
+ ************************************************************/
+int tracer_open(struct inode* pmInode,
+		struct file*  pmFile)
+{
+  int lDevMinor = MINOR(pmInode->i_rdev) & 0xf;  /* Device minor number */
+
+  /* Only minor number 0 and 1 are used */
+  if((lDevMinor > 0) && (lDevMinor != 1))
+    return -ENODEV;
+
+  /* If the device has already been opened */
+  if(sOpenCount)
+    {
+    /* Is there another process trying to open the daemon's channel (minor number 0) */
+    if(lDevMinor == 0)
+      /* This isn't allowed */
+      return -EBUSY;
+    else
+      /* Only increment use, this is just another user process trying to log user events */
+      goto IncrementUse;
+    }
+
+  /* Fetch the task structure of the process that opened the device */
+  sDaemonTaskStruct = current;
+
+  /* Reset the default configuration since this is the daemon and he will complete the setup */
+  tracer_set_default_config();
+
+#if 0
+  /* DEBUG */
+  printk("<1>Process %d opened the tracing device \n", sDaemonTaskStruct->pid);
+#endif
+
+IncrementUse:
+  /* Lock the device */
+  sOpenCount++;
+
+#ifdef MODULE
+  /* Increment module usage */
+  MOD_INC_USE_COUNT;
+#endif
+
+  /* Everything is OK */
+  return 0;
+}
+
+/*************************************************************
+ * Function : tracer_release()
+ * Description : "Release" file op
+ * Parameters :
+ *     pmInode, the inode associated with the device
+ *     pmFile, file structure given to the acting process
+ * Return values : 
+ *     0, everything went OK
+ * Note :
+ *     It is assumed that if the tracing daemon dies, exits
+ *     or simply stops existing, the kernel or "someone" will
+ *     call tracer_release. Otherwise, we're in trouble ...
+ *************************************************************/
+int tracer_release(struct inode* pmInode,
+		   struct file*  pmFile)
+{
+  int lDevMinor = MINOR(pmInode->i_rdev) & 0xf;  /* Device minor number */
+
+  /* Is this a simple user process exiting? */
+  if(lDevMinor != 0)
+    goto DecrementUse;
+
+  /* Did we loose any events */
+  if(sEventsLost > 0)
+    printk(KERN_ALERT "Tracer: Lost %d events \n", sEventsLost);
+
+  /* Reset the daemon PID */
+  sDaemonTaskStruct = NULL;
+
+  /* Free the current buffers, if any */
+  if(sTracBuf != NULL)
+    rvfree(sTracBuf, sAllocSize);
+
+  /* Reset the read and write buffers */
+  sTracBuf    = NULL;
+  sWritBuf    = NULL;
+  sReadBuf    = NULL;
+  sWritBufEnd = NULL;
+  sReadBufEnd = NULL;
+  sWritPos    = NULL;
+  sReadLimit  = NULL;
+  sWritLimit  = NULL;
+
+  /* Reset the tracer's configuration */
+  tracer_set_default_config();
+  sTracerStarted = FALSE;
+
+  /* Reset number of bytes recorded and number of events lost */
+  sBufReadComplete    = 0;
+  sSizeReadIncomplete = 0;
+  sEventsLost         = 0;
+
+  /* Reset signal sent */
+  sSignalSent = FALSE;
+
+DecrementUse:
+  /* Unlock the device */
+  sOpenCount--;
+
+#ifdef MODULE
+  /* Decrement module usage */
+  MOD_DEC_USE_COUNT;
+#endif
+
+  /* Tell the caller that everything is OK */
+  return 0;
+}
+
+/*************************************************************
+ * Function : tracer_fsync()
+ * Description : "Fsync" file op
+ * Parameters :
+ *     pmFile, file structure given to the acting process
+ *     pmDEntry, dentry associated with file
+ * Return values : 
+ *     0, everything went OK
+ *     -EACCESS, permission denied
+ * Note :
+ *     We need to look the modifications of the values because
+ *     they are read and written by trace().
+ * Sonia : ne m oublie pas, je suis toujours a toi....
+ *************************************************************/
+int tracer_fsync(struct file*   pmFile,
+		 struct dentry* pmDEntry,
+		 int            pmDataSync)
+{
+  unsigned long int   lFlags;      /* CPU flags for lock */
+
+  /* Only the trace daemon is allowed access to fsync */
+  if(current != sDaemonTaskStruct)
+    return -EACCES;
+
+  /* Lock the kernel */
+  spin_lock_irqsave(&sSpinLock, lFlags);
+  
+  /* Reset the write positions */
+  sWritPos   = sWritBuf;
+
+  /* Reset read limit */
+  sReadLimit = sReadBuf;
+
+  /* Reset bytes recorded */
+  sBufReadComplete    = 0;
+  sSizeReadIncomplete = 0;
+  sEventsLost         = 0;
+
+  /* Reset signal sent */
+  sSignalSent = FALSE;
+
+  /* Unlock the kernel */
+  spin_unlock_irqrestore(&sSpinLock, lFlags);
+
+  /* Tell the caller that everything is OK */
+  return 0;
+}
+
+/*************************************************************
+ * Function : tracer_set_buffer_size()
+ * Description :
+ *     Sets the size of the buffers containing the trace data.
+ * Parameters :
+ *     pmSize, Size of buffers
+ * Return values :
+ *     0, Size setting went OK
+ *     -ENOMEM, unable to get a hold of memory for tracer
+ *************************************************************/
+int tracer_set_buffer_size(int pmSize)
+{
+  int       lSizeAlloc;     /* Size to be allocated */
+
+  /* Set size to allocate (= pmSize * 2) and fix it's size to be on a page boundary */
+  lSizeAlloc = FIX_SIZE(pmSize << 1);
+
+  /* Free the current buffers, if any */
+  if(sTracBuf != NULL)
+    rvfree(sTracBuf, sAllocSize);
+
+  /* Allocate space for the tracing buffers */
+  if((sTracBuf = (char*) rvmalloc(lSizeAlloc)) == NULL)
+    return -ENOMEM;
+
+  /* Remember the size set */
+  sBufSize = pmSize;
+  sAllocSize = lSizeAlloc;
+
+  /* Set the read and write buffers */
+  sWritBuf = sTracBuf;
+  sReadBuf = sTracBuf + sBufSize;
+
+  /* Set end of buffers */
+  sWritBufEnd = sWritBuf + sBufSize;
+  sReadBufEnd = sReadBuf + sBufSize;
+
+  /* Set write position */
+  sWritPos = sWritBuf;
+
+  /* Set read limit */
+  sReadLimit = sReadBuf;
+
+  /* Set write limit */
+  sWritLimit = sWritBufEnd - TRACER_LAST_EVENT_SIZE;
+
+  /* All is OK */
+  return 0;
+}
+
+/*************************************************************
+ * Function : tracer_set_default_config()
+ * Description : Sets the tracer in its default config
+ * Parameters :
+ *     NONE
+ * Return values :
+ *    0, everything went OK
+ *    -ENOMEM, unable to get a hold of memory for tracer
+ *************************************************************/
+int tracer_set_default_config(void)
+{
+  int  i;          /* Generic index */
+  int  lError = 0; /* Error, if any */
+
+  /* Initialize the event mask */
+  sTracedEvents = 0;
+  
+  /* Initialize the event mask with all existing events with their details*/
+  for(i = 0; i <= TRACE_EV_MAX; i++)
+    {
+    ltt_set_bit(i, &sTracedEvents);
+    ltt_set_bit(i, &sLogEventDetailsMask);
+    }
+
+  /* Do not interfere with Linux's syscall flow until we actually start tracing */
+  syscall_entry_trace_active = 0;
+  syscall_exit_trace_active  = 0;
+
+  /* Forget about the CPUID */
+  sLogCPUID = FALSE;
+  
+  /* We aren't tracing any PID or GID in particular */
+  sTracingPID  = FALSE;
+  sTracingPGRP = FALSE;
+  sTracingGID  = FALSE;
+  sTracingUID  = FALSE;
+
+  /* We aren't looking for a particular call depth */
+  sSyscallEIPDepthSet = FALSE;
+
+  /* We aren't going to place bounds on syscall EIP fetching */
+  sUseSyscallEIPBounds = FALSE;
+  sLowerEIPBoundSet = FALSE;
+  sUpperEIPBoundSet = FALSE;
+
+  /* Set the kernel trace configuration to it's basics */
+  trace_set_config(trace,
+		   sSyscallEIPDepthSet,
+		   sUseSyscallEIPBounds,
+		   0,
+		   0,
+		   0);
+
+  /* Return the error code */
+  return lError;
+}
+
+/**************************************************************
+ * Function : tracer_init()
+ * Description : Tracer initialization function.
+ * Parameters :
+ *     NONE
+ * Return values : 
+ *    0, everything went OK
+ *    -ENONMEM, incapable of allocating necessary memory
+ *    Forwarded error code otherwise
+ **************************************************************/
+int __init tracer_init(void)
+{
+  int  lError = 0; /* Error, if any */
+
+  /* Initialize configuration */
+  if((lError = tracer_set_default_config()) < 0)
+    return lError;
+
+  /* Initialize open count */
+  sOpenCount = 0;
+
+  /* Initialize tracer lock */
+  sTracLock = 0;
+
+  /* Initialize signal sent */
+  sSignalSent = FALSE;
+
+  /* Initialize bytes read and events lost */
+  sBufReadComplete    = 0;
+  sSizeReadIncomplete = 0;
+  sEventsLost         = 0;
+
+  /* Initialize buffer ID */
+  sBufferID    = 0;
+
+  /* Initialize tracing daemon task structure */
+  sDaemonTaskStruct = NULL;
+
+  /* Allocate memory for large data components */
+  if((sUserEventData = vmalloc(CUSTOM_EVENT_MAX_SIZE)) < 0)
+    return -ENOMEM;
+
+  /* Initialize spin lock */
+  sSpinLock = SPIN_LOCK_UNLOCKED;
+
+  /* Register the tracer as a char device */ 
+  sMajorNumber = register_chrdev(0, TRACER_NAME, &sTracerFileOps);
+
+  /* Register the tracer with the kernel */
+  if((lError = register_tracer(trace)) < 0)
+    {
+    /* Tell the user about the problem */
+    printk(KERN_ALERT "Tracer: Unable to register tracer with kernel, tracer disabled \n");
+
+    /* Make sure no one can open this device */
+    sOpenCount = 1;
+    }
+  else
+    printk(KERN_INFO "Tracer: Initialization complete \n");
+
+  /* Return error code */
+  return lError;
+}
+
+/* Is this loaded as a module */
+#ifdef MODULE
+/**************************************************************
+ * Function : cleanup_module()
+ * Description : Cleanup of the tracer.
+ * Parameters : NONE
+ * Return values : NONE
+ * Note : The order of the unregesterings is important. First,
+ *        rule out any possibility of getting more trace 
+ *        data. Second, rule out any possibility of being read
+ *        by the tracing daemon. Last, free the tracing
+ *        buffer.
+ **************************************************************/
+void tracer_exit(void)
+{
+  /* Unregister the tracer from the kernel */
+  unregister_tracer(trace);
+
+  /* Unregister the tracer from being a char device */
+  unregister_chrdev(sMajorNumber, TRACER_NAME);
+
+  /* Free the current buffers, if any */
+  if(sTracBuf != NULL)
+    rvfree(sTracBuf, sAllocSize);
+
+  /* Paranoia */
+  sTracBuf = NULL;
+}
+module_exit(tracer_exit);
+#endif /* MODULE */
+
+module_init(tracer_init);
diff -rbNu linux-2.4.19/drivers/trace/tracer.h linux-2.4.19-ltt/drivers/trace/tracer.h
--- linux-2.4.19/drivers/trace/tracer.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.19-ltt/drivers/trace/tracer.h	2004-12-28 23:22:57.000000000 +0100
@@ -0,0 +1,276 @@
+/*
+ * drivers/trace/tracer.h
+ *
+ * Copyright (C) 1999, 2000, 2001 Karim Yaghmour (karym@opersys.com)
+ * Portions contributed by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
+ *
+ * This contains the necessary definitions the system tracer
+ */
+
+#ifndef _TRACER_H
+#define _TRACER_H
+
+/* Logic values */
+#define FALSE 0
+#define TRUE  1
+
+/* Structure packing within the trace */
+#ifndef LTT_PACKED_STRUCT
+#if LTT_UNPACKED_STRUCTS
+#define LTT_PACKED_STRUCT
+#else  /* if LTT_UNPACKED_STRUCTS */
+#define LTT_PACKED_STRUCT __attribute__ ((packed));
+#endif /* if LTT_UNPACKED_STRUCTS */
+#endif /* if LTT_PACKED_STRUCT */
+
+/* Tracer properties */
+#define TRACER_NAME      "tracer"     /* Name of the device as seen in /proc/devices */
+
+/* Tracer buffer information */
+#define TRACER_DEFAULT_BUF_SIZE   50000   /* Default size of tracing buffer */
+#define TRACER_MIN_BUF_SIZE        1000   /* Minimum size of tracing buffer */
+#define TRACER_MAX_BUF_SIZE      500000   /* Maximum size of tracing buffer */
+
+/* Local definitions */
+typedef uint32_t    trace_time_delta;    /* The type used to start the time delta between events */
+
+/* Number of bytes set aside for last event */
+#define TRACER_LAST_EVENT_SIZE   (sizeof(uint8_t) + sizeof(uint8_t) + sizeof(trace_time_delta) + sizeof(uint32_t))
+
+/* Architecture types */
+#define TRACE_ARCH_TYPE_I386                1   /* i386 system */
+#define TRACE_ARCH_TYPE_PPC                 2   /* PPC system */
+#define TRACE_ARCH_TYPE_SH                  3   /* SH system */
+#define TRACE_ARCH_TYPE_S390                4   /* S/390 system */
+#define TRACE_ARCH_TYPE_MIPS                5   /* MIPS system */
+#define TRACE_ARCH_TYPE_ARM                 6   /* ARM system */
+
+/* Standard definitions for variants */
+#define TRACE_ARCH_VARIANT_NONE             0   /* Main architecture implementation */
+
+/* PowerPC variants */
+#define TRACE_ARCH_VARIANT_PPC_4xx          1   /* 4xx systems (IBM embedded series) */
+#define TRACE_ARCH_VARIANT_PPC_6xx          2   /* 6xx/7xx/74xx/8260/POWER3 systems (desktop flavor) */
+#define TRACE_ARCH_VARIANT_PPC_8xx          3   /* 8xx system (Motoral embedded series) */
+#define TRACE_ARCH_VARIANT_PPC_ISERIES      4   /* 8xx system (iSeries) */
+
+/* System types */
+#define TRACE_SYS_TYPE_VANILLA_LINUX        1   /* Vanilla linux kernel  */
+
+/* The information logged when the tracing is started */
+#define TRACER_MAGIC_NUMBER     0x00D6B7ED      /* That day marks an important historical event ... */
+#define TRACER_VERSION_MAJOR    1               /* Major version number */
+#define TRACER_VERSION_MINOR   14               /* Minor version number */
+typedef struct _trace_start
+{
+  uint32_t           MagicNumber;  /* Magic number to identify a trace */
+  uint32_t           ArchType;     /* Type of architecture */
+  uint32_t           ArchVariant;  /* Variant of the given type of architecture */
+  uint32_t           SystemType;   /* Operating system type */
+  uint8_t            MajorVersion; /* Major version of trace */
+  uint8_t            MinorVersion; /* Minor version of trace */
+
+  uint32_t           BufferSize;   /* Size of buffers */
+  trace_event_mask   EventMask;    /* The event mask */
+  trace_event_mask   DetailsMask;  /* Are the event details logged */
+  uint8_t            LogCPUID;     /* Is the CPUID logged */
+} LTT_PACKED_STRUCT trace_start;
+
+/* Start and end of trace buffer information */
+typedef struct _trace_buffer_start
+{
+  struct timeval     Time;  /* Time stamp of this buffer */
+  uint32_t           ID;    /* Unique buffer ID */  
+} LTT_PACKED_STRUCT trace_buffer_start;
+
+/* The configurations possible */
+#define TRACER_START                      TRACER_MAGIC_NUMBER + 0  /* Start tracing events using the current configuration */
+#define TRACER_STOP                       TRACER_MAGIC_NUMBER + 1  /* Stop tracing */
+#define TRACER_CONFIG_DEFAULT             TRACER_MAGIC_NUMBER + 2  /* Set the tracer to the default configuration */
+#define TRACER_CONFIG_MEMORY_BUFFERS      TRACER_MAGIC_NUMBER + 3  /* Set the memory buffers the daemon wants us to use */
+#define TRACER_CONFIG_EVENTS              TRACER_MAGIC_NUMBER + 4  /* Trace the given events */
+#define TRACER_CONFIG_DETAILS             TRACER_MAGIC_NUMBER + 5  /* Record the details of the event, or not */
+#define TRACER_CONFIG_CPUID               TRACER_MAGIC_NUMBER + 6  /* Record the CPUID associated with the event */
+#define TRACER_CONFIG_PID                 TRACER_MAGIC_NUMBER + 7  /* Trace only one process */
+#define TRACER_CONFIG_PGRP                TRACER_MAGIC_NUMBER + 8  /* Trace only the given process group */
+#define TRACER_CONFIG_GID                 TRACER_MAGIC_NUMBER + 9  /* Trace the processes of a given group of users */
+#define TRACER_CONFIG_UID                 TRACER_MAGIC_NUMBER + 10 /* Trace the processes of a given user */
+#define TRACER_CONFIG_SYSCALL_EIP_DEPTH   TRACER_MAGIC_NUMBER + 11 /* Set the call depth at which the EIP should be fetched on syscall */
+#define TRACER_CONFIG_SYSCALL_EIP_LOWER   TRACER_MAGIC_NUMBER + 12 /* Set the lowerbound address from which EIP is recorded on syscall */
+#define TRACER_CONFIG_SYSCALL_EIP_UPPER   TRACER_MAGIC_NUMBER + 13 /* Set the upperbound address from which EIP is recorded on syscall */
+#define TRACER_DATA_COMITTED              TRACER_MAGIC_NUMBER + 14 /* The daemon has comitted the last trace */
+#define TRACER_GET_EVENTS_LOST            TRACER_MAGIC_NUMBER + 15 /* Get the number of events lost */
+#define TRACER_CREATE_USER_EVENT          TRACER_MAGIC_NUMBER + 16 /* Create a user tracable event */
+#define TRACER_DESTROY_USER_EVENT         TRACER_MAGIC_NUMBER + 17 /* Destroy a user tracable event */
+#define TRACER_TRACE_USER_EVENT           TRACER_MAGIC_NUMBER + 18 /* Trace a user event */
+#define TRACER_SET_EVENT_MASK             TRACER_MAGIC_NUMBER + 19 /* Set the trace event mask */
+#define TRACER_GET_EVENT_MASK             TRACER_MAGIC_NUMBER + 20 /* Get the trace event mask */
+
+#ifdef __powerpc__
+/* We need to replace the usual PPC kernel bit manipulation functions with
+ * equivalent functions that are cross-platform compatible.  The PPC kernel
+ * functions define bit order as follows:
+ *
+ * bit  0: 0x0000000100000000
+ * bit  1: 0x0000000200000000
+ * .
+ * .
+ * .
+ * bit  7: 0x0000008000000000
+ * bit  8: 0x0000010000000000
+ * bit  9: 0x0000020000000000
+ * .
+ * .
+ * .
+ * bit 31: 0x8000000000000000
+ * bit 32: 0x0000000000000001
+ * bit 33: 0x0000000000000002
+ * .
+ * .
+ * .
+ * bit 63: 0x0000000080000000
+ *
+ * Our redefined functions define bit order the same as the kernel bit functions
+ * for x86 targets:
+ *
+ * bit  0: 0x0100000000000000
+ * bit  1: 0x0200000000000000
+ * .
+ * .
+ * .
+ * bit  7: 0x8000000000000000
+ * bit  8: 0x0001000000000000
+ * bit  9: 0x0002000000000000
+ * .
+ * .
+ * .
+ * bit 31: 0x0000000800000000
+ * bit 32: 0x0000000001000000
+ * bit 33: 0x0000000002000000
+ * .
+ * .
+ * .
+ * bit 63: 0x0000000000000080
+ */
+static inline int ltt_set_bit(int nr, volatile void * addr)
+{
+	unsigned long old, t;
+	unsigned long mask = 1 << (24 - (nr & 0x18) + (nr & 0x7));
+	volatile unsigned long *p = ((volatile unsigned long *)addr) + (nr >> 5);
+	
+	__asm__ __volatile__(
+		"1:lwarx %0,0,%3 \n\t"
+		"or	%1,%0,%2 \n\t"
+		"stwcx.	%1,0,%3 \n\t"
+		"bne	1b \n\t"
+		: "=&r" (old), "=&r" (t)	/*, "=m" (*p)*/
+		: "r" (mask), "r" (p)
+		/*: "cc" */);
+
+	return (old & mask) != 0;
+}
+
+static inline int ltt_clear_bit(unsigned long nr, volatile void *addr)
+{
+	unsigned long old, t;
+	unsigned long mask = 1 << (24 - (nr & 0x18) + (nr & 0x7));
+	volatile unsigned long *p = ((volatile unsigned long *)addr) + (nr >> 5);
+
+	__asm__ __volatile__("\n\t"                      \
+	"1:	lwarx	%0,0,%3\n\t"                     \
+	"andc	%1,%0,%2\n\t"                            \
+	"stwcx.	%1,0,%3\n\t"                             \
+	"bne	1b\n\t "                                 \
+	: "=&r" (old), "=&r" (t),	/*, "=m" (*p)*/a \
+	: "r" (mask), "r" (p),                           \
+        :);                                              \
+
+	return (old & mask) != 0;
+}
+
+static inline int ltt_test_bit(int nr, __const__ volatile void *addr)
+{
+	__const__ volatile unsigned int *p = (__const__ volatile unsigned int *) addr;
+
+	return ((p[nr >> 5] >> (24 - (nr & 0x18) + (nr & 0x7))) & 1) != 0;
+}
+#else  /* ifdef __powerpc__ */
+#if defined(__s390__) || defined(__mips__) /* Added by T.H., modified by K.Y. for mips */
+/* Use functions taken from LTTTypes.h */
+extern __inline__ int ltt_set_bit(int nr, void * addr)
+{
+  unsigned char *p = addr;
+  unsigned char mask = 1 << (nr&7);
+  unsigned char old;
+
+  p += nr>>3;
+  old = *p;
+  *p |= mask;
+
+  return ((old & mask) != 0);
+}
+
+extern __inline__ int ltt_clear_bit(int nr, void * addr)
+{
+  unsigned char *p = addr;
+  unsigned char mask = 1 << (nr&7);
+  unsigned char old;
+
+  p += nr>>3;
+  old = *p;
+  *p &= ~mask;
+
+  return ((old & mask) != 0);
+}
+
+extern __inline__ int ltt_test_bit(int nr,void *addr)
+{
+  unsigned char *p = addr;
+  unsigned char mask = 1 << (nr&7);
+   
+  p += nr>>3;
+                
+  return ((*p & mask) != 0);
+}
+#else /* For non-powerpc, non-s390 and non-mips processors we can use the kernel functions. */
+#define ltt_set_bit    set_bit
+#define ltt_clear_bit  clear_bit
+#define ltt_test_bit   test_bit
+#endif /* if defined(__s390__) || defined(__mips__) */
+#endif /* ifdef __powerpc__ */
+
+/* Function prototypes */
+int     trace
+          (uint8_t,
+	   void*);
+void    tracer_switch_buffers
+          (struct timeval);
+int     tracer_ioctl
+          (struct inode*,
+	   struct file*,
+	   unsigned int,
+	   unsigned long);
+int     tracer_mmap
+	  (struct file*,
+	   struct vm_area_struct*);
+int     tracer_open
+          (struct inode*,
+           struct file*);
+int     tracer_release
+          (struct inode*,
+	   struct file*);
+int     tracer_fsync
+          (struct file*,
+	   struct dentry*,
+	   int);
+#ifdef MODULE
+void    tracer_exit
+          (void);
+#endif
+int     tracer_set_buffer_size
+          (int);
+int     tracer_set_default_config
+          (void);
+int     tracer_init
+          (void);
+#endif /* _TRACER_H */
diff -rbNu linux-2.4.19/fs/buffer.c linux-2.4.19-ltt/fs/buffer.c
--- linux-2.4.19/fs/buffer.c	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.19-ltt/fs/buffer.c	2004-12-28 22:39:46.000000000 +0100
@@ -49,6 +49,8 @@
 #include <linux/completion.h>
 #include <linux/compiler.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/io.h>
 #include <asm/bitops.h>
@@ -154,6 +156,7 @@
 	get_bh(bh);
 	add_wait_queue(&bh->b_wait, &wait);
 	do {
+		TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_BUF_WAIT_START, 0, 0, NULL);
 		run_task_queue(&tq_disk);
 		set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 		if (!buffer_locked(bh))
@@ -161,6 +164,7 @@
 		schedule();
 	} while (buffer_locked(bh));
 	tsk->state = TASK_RUNNING;
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_BUF_WAIT_END, 0, 0, NULL);
 	remove_wait_queue(&bh->b_wait, &wait);
 	put_bh(bh);
 }
diff -rbNu linux-2.4.19/fs/exec.c linux-2.4.19-ltt/fs/exec.c
--- linux-2.4.19/fs/exec.c	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.19-ltt/fs/exec.c	2004-12-28 22:39:46.000000000 +0100
@@ -38,6 +38,8 @@
 #define __NO_VERSION__
 #include <linux/module.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/pgalloc.h>
 #include <asm/mmu_context.h>
@@ -866,6 +868,11 @@
 	if (IS_ERR(file))
 		return retval;
 
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_EXEC,
+			  0,
+			  file->f_dentry->d_name.len,
+			  file->f_dentry->d_name.name);
+
 	bprm.p = PAGE_SIZE*MAX_ARG_PAGES-sizeof(void *);
 	memset(bprm.page, 0, MAX_ARG_PAGES*sizeof(bprm.page[0])); 
 
diff -rbNu linux-2.4.19/fs/ioctl.c linux-2.4.19-ltt/fs/ioctl.c
--- linux-2.4.19/fs/ioctl.c	2001-02-09 20:29:44.000000000 +0100
+++ linux-2.4.19-ltt/fs/ioctl.c	2004-12-28 22:39:46.000000000 +0100
@@ -8,6 +8,8 @@
 #include <linux/smp_lock.h>
 #include <linux/file.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/ioctls.h>
 
@@ -56,6 +58,10 @@
 	if (!filp)
 		goto out;
 	error = 0;
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_IOCTL,
+			  fd,
+			  cmd,
+			  NULL);
 	lock_kernel();
 	switch (cmd) {
 		case FIOCLEX:
diff -rbNu linux-2.4.19/fs/open.c linux-2.4.19-ltt/fs/open.c
--- linux-2.4.19/fs/open.c	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.19-ltt/fs/open.c	2004-12-28 22:39:46.000000000 +0100
@@ -16,6 +16,8 @@
 #include <linux/tty.h>
 #include <linux/iobuf.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 
 #define special_file(m) (S_ISCHR(m)||S_ISBLK(m)||S_ISFIFO(m)||S_ISSOCK(m))
@@ -814,6 +816,10 @@
 			error = PTR_ERR(f);
 			if (IS_ERR(f))
 				goto out_error;
+			TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_OPEN,
+					  fd,
+					  f->f_dentry->d_name.len,
+					  f->f_dentry->d_name.name); 
 			fd_install(fd, f);
 		}
 out:
@@ -880,6 +886,10 @@
 	filp = files->fd[fd];
 	if (!filp)
 		goto out_unlock;
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_CLOSE,
+			  fd,
+			  0,
+			  NULL);
 	files->fd[fd] = NULL;
 	FD_CLR(fd, files->close_on_exec);
 	__put_unused_fd(files, fd);
diff -rbNu linux-2.4.19/fs/read_write.c linux-2.4.19-ltt/fs/read_write.c
--- linux-2.4.19/fs/read_write.c	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.19-ltt/fs/read_write.c	2004-12-28 22:39:46.000000000 +0100
@@ -27,6 +27,8 @@
 #include <linux/smp_lock.h>
 #include <linux/dnotify.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 
 struct file_operations generic_ro_fops = {
@@ -121,6 +123,10 @@
 		if (res != (loff_t)retval)
 			retval = -EOVERFLOW;	/* LFS: should only happen on 32 bit platforms */
 	}
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SEEK,
+			  fd,
+			  offset,
+			  NULL);
 	fput(file);
 bad:
 	return retval;
@@ -146,6 +152,11 @@
 	offset = llseek(file, ((loff_t) offset_high << 32) | offset_low,
 			origin);
 
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SEEK,
+			  fd,
+			  offset,
+			  NULL);
+
 	retval = (int)offset;
 	if (offset >= 0) {
 		retval = -EFAULT;
@@ -173,10 +184,15 @@
 			if (!ret) {
 				ssize_t (*read)(struct file *, char *, size_t, loff_t *);
 				ret = -EINVAL;
-				if (file->f_op && (read = file->f_op->read) != NULL)
+				if (file->f_op && (read = file->f_op->read) != NULL) {
+				 	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_READ,
+							  fd,
+							  count,
+							  NULL); 
 					ret = read(file, buf, count, &file->f_pos);
 			}
 		}
+		}
 		if (ret > 0)
 			dnotify_parent(file->f_dentry, DN_ACCESS);
 		fput(file);
@@ -199,10 +215,15 @@
 			if (!ret) {
 				ssize_t (*write)(struct file *, const char *, size_t, loff_t *);
 				ret = -EINVAL;
-				if (file->f_op && (write = file->f_op->write) != NULL)
+				if (file->f_op && (write = file->f_op->write) != NULL) {
+				        TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_WRITE,
+							  fd, 
+							  count,
+							  NULL);
 					ret = write(file, buf, count, &file->f_pos);
 			}
 		}
+		}
 		if (ret > 0)
 			dnotify_parent(file->f_dentry, DN_MODIFY);
 		fput(file);
@@ -330,6 +351,10 @@
 	file = fget(fd);
 	if (!file)
 		goto bad_file;
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_READ,
+			  fd,
+			  count,
+			  NULL);
 	if (file->f_op && (file->f_mode & FMODE_READ) &&
 	    (file->f_op->readv || file->f_op->read))
 		ret = do_readv_writev(VERIFY_WRITE, file, vector, count);
@@ -350,6 +375,10 @@
 	file = fget(fd);
 	if (!file)
 		goto bad_file;
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_WRITE,
+			  fd,
+			  count,
+			  NULL);
 	if (file->f_op && (file->f_mode & FMODE_WRITE) &&
 	    (file->f_op->writev || file->f_op->write))
 		ret = do_readv_writev(VERIFY_READ, file, vector, count);
@@ -385,6 +414,12 @@
 		goto out;
 	if (pos < 0)
 		goto out;
+
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_READ,
+			  fd,
+			  count,
+			  NULL);
+
 	ret = read(file, buf, count, &pos);
 	if (ret > 0)
 		dnotify_parent(file->f_dentry, DN_ACCESS);
@@ -417,6 +452,11 @@
 	if (pos < 0)
 		goto out;
 
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_WRITE,
+			  fd,
+			  count,
+			  NULL);
+
 	ret = write(file, buf, count, &pos);
 	if (ret > 0)
 		dnotify_parent(file->f_dentry, DN_MODIFY);
diff -rbNu linux-2.4.19/fs/select.c linux-2.4.19-ltt/fs/select.c
--- linux-2.4.19/fs/select.c	2001-09-10 22:04:33.000000000 +0200
+++ linux-2.4.19-ltt/fs/select.c	2004-12-28 22:39:46.000000000 +0100
@@ -20,6 +20,8 @@
 #include <linux/personality.h> /* for STICKY_TIMEOUTS */
 #include <linux/file.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 
 #define ROUND_UP(x,y) (((x)+(y)-1)/(y))
@@ -193,6 +195,10 @@
 			file = fget(i);
 			mask = POLLNVAL;
 			if (file) {
+				TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SELECT,
+						  i /*  The fd*/,
+						  __timeout,
+						  NULL);
 				mask = DEFAULT_POLLMASK;
 				if (file->f_op && file->f_op->poll)
 					mask = file->f_op->poll(file, wait);
@@ -367,6 +373,10 @@
 			struct file * file = fget(fd);
 			mask = POLLNVAL;
 			if (file != NULL) {
+			        TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_POLL,
+						  fd,
+						  0,
+						  NULL);
 				mask = DEFAULT_POLLMASK;
 				if (file->f_op && file->f_op->poll)
 					mask = file->f_op->poll(file, *pwait);
diff -rbNu linux-2.4.19/include/asm-mips/mipsregs.h linux-2.4.19-ltt/include/asm-mips/mipsregs.h
--- linux-2.4.19/include/asm-mips/mipsregs.h	2002-08-03 02:39:45.000000000 +0200
+++ linux-2.4.19-ltt/include/asm-mips/mipsregs.h	2004-12-28 22:39:46.000000000 +0100
@@ -446,6 +446,9 @@
 
 #ifndef __ASSEMBLY__
 
+#define CAUSE_EXCCODE(x) ((CAUSEF_EXCCODE & (x->cp0_cause)) >> CAUSEB_EXCCODE)
+#define CAUSE_EPC(x) (x->cp0_epc + (((x->cp0_cause & CAUSEF_BD) >> CAUSEB_BD) << 2))
+
 /*
  * Functions to access the r10k performance counter and control registers
  */
diff -rbNu linux-2.4.19/include/linux/trace.h linux-2.4.19-ltt/include/linux/trace.h
--- linux-2.4.19/include/linux/trace.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.19-ltt/include/linux/trace.h	2004-12-28 23:27:29.000000000 +0100
@@ -0,0 +1,437 @@
+/*
+ * linux/include/linux/trace.h
+ *
+ * Copyright (C) 1999, Karim Yaghmour
+ *
+ * This contains the necessary definitions for tracing the
+ * the system.
+ */
+
+#ifndef _LINUX_TRACE_H
+#define _LINUX_TRACE_H
+
+#include <linux/config.h>
+#include <linux/types.h>
+
+/* Is kernel tracing enabled */
+#if defined(CONFIG_TRACE) || defined(CONFIG_TRACE_MODULE)
+
+/* Structure packing within the trace */
+#if LTT_UNPACKED_STRUCTS
+#define LTT_PACKED_STRUCT
+#else  /* if LTT_UNPACKED_STRUCTS */
+#define LTT_PACKED_STRUCT __attribute__ ((packed))
+#endif /* if LTT_UNPACKED_STRUCTS */
+
+/* The prototype of the tracer call (EventID, *EventStruct) */
+typedef int (*tracer_call) (uint8_t, void*);
+
+/* This structure contains all the information needed to be known
+   about the tracing module. */
+struct tracer
+{
+  /* The tracing routine itself */
+  tracer_call trace;
+
+  /* Fetch of eip origin of syscall */
+  int         fetch_syscall_eip_use_depth;  /* Use the given depth */
+  int         fetch_syscall_eip_use_bounds; /* Find eip in bounds */
+  int         syscall_eip_depth;            /* Call depth at which eip is fetched */
+  void*       syscall_lower_eip_bound;      /* Lower eip bound */
+  void*       syscall_upper_eip_bound;      /* Higher eip bound */
+};
+
+/* Maximal size a custom event can have */
+#define CUSTOM_EVENT_MAX_SIZE        8192
+
+/* String length limits for custom events creation */
+#define CUSTOM_EVENT_TYPE_STR_LEN      20
+#define CUSTOM_EVENT_DESC_STR_LEN     100
+#define CUSTOM_EVENT_FORM_STR_LEN     256
+#define CUSTOM_EVENT_FINAL_STR_LEN    200
+
+/* Type of custom event formats */
+#define CUSTOM_EVENT_FORMAT_TYPE_NONE   0
+#define CUSTOM_EVENT_FORMAT_TYPE_STR    1
+#define CUSTOM_EVENT_FORMAT_TYPE_HEX    2
+#define CUSTOM_EVENT_FORMAT_TYPE_XML    3
+#define CUSTOM_EVENT_FORMAT_TYPE_IBM    4
+
+/* Global trace flags */
+extern unsigned int syscall_entry_trace_active;
+extern unsigned int syscall_exit_trace_active;
+
+/* The functions to the tracer management code */
+int register_tracer
+       (tracer_call   /* The tracer function */);
+int unregister_tracer
+       (tracer_call   /* The tracer function */);
+int trace_set_config
+       (tracer_call   /* The tracer function */,
+	int           /* Use depth to fetch eip */,
+	int           /* Use bounds to fetch eip */,
+	int           /* Detph to fetch eip */,
+	void*         /* Lower bound eip address */,
+	void*         /* Upper bound eip address */);
+int trace_register_callback
+       (tracer_call   /* The callback to add */,
+	uint8_t       /* The event ID targeted */);
+int trace_unregister_callback
+       (tracer_call   /* The callback to remove */,
+	uint8_t       /* The event ID targeted */);
+int trace_get_config
+       (int*          /* Use depth to fetch eip */,
+	int*          /* Use bounds to fetch eip */,
+	int*          /* Detph to fetch eip */,
+	void**        /* Lower bound eip address */,
+	void**        /* Upper bound eip address */);
+int  trace_create_event
+       (char*         /* String describing event type */,
+	char*         /* String to format standard event description */,
+	int           /* Type of formatting used to log event data */,
+	char*         /* Data specific to format */);
+int  trace_create_owned_event
+       (char*         /* String describing event type */,
+	char*         /* String to format standard event description */,
+	int           /* Type of formatting used to log event data */,
+	char*         /* Data specific to format */,
+	pid_t         /* PID of event's owner */);
+void trace_destroy_event
+       (int           /* The event ID given by trace_create_event() */);
+void trace_destroy_owners_events
+       (pid_t         /* The PID of the process' who's events are to be deleted */);
+void trace_reregister_custom_events
+       (void);
+int  trace_std_formatted_event
+       (int           /* The event ID given by trace_create_event() */,
+	...           /* The parameters to be printed out in the event string */);
+int  trace_raw_event
+       (int           /* The event ID given by trace_create_event() */,
+	int           /* The size of the raw data */,
+	void*         /* Pointer to the raw event data */);
+int  trace_event
+       (uint8_t       /* Event ID (as defined in this header file) */,
+	void*         /* Structure describing the event */);
+
+/* Generic macros */
+#define TRACE_EVENT(ID, DATA) trace_event(ID, DATA)
+
+/* Traced events */
+#define TRACE_EV_START           0    /* This is to mark the trace's start */
+#define TRACE_EV_SYSCALL_ENTRY   1    /* Entry in a given system call */
+#define TRACE_EV_SYSCALL_EXIT    2    /* Exit from a given system call */
+#define TRACE_EV_TRAP_ENTRY      3    /* Entry in a trap */
+#define TRACE_EV_TRAP_EXIT       4    /* Exit from a trap */
+#define TRACE_EV_IRQ_ENTRY       5    /* Entry in an irq */
+#define TRACE_EV_IRQ_EXIT        6    /* Exit from an irq */
+#define TRACE_EV_SCHEDCHANGE     7    /* Scheduling change */
+#define TRACE_EV_KERNEL_TIMER    8    /* The kernel timer routine has been called */
+#define TRACE_EV_SOFT_IRQ        9    /* Hit key part of soft-irq management */
+#define TRACE_EV_PROCESS        10    /* Hit key part of process management */
+#define TRACE_EV_FILE_SYSTEM    11    /* Hit key part of file system */
+#define TRACE_EV_TIMER          12    /* Hit key part of timer management */
+#define TRACE_EV_MEMORY         13    /* Hit key part of memory management */
+#define TRACE_EV_SOCKET         14    /* Hit key part of socket communication */
+#define TRACE_EV_IPC            15    /* Hit key part of System V IPC */
+#define TRACE_EV_NETWORK        16    /* Hit key part of network communication */
+
+#define TRACE_EV_BUFFER_START   17    /* Mark the begining of a trace buffer */
+#define TRACE_EV_BUFFER_END     18    /* Mark the ending of a trace buffer */
+#define TRACE_EV_NEW_EVENT      19    /* New event type */
+#define TRACE_EV_CUSTOM         20    /* Custom event */
+
+#define TRACE_EV_CHANGE_MASK    21    /* Change in event mask */
+
+/* Number of traced events */
+#define TRACE_EV_MAX           TRACE_EV_CHANGE_MASK
+
+/* Structures and macros for events */
+/*  TRACE_SYSCALL_ENTRY */
+typedef struct _trace_syscall_entry
+{
+  uint8_t   syscall_id;   /* Syscall entry number in entry.S */
+  uint32_t  address;      /* Address from which call was made */
+} LTT_PACKED_STRUCT trace_syscall_entry;
+
+/*  TRACE_TRAP_ENTRY */
+#ifndef __s390__
+typedef struct _trace_trap_entry
+{
+  uint16_t  trap_id;  /* Trap number */
+  uint32_t  address;  /* Address where trap occured */
+} LTT_PACKED_STRUCT trace_trap_entry;
+#else
+typedef uint64_t trapid_t;
+typedef struct _trace_trap_entry
+{
+  trapid_t  trap_id;  /* Trap number */
+  uint32_t  address;  /* Address where trap occured */
+} LTT_PACKED_STRUCT trace_trap_entry;
+#endif
+#define TRACE_TRAP_ENTRY(ID, EIP) \
+           do \
+           {\
+           trace_trap_entry trap_event;\
+           trap_event.trap_id = ID;\
+           trap_event.address = EIP;\
+           trace_event(TRACE_EV_TRAP_ENTRY, &trap_event);\
+	   } while(0)
+
+/*  TRACE_TRAP_EXIT */
+#define TRACE_TRAP_EXIT()  trace_event(TRACE_EV_TRAP_EXIT, NULL)
+
+/*  TRACE_IRQ_ENTRY */
+typedef struct _trace_irq_entry
+{
+  uint8_t  irq_id;      /* IRQ number */
+  uint8_t  kernel;      /* Are we executing kernel code */
+} LTT_PACKED_STRUCT trace_irq_entry;
+#define TRACE_IRQ_ENTRY(ID, KERNEL) \
+           do \
+           {\
+           trace_irq_entry irq_entry;\
+           irq_entry.irq_id = ID;\
+           irq_entry.kernel = KERNEL;\
+           trace_event(TRACE_EV_IRQ_ENTRY, &irq_entry);\
+           } while(0)
+
+/*  TRACE_IRQ_EXIT */
+#define TRACE_IRQ_EXIT()  trace_event(TRACE_EV_IRQ_EXIT, NULL)
+
+/*  TRACE_SCHEDCHANGE */ 
+typedef struct _trace_schedchange
+{
+  uint32_t  out;         /* Outgoing process */
+  uint32_t  in;          /* Incoming process */
+  uint32_t  out_state;   /* Outgoing process' state */
+} LTT_PACKED_STRUCT trace_schedchange;
+#define TRACE_SCHEDCHANGE(OUT, IN) \
+           do \
+           {\
+           trace_schedchange sched_event;\
+           sched_event.out       = OUT->pid;\
+           sched_event.in        = (uint32_t) IN;\
+           sched_event.out_state = OUT->state; \
+           trace_event(TRACE_EV_SCHEDCHANGE, &sched_event);\
+           } while(0)
+
+/*  TRACE_SOFT_IRQ */
+#define TRACE_EV_SOFT_IRQ_BOTTOM_HALF        1  /* Conventional bottom-half */
+#define TRACE_EV_SOFT_IRQ_SOFT_IRQ           2  /* Real soft-irq */
+#define TRACE_EV_SOFT_IRQ_TASKLET_ACTION     3  /* Tasklet action */
+#define TRACE_EV_SOFT_IRQ_TASKLET_HI_ACTION  4  /* Tasklet hi-action */
+typedef struct _trace_soft_irq
+{
+  uint8_t   event_sub_id;     /* Soft-irq event Id */
+  uint32_t  event_data;       /* Data associated with event */
+} LTT_PACKED_STRUCT trace_soft_irq;
+#define TRACE_SOFT_IRQ(ID, DATA) \
+           do \
+           {\
+           trace_soft_irq soft_irq_event;\
+           soft_irq_event.event_sub_id = ID;\
+           soft_irq_event.event_data   = DATA;\
+           trace_event(TRACE_EV_SOFT_IRQ, &soft_irq_event);\
+	   } while(0)
+
+/*  TRACE_PROCESS */
+#define TRACE_EV_PROCESS_KTHREAD     1  /* Creation of a kernel thread */
+#define TRACE_EV_PROCESS_FORK        2  /* A fork or clone occured */
+#define TRACE_EV_PROCESS_EXIT        3  /* An exit occured */
+#define TRACE_EV_PROCESS_WAIT        4  /* A wait occured */
+#define TRACE_EV_PROCESS_SIGNAL      5  /* A signal has been sent */
+#define TRACE_EV_PROCESS_WAKEUP      6  /* Wake up a process */
+typedef struct _trace_process
+{
+  uint8_t   event_sub_id;    /* Process event ID */
+  uint32_t  event_data1;     /* Data associated with event */
+  uint32_t  event_data2; 
+} LTT_PACKED_STRUCT trace_process;
+#define TRACE_PROCESS(ID, DATA1, DATA2) \
+           do \
+           {\
+           trace_process proc_event;\
+           proc_event.event_sub_id = ID;\
+           proc_event.event_data1 = DATA1;\
+           proc_event.event_data2 = DATA2;\
+           trace_event(TRACE_EV_PROCESS, &proc_event);\
+           } while(0)
+
+/*  TRACE_FILE_SYSTEM */
+#define TRACE_EV_FILE_SYSTEM_BUF_WAIT_START  1  /* Starting to wait for a data buffer */
+#define TRACE_EV_FILE_SYSTEM_BUF_WAIT_END    2  /* End to wait for a data buffer */
+#define TRACE_EV_FILE_SYSTEM_EXEC            3  /* An exec occured */
+#define TRACE_EV_FILE_SYSTEM_OPEN            4  /* An open occured */
+#define TRACE_EV_FILE_SYSTEM_CLOSE           5  /* A close occured */
+#define TRACE_EV_FILE_SYSTEM_READ            6  /* A read occured */
+#define TRACE_EV_FILE_SYSTEM_WRITE           7  /* A write occured */
+#define TRACE_EV_FILE_SYSTEM_SEEK            8  /* A seek occured */
+#define TRACE_EV_FILE_SYSTEM_IOCTL           9  /* An ioctl occured */
+#define TRACE_EV_FILE_SYSTEM_SELECT         10  /* A select occured */
+#define TRACE_EV_FILE_SYSTEM_POLL           11  /* A poll occured */
+typedef struct _trace_file_system
+{
+  uint8_t   event_sub_id;    /* File system event ID */
+  uint32_t  event_data1;     /* Event data */
+  uint32_t  event_data2;     /* Event data 2 */
+  char*     file_name;       /* Name of file operated on */
+} LTT_PACKED_STRUCT trace_file_system;
+#define TRACE_FILE_SYSTEM(ID, DATA1, DATA2, FILE_NAME) \
+           do \
+           {\
+           trace_file_system fs_event;\
+           fs_event.event_sub_id = ID;\
+           fs_event.event_data1  = DATA1;\
+           fs_event.event_data2  = DATA2;\
+           fs_event.file_name    = (char*)FILE_NAME;\
+           trace_event(TRACE_EV_FILE_SYSTEM, &fs_event);\
+           } while(0)
+
+/*  TRACE_TIMER */
+#define TRACE_EV_TIMER_EXPIRED      1  /* Timer expired */
+#define TRACE_EV_TIMER_SETITIMER    2  /* Setting itimer occurred */
+#define TRACE_EV_TIMER_SETTIMEOUT   3  /* Setting sched timeout occurred */
+typedef struct _trace_timer
+{
+  uint8_t   event_sub_id;    /* Timer event ID */
+  uint8_t   event_sdata;     /* Short data */
+  uint32_t  event_data1;     /* Data associated with event */
+  uint32_t  event_data2;     
+} LTT_PACKED_STRUCT trace_timer;
+#define TRACE_TIMER(ID, SDATA, DATA1, DATA2) \
+           do \
+           {\
+           trace_timer timer_event;\
+           timer_event.event_sub_id = ID;\
+           timer_event.event_sdata  = SDATA;\
+           timer_event.event_data1  = DATA1;\
+           timer_event.event_data2  = DATA2;\
+           trace_event(TRACE_EV_TIMER, &timer_event);\
+	   } while(0)
+
+/*  TRACE_MEMORY */
+#define TRACE_EV_MEMORY_PAGE_ALLOC        1  /* Allocating pages */
+#define TRACE_EV_MEMORY_PAGE_FREE         2  /* Freing pages */
+#define TRACE_EV_MEMORY_SWAP_IN           3  /* Swaping pages in */
+#define TRACE_EV_MEMORY_SWAP_OUT          4  /* Swaping pages out */
+#define TRACE_EV_MEMORY_PAGE_WAIT_START   5  /* Start to wait for page */
+#define TRACE_EV_MEMORY_PAGE_WAIT_END     6  /* End to wait for page */
+typedef struct _trace_memory
+{
+  uint8_t        event_sub_id;    /* Memory event ID */
+  unsigned long  event_data;      /* Data associated with event */
+} LTT_PACKED_STRUCT trace_memory;
+#define TRACE_MEMORY(ID, DATA) \
+           do \
+           {\
+           trace_memory memory_event;\
+           memory_event.event_sub_id = ID;\
+           memory_event.event_data   = DATA;\
+           trace_event(TRACE_EV_MEMORY, &memory_event);\
+           } while(0)
+
+/*  TRACE_SOCKET */
+#define TRACE_EV_SOCKET_CALL     1  /* A socket call occured */
+#define TRACE_EV_SOCKET_CREATE   2  /* A socket has been created */
+#define TRACE_EV_SOCKET_SEND     3  /* Data was sent to a socket */
+#define TRACE_EV_SOCKET_RECEIVE  4  /* Data was read from a socket */
+typedef struct _trace_socket
+{
+  uint8_t   event_sub_id;    /* Socket event ID */
+  uint32_t  event_data1;     /* Data associated with event */
+  uint32_t  event_data2;     /* Data associated with event */
+} LTT_PACKED_STRUCT trace_socket;
+#define TRACE_SOCKET(ID, DATA1, DATA2) \
+           do \
+           {\
+           trace_socket socket_event;\
+           socket_event.event_sub_id = ID;\
+           socket_event.event_data1  = DATA1;\
+           socket_event.event_data2  = DATA2;\
+           trace_event(TRACE_EV_SOCKET, &socket_event);\
+           } while(0)
+
+/*  TRACE_IPC */
+#define TRACE_EV_IPC_CALL            1  /* A System V IPC call occured */
+#define TRACE_EV_IPC_MSG_CREATE      2  /* A message queue has been created */
+#define TRACE_EV_IPC_SEM_CREATE      3  /* A semaphore was created */
+#define TRACE_EV_IPC_SHM_CREATE      4  /* A shared memory segment has been created */
+typedef struct _trace_ipc
+{
+  uint8_t   event_sub_id;    /* IPC event ID */
+  uint32_t  event_data1;     /* Data associated with event */
+  uint32_t  event_data2;     /* Data associated with event */
+} LTT_PACKED_STRUCT trace_ipc;
+#define TRACE_IPC(ID, DATA1, DATA2) \
+           do \
+           {\
+           trace_ipc ipc_event;\
+           ipc_event.event_sub_id = ID;\
+           ipc_event.event_data1  = DATA1;\
+           ipc_event.event_data2  = DATA2;\
+           trace_event(TRACE_EV_IPC, &ipc_event);\
+           } while(0)
+
+/*  TRACE_NETWORK */
+#define TRACE_EV_NETWORK_PACKET_IN   1  /* A packet came in */
+#define TRACE_EV_NETWORK_PACKET_OUT  2  /* A packet was sent */
+typedef struct _trace_network
+{
+  uint8_t  event_sub_id;   /* Network event ID */
+  uint32_t event_data;     /* Event data */
+} LTT_PACKED_STRUCT trace_network;
+#define TRACE_NETWORK(ID, DATA) \
+           do \
+           {\
+           trace_network net_event;\
+           net_event.event_sub_id = ID;\
+           net_event.event_data   = DATA;\
+           trace_event(TRACE_EV_NETWORK, &net_event);\
+           } while(0)
+
+/* Custom declared events */
+/* ***WARNING*** These structures should never be used as is, use the provided custom event creation
+                 and logging functions. */
+typedef struct _trace_new_event
+{
+  /* Basics */
+  uint32_t         id;                               /* Custom event ID */
+  char             type[CUSTOM_EVENT_TYPE_STR_LEN];  /* Event type description */
+  char             desc[CUSTOM_EVENT_DESC_STR_LEN];  /* Detailed event description */
+
+  /* Custom formatting */
+  uint32_t         format_type;                       /* Type of formatting */
+  char             form[CUSTOM_EVENT_FORM_STR_LEN];   /* Data specific to format */
+} LTT_PACKED_STRUCT trace_new_event;
+typedef struct _trace_custom
+{
+  uint32_t          id;         /* Event ID */
+  uint32_t          data_size;  /* Size of data recorded by event */
+  void*             data;       /* Data recorded by event */
+} LTT_PACKED_STRUCT trace_custom;
+
+/* TRACE_CHANGE_MASK */
+typedef uint64_t trace_event_mask;    /* The event mask type */
+typedef struct _trace_change_mask
+{
+  trace_event_mask          mask;       /* Event mask */
+} LTT_PACKED_STRUCT trace_change_mask;
+
+#else /* Kernel is configured without tracing */
+#define TRACE_EVENT(ID, DATA)
+#define TRACE_TRAP_ENTRY(ID, EIP)
+#define TRACE_TRAP_EXIT()
+#define TRACE_IRQ_ENTRY(ID, KERNEL)
+#define TRACE_IRQ_EXIT()
+#define TRACE_SCHEDCHANGE(OUT, IN)
+#define TRACE_SOFT_IRQ(ID, DATA)
+#define TRACE_PROCESS(ID, DATA1, DATA2)
+#define TRACE_FILE_SYSTEM(ID, DATA1, DATA2, FILE_NAME)
+#define TRACE_TIMER(ID, SDATA, DATA1, DATA2)
+#define TRACE_MEMORY(ID, DATA)
+#define TRACE_SOCKET(ID, DATA1, DATA2)
+#define TRACE_IPC(ID, DATA1, DATA2)
+#define TRACE_NETWORK(ID, DATA)
+#endif /* defined(CONFIG_TRACE) || defined(CONFIG_TRACE_MODULE) */
+
+#endif /* _LINUX_TRACE_H */
diff -rbNu linux-2.4.19/ipc/msg.c linux-2.4.19-ltt/ipc/msg.c
--- linux-2.4.19/ipc/msg.c	2001-09-14 23:17:00.000000000 +0200
+++ linux-2.4.19-ltt/ipc/msg.c	2004-12-28 22:39:46.000000000 +0100
@@ -25,6 +25,8 @@
 #include <asm/uaccess.h>
 #include "util.h"
 
+#include <linux/trace.h>
+
 /* sysctl: */
 int msg_ctlmax = MSGMAX;
 int msg_ctlmnb = MSGMNB;
@@ -326,6 +328,7 @@
 		msg_unlock(id);
 	}
 	up(&msg_ids.sem);
+	TRACE_IPC(TRACE_EV_IPC_MSG_CREATE, ret, msgflg);
 	return ret;
 }
 
diff -rbNu linux-2.4.19/ipc/sem.c linux-2.4.19-ltt/ipc/sem.c
--- linux-2.4.19/ipc/sem.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/ipc/sem.c	2004-12-28 22:39:46.000000000 +0100
@@ -65,6 +65,7 @@
 #include <asm/uaccess.h>
 #include "util.h"
 
+#include <linux/trace.h>
 
 #define sem_lock(id)	((struct sem_array*)ipc_lock(&sem_ids,id))
 #define sem_unlock(id)	ipc_unlock(&sem_ids,id)
@@ -181,6 +182,7 @@
 	}
 
 	up(&sem_ids.sem);
+	TRACE_IPC(TRACE_EV_IPC_SEM_CREATE, err, semflg);
 	return err;
 }
 
diff -rbNu linux-2.4.19/ipc/shm.c linux-2.4.19-ltt/ipc/shm.c
--- linux-2.4.19/ipc/shm.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/ipc/shm.c	2004-12-28 22:39:46.000000000 +0100
@@ -26,6 +26,8 @@
 
 #include "util.h"
 
+#include <linux/trace.h>
+
 struct shmid_kernel /* private to the kernel */
 {	
 	struct kern_ipc_perm	shm_perm;
@@ -254,6 +256,7 @@
 		shm_unlock(id);
 	}
 	up(&shm_ids.sem);
+	TRACE_IPC(TRACE_EV_IPC_SHM_CREATE, err, shmflg);
 	return err;
 }
 
diff -rbNu linux-2.4.19/kernel/Makefile linux-2.4.19-ltt/kernel/Makefile
--- linux-2.4.19/kernel/Makefile	2001-09-17 06:22:40.000000000 +0200
+++ linux-2.4.19-ltt/kernel/Makefile	2004-12-28 22:39:46.000000000 +0100
@@ -9,7 +9,7 @@
 
 O_TARGET := kernel.o
 
-export-objs = signal.o sys.o kmod.o context.o ksyms.o pm.o exec_domain.o printk.o
+export-objs = signal.o sys.o kmod.o context.o ksyms.o pm.o exec_domain.o printk.o trace.o
 
 obj-y     = sched.o dma.o fork.o exec_domain.o panic.o printk.o \
 	    module.o exit.o itimer.o info.o time.o softirq.o resource.o \
@@ -20,6 +20,10 @@
 obj-$(CONFIG_MODULES) += ksyms.o
 obj-$(CONFIG_PM) += pm.o
 
+ifdef CONFIG_TRACE
+obj-y += trace.o
+endif
+
 ifneq ($(CONFIG_IA64),y)
 # According to Alan Modra <alan@linuxcare.com.au>, the -fno-omit-frame-pointer is
 # needed for x86 only.  Why this used to be enabled for all architectures is beyond
diff -rbNu linux-2.4.19/kernel/exit.c linux-2.4.19-ltt/kernel/exit.c
--- linux-2.4.19/kernel/exit.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/kernel/exit.c	2004-12-28 22:39:46.000000000 +0100
@@ -17,6 +17,8 @@
 #include <linux/acct.h>
 #endif
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
 #include <asm/mmu_context.h>
@@ -455,6 +457,8 @@
 #endif
 	__exit_mm(tsk);
 
+	TRACE_PROCESS(TRACE_EV_PROCESS_EXIT, 0, 0);
+
 	lock_kernel();
 	sem_exit();
 	__exit_files(tsk);
@@ -512,6 +516,8 @@
 	if (options & ~(WNOHANG|WUNTRACED|__WNOTHREAD|__WCLONE|__WALL))
 		return -EINVAL;
 
+	TRACE_PROCESS(TRACE_EV_PROCESS_WAIT, pid, 0);
+
 	add_wait_queue(&current->wait_chldexit,&wait);
 repeat:
 	flag = 0;
diff -rbNu linux-2.4.19/kernel/fork.c linux-2.4.19-ltt/kernel/fork.c
--- linux-2.4.19/kernel/fork.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/kernel/fork.c	2004-12-28 22:39:46.000000000 +0100
@@ -23,6 +23,8 @@
 #include <linux/personality.h>
 #include <linux/compiler.h>
 
+#include <linux/trace.h>
+
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
 #include <asm/uaccess.h>
@@ -751,6 +753,9 @@
 	if (p->ptrace & PT_PTRACED)
 		send_sig(SIGSTOP, p, 1);
 
+	/* Trace the event  */
+	TRACE_PROCESS(TRACE_EV_PROCESS_FORK, retval, 0);
+
 	wake_up_process(p);		/* do this last */
 	++total_forks;
 	if (clone_flags & CLONE_VFORK)
diff -rbNu linux-2.4.19/kernel/itimer.c linux-2.4.19-ltt/kernel/itimer.c
--- linux-2.4.19/kernel/itimer.c	2000-06-29 19:07:36.000000000 +0200
+++ linux-2.4.19-ltt/kernel/itimer.c	2004-12-28 22:39:46.000000000 +0100
@@ -10,6 +10,8 @@
 #include <linux/smp_lock.h>
 #include <linux/interrupt.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 
 /*
@@ -95,6 +97,8 @@
 	struct task_struct * p = (struct task_struct *) __data;
 	unsigned long interval;
 
+	TRACE_TIMER(TRACE_EV_TIMER_EXPIRED, 0, 0, 0);
+
 	send_sig(SIGALRM, p, 1);
 	interval = p->it_real_incr;
 	if (interval) {
@@ -114,6 +118,7 @@
 	j = tvtojiffies(&value->it_value);
 	if (ovalue && (k = do_getitimer(which, ovalue)) < 0)
 		return k;
+	TRACE_TIMER(TRACE_EV_TIMER_SETITIMER, which, i, j);
 	switch (which) {
 		case ITIMER_REAL:
 			del_timer_sync(&current->real_timer);
diff -rbNu linux-2.4.19/kernel/sched.c linux-2.4.19-ltt/kernel/sched.c
--- linux-2.4.19/kernel/sched.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/kernel/sched.c	2004-12-28 22:39:46.000000000 +0100
@@ -30,6 +30,8 @@
 #include <linux/prefetch.h>
 #include <linux/compiler.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 
@@ -353,6 +355,8 @@
 	unsigned long flags;
 	int success = 0;
 
+	TRACE_PROCESS(TRACE_EV_PROCESS_WAKEUP, p->pid, p->state);
+
 	/*
 	 * We want the common case fall through straight, thus the goto.
 	 */
@@ -378,6 +382,7 @@
 {
 	struct task_struct * p = (struct task_struct *) __data;
 
+	TRACE_TIMER(TRACE_EV_TIMER_EXPIRED, 0, 0, 0);
 	wake_up_process(p);
 }
 
@@ -442,6 +447,8 @@
 		}
 	}
 
+	TRACE_TIMER(TRACE_EV_TIMER_SETTIMEOUT, 0, timeout, 0);
+
 	expire = timeout + jiffies;
 
 	init_timer(&timer);
@@ -690,6 +697,8 @@
 		}
 	}
 
+	TRACE_SCHEDCHANGE(prev, next);
+
 	/*
 	 * This just switches the register state and the
 	 * stack.
diff -rbNu linux-2.4.19/kernel/signal.c linux-2.4.19-ltt/kernel/signal.c
--- linux-2.4.19/kernel/signal.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/kernel/signal.c	2004-12-28 22:39:46.000000000 +0100
@@ -14,6 +14,8 @@
 #include <linux/init.h>
 #include <linux/sched.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 
 /*
@@ -570,6 +572,8 @@
 	if (sig < SIGRTMIN && sigismember(&t->pending.signal, sig))
 		goto out;
 
+	TRACE_PROCESS(TRACE_EV_PROCESS_SIGNAL, sig, t->pid);
+
 	ret = deliver_signal(sig, info, t);
 out:
 	spin_unlock_irqrestore(&t->sigmask_lock, flags);
diff -rbNu linux-2.4.19/kernel/softirq.c linux-2.4.19-ltt/kernel/softirq.c
--- linux-2.4.19/kernel/softirq.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/kernel/softirq.c	2004-12-28 22:39:46.000000000 +0100
@@ -17,6 +17,8 @@
 #include <linux/init.h>
 #include <linux/tqueue.h>
 
+#include <linux/trace.h>
+
 /*
    - No shared variables, all the data are CPU local.
    - If a softirq needs serialization, let it serialize itself
@@ -86,8 +88,10 @@
 		h = softirq_vec;
 
 		do {
-			if (pending & 1)
+		        if (pending & 1) {
+		                TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_SOFT_IRQ, (h - softirq_vec));
 				h->action(h);
+			}
 			h++;
 			pending >>= 1;
 		} while (pending);
@@ -192,6 +196,9 @@
 			if (!atomic_read(&t->count)) {
 				if (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))
 					BUG();
+
+				TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_TASKLET_ACTION, (unsigned long) (t->func));
+
 				t->func(t->data);
 				tasklet_unlock(t);
 				continue;
@@ -226,6 +233,9 @@
 			if (!atomic_read(&t->count)) {
 				if (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))
 					BUG();
+
+				TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_TASKLET_HI_ACTION, (unsigned long) (t->func));
+
 				t->func(t->data);
 				tasklet_unlock(t);
 				continue;
@@ -296,8 +306,10 @@
 	if (!hardirq_trylock(cpu))
 		goto resched_unlock;
 
-	if (bh_base[nr])
+	if (bh_base[nr]){
+	        TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_BOTTOM_HALF, (nr));
 		bh_base[nr]();
+	}
 
 	hardirq_endlock(cpu);
 	spin_unlock(&global_bh_lock);
diff -rbNu linux-2.4.19/kernel/timer.c linux-2.4.19-ltt/kernel/timer.c
--- linux-2.4.19/kernel/timer.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/kernel/timer.c	2004-12-28 22:39:46.000000000 +0100
@@ -23,6 +23,8 @@
 #include <linux/interrupt.h>
 #include <linux/kernel_stat.h>
 
+#include <linux/trace.h>
+
 #include <asm/uaccess.h>
 
 /*
@@ -683,6 +685,7 @@
 
 void timer_bh(void)
 {
+	TRACE_EVENT(TRACE_EV_KERNEL_TIMER, NULL);
 	update_times();
 	run_timer_list();
 }
diff -rbNu linux-2.4.19/kernel/trace.c linux-2.4.19-ltt/kernel/trace.c
--- linux-2.4.19/kernel/trace.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.19-ltt/kernel/trace.c	2004-12-28 22:39:46.000000000 +0100
@@ -0,0 +1,699 @@
+/*
+ * linux/kernel/trace.c
+ *
+ * (C) Copyright 1999, 2000, 2001, 2002 - Karim Yaghmour (karym@opersys.com)
+ *
+ * This code is distributed under the GPL license
+ *
+ * Tracing management
+ *
+ */
+
+#include <linux/init.h>     /* For __init */
+#include <linux/trace.h>    /* Tracing definitions */
+#include <linux/errno.h>    /* Miscellaneous error codes */
+#include <linux/stddef.h>   /* NULL */
+#include <linux/slab.h>     /* kmalloc() */
+#include <linux/module.h>   /* EXPORT_SYMBOL */
+#include <linux/sched.h>    /* pid_t */
+
+/* Global variables */
+unsigned int syscall_entry_trace_active = 0;
+unsigned int syscall_exit_trace_active = 0;
+
+/* Local variables */
+static int        tracer_registered = 0;   /* Is there a tracer registered */
+struct tracer *   tracer = NULL;           /* The registered tracer */
+
+/* Registration lock */
+rwlock_t tracer_register_lock = RW_LOCK_UNLOCKED;
+
+/* Trace callback table entry */
+struct trace_callback_table_entry
+{
+  tracer_call                         callback;    /* The callback function */
+
+  struct trace_callback_table_entry*  next;        /* Next entry */
+};
+
+/* Trace callback table */
+struct trace_callback_table_entry trace_callback_table[TRACE_EV_MAX];
+
+/* Custom event description */
+struct custom_event_desc
+{
+  /* The event itself */
+  trace_new_event              event;
+
+  /* PID of event owner, if any */
+  pid_t                        owner_pid;
+
+  /* List links */
+  struct custom_event_desc*    next;
+  struct custom_event_desc*    prev;
+};
+
+/* Next event ID to be used */
+int next_event_id;
+
+/* Circular list of custom events */
+struct custom_event_desc  custom_events_head;
+struct custom_event_desc* custom_events;
+
+/* Circular list lock */
+rwlock_t custom_list_lock = RW_LOCK_UNLOCKED;
+
+/****************************************************
+ * Register the tracer to the kernel
+ * Return values :
+ *   0, all is OK
+ *   -EBUSY, there already is a registered tracer
+ *   -ENOMEM, couldn't allocate memory
+ ****************************************************/
+int register_tracer(tracer_call pm_trace_function)
+{
+  unsigned long    l_flags;   /* Flags for irqsave */
+
+  /* Is there a tracer already registered */
+  if(tracer_registered == 1)
+    return -EBUSY;
+
+  /* Allocate memory for the tracer */
+  if((tracer = (struct tracer *) kmalloc(sizeof(struct tracer), GFP_ATOMIC)) == NULL)
+    /* We couldn't allocate any memory */
+    return -ENOMEM;
+
+  /* Lock registration variables */
+  write_lock_irqsave(&tracer_register_lock, l_flags);
+
+  /* There is a tracer registered */
+  tracer_registered = 1;
+
+  /* Set the tracer to the one being passed by the caller */
+  tracer->trace = pm_trace_function;
+
+  /* Unlock registration variables */
+  write_unlock_irqrestore(&tracer_register_lock, l_flags);
+
+  /* Initialize the tracer settings */
+  tracer->fetch_syscall_eip_use_bounds = 0;
+  tracer->fetch_syscall_eip_use_depth  = 0;
+
+  /* Tell the caller that everything went fine */
+  return 0;
+}
+
+/***************************************************
+ * Unregister the currently registered tracer
+ * Return values :
+ *   0, all is OK
+ *   -ENOMEDIUM, there isn't a registered tracer
+ *   -ENXIO, unregestering wrong tracer
+ ***************************************************/
+int unregister_tracer(tracer_call pm_trace_function)
+{
+  unsigned long    l_flags;   /* Flags for irqsave */
+
+  /* Is there a tracer already registered */
+  if(tracer_registered == 0)
+    /* Nothing to unregister */
+    return -ENOMEDIUM;
+
+  /* Lock registration variables */
+  write_lock_irqsave(&tracer_register_lock, l_flags);
+
+  /* Is it the tracer that was registered */
+  if(tracer->trace == pm_trace_function)
+    /* There isn't any tracer in here */
+    tracer_registered = 0;
+  else
+    {
+    /* Unlock registration variables */
+    write_unlock_irqrestore(&tracer_register_lock, l_flags);
+
+    /* We're done here */
+    return -ENXIO;
+    }
+
+  /* Free the memory used by the tracing structure */
+  kfree(tracer);
+  tracer = NULL;
+
+  /* Unlock registration variables */
+  write_unlock_irqrestore(&tracer_register_lock, l_flags);
+
+  /* Tell the caller that everything went OK */
+  return 0;
+}
+
+/*******************************************************
+ * Set the tracing configuration
+ * Parameters :
+ *   pm_trace_function, the trace function.
+ *   pm_fetch_syscall_use_depth, Use depth to fetch eip
+ *   pm_fetch_syscall_use_bounds, Use bounds to fetch eip
+ *   pm_syscall_eip_depth, Detph to fetch eip
+ *   pm_syscall_lower_bound, Lower bound eip address
+ *   pm_syscall_upper_bound, Upper bound eip address
+ * Return values : 
+ *   0, all is OK 
+ *   -ENOMEDIUM, there isn't a registered tracer
+ *   -ENXIO, wrong tracer
+ *   -EINVAL, invalid configuration
+ *******************************************************/
+int trace_set_config(tracer_call pm_trace_function,
+		     int         pm_fetch_syscall_use_depth,
+		     int         pm_fetch_syscall_use_bounds,
+		     int         pm_syscall_eip_depth,
+		     void*       pm_syscall_lower_bound,
+		     void*       pm_syscall_upper_bound)
+{
+  /* Is there a tracer already registered */
+  if(tracer_registered == 0)
+    return -ENOMEDIUM;
+
+  /* Is it the tracer that was registered */
+  if(tracer->trace != pm_trace_function)
+    return -ENXIO;
+
+  /* Is this a valid configuration */
+  if((pm_fetch_syscall_use_depth && pm_fetch_syscall_use_bounds)
+   ||(pm_syscall_lower_bound > pm_syscall_upper_bound)
+   ||(pm_syscall_eip_depth < 0))
+    return -EINVAL;
+
+  /* Set the configuration */
+  tracer->fetch_syscall_eip_use_depth  = pm_fetch_syscall_use_depth;
+  tracer->fetch_syscall_eip_use_bounds = pm_fetch_syscall_use_bounds;
+  tracer->syscall_eip_depth = pm_syscall_eip_depth;
+  tracer->syscall_lower_eip_bound = pm_syscall_lower_bound;
+  tracer->syscall_upper_eip_bound = pm_syscall_upper_bound;
+
+  /* Tell the caller that everything was OK */
+  return 0;
+}
+
+/*******************************************************
+ * Get the tracing configuration
+ * Parameters :
+ *   pm_fetch_syscall_use_depth, Use depth to fetch eip
+ *   pm_fetch_syscall_use_bounds, Use bounds to fetch eip
+ *   pm_syscall_eip_depth, Detph to fetch eip
+ *   pm_syscall_lower_bound, Lower bound eip address
+ *   pm_syscall_upper_bound, Upper bound eip address
+ * Return values :
+ *   0, all is OK 
+ *   -ENOMEDIUM, there isn't a registered tracer
+ *******************************************************/
+int trace_get_config(int*        pm_fetch_syscall_use_depth,
+		     int*        pm_fetch_syscall_use_bounds,
+		     int*        pm_syscall_eip_depth,
+		     void**      pm_syscall_lower_bound,
+		     void**      pm_syscall_upper_bound)
+{
+  /* Is there a tracer already registered */
+  if(tracer_registered == 0)
+    return -ENOMEDIUM;
+
+  /* Get the configuration */
+  *pm_fetch_syscall_use_depth  = tracer->fetch_syscall_eip_use_depth;
+  *pm_fetch_syscall_use_bounds = tracer->fetch_syscall_eip_use_bounds;
+  *pm_syscall_eip_depth = tracer->syscall_eip_depth;
+  *pm_syscall_lower_bound = tracer->syscall_lower_eip_bound;
+  *pm_syscall_upper_bound = tracer->syscall_upper_eip_bound;
+
+  /* Tell the caller that everything was OK */
+  return 0;
+}
+
+/*******************************************************
+ * Register a callback function to be called on occurence
+ * of given event
+ * Parameters :
+ *   pm_trace_function, the callback function.
+ *   pm_event_id, the event ID to be monitored.
+ * Return values :
+ *   0, all is OK
+ *   -ENOMEM, unable to allocate memory for callback
+ *******************************************************/
+int trace_register_callback(tracer_call pm_trace_function,
+			    uint8_t     pm_event_id)
+{
+  struct trace_callback_table_entry*  p_tct_entry;
+
+  /* Search for an empty entry in the callback table */
+  for(p_tct_entry = &(trace_callback_table[pm_event_id - 1]);
+      p_tct_entry->next != NULL;
+      p_tct_entry = p_tct_entry->next);
+
+  /* Allocate a new callback */
+  if((p_tct_entry->next = kmalloc(sizeof(struct trace_callback_table_entry), GFP_ATOMIC)) == NULL)
+    return -ENOMEM;
+
+  /* Setup the new callback */
+  p_tct_entry->next->callback = pm_trace_function;
+  p_tct_entry->next->next     = NULL;
+
+  /* Tell the caller everything is ok */
+  return 0;
+}
+
+/*******************************************************
+ * UnRegister a callback function.
+ * Parameters :
+ *   pm_trace_function, the callback function.
+ *   pm_event_id, the event ID that had to be monitored.
+ * Return values :
+ *   0, all is OK
+ *   -ENOMEDIUM, no such callback resigtered
+ *******************************************************/
+int trace_unregister_callback(tracer_call pm_trace_function,
+			      uint8_t     pm_event_id)
+{
+  struct trace_callback_table_entry*  p_tct_entry;  /* Pointer to trace callback table entry */
+  struct trace_callback_table_entry*  p_temp_entry; /* Pointer to trace callback table entry */
+
+  /* Search for the callback in the callback table */
+  for(p_tct_entry = &(trace_callback_table[pm_event_id - 1]);
+      ((p_tct_entry->next != NULL) && (p_tct_entry->next->callback != pm_trace_function));
+      p_tct_entry = p_tct_entry->next);
+
+  /* Did we find anything */
+  if(p_tct_entry == NULL)
+    return -ENOMEDIUM;
+
+  /* Free the callback entry */
+  p_temp_entry = p_tct_entry->next->next;
+  kfree(p_tct_entry->next);
+  p_tct_entry->next = p_temp_entry;
+
+  /* Tell the caller everything is ok */
+  return 0;
+}
+
+/*******************************************************
+ * Create a new traceable event type
+ * Parameters :
+ *   pm_event_type, string describing event type
+ *   pm_event_desc, string used for standard formatting
+ *   pm_format_type, type of formatting used to log event
+ *                 data
+ *   pm_format_data, data specific to format
+ *   pm_owner_pid, PID of event's owner (0 if none)
+ * Return values :
+ *   New Event ID if all is OK
+ *   -ENOMEM, Unable to allocate new event
+ *******************************************************/
+int _trace_create_event(char*            pm_event_type,
+			char*            pm_event_desc,
+			int              pm_format_type,
+			char*            pm_format_data,
+			pid_t            pm_owner_pid)
+{
+  struct custom_event_desc* p_new_event;          /* Newly created event */
+
+  /* Create event */
+  if((p_new_event = (struct custom_event_desc*) kmalloc(sizeof(struct custom_event_desc), GFP_ATOMIC)) == NULL)
+    return -ENOMEM;
+
+  /* Initialize event properties */
+  p_new_event->event.type[0] = '\0';
+  p_new_event->event.desc[0] = '\0';
+  p_new_event->event.form[0] = '\0';
+
+  /* Set basic event properties */
+  if(pm_event_type != NULL)
+    strncpy(p_new_event->event.type, pm_event_type, CUSTOM_EVENT_TYPE_STR_LEN);
+  if(pm_event_desc != NULL)
+    strncpy(p_new_event->event.desc, pm_event_desc, CUSTOM_EVENT_DESC_STR_LEN);
+  if(pm_format_data != NULL)
+    strncpy(p_new_event->event.form, pm_format_data, CUSTOM_EVENT_FORM_STR_LEN);
+
+  /* Ensure that strings are bound */
+  p_new_event->event.type[CUSTOM_EVENT_TYPE_STR_LEN - 1] = '\0';
+  p_new_event->event.desc[CUSTOM_EVENT_DESC_STR_LEN - 1] = '\0';
+  p_new_event->event.form[CUSTOM_EVENT_FORM_STR_LEN - 1] = '\0';
+
+  /* Set format type */
+  p_new_event->event.format_type = pm_format_type;
+
+  /* Give the new event a unique event ID */
+  p_new_event->event.id = next_event_id;
+  next_event_id++;
+
+  /* Set event's owner */
+  p_new_event->owner_pid = pm_owner_pid;
+
+  /* Insert new event in event list */
+  write_lock(&custom_list_lock);
+  p_new_event->next = custom_events;
+  p_new_event->prev = custom_events->prev;
+  custom_events->prev->next = p_new_event;
+  custom_events->prev = p_new_event;
+  write_unlock(&custom_list_lock);
+
+  /* Log the event creation event */
+  trace_event(TRACE_EV_NEW_EVENT, &(p_new_event->event));
+
+  /* Return new event ID */
+  return p_new_event->event.id;
+}
+int trace_create_event(char*            pm_event_type,
+		       char*            pm_event_desc,
+		       int              pm_format_type,
+		       char*            pm_format_data)
+{
+  return _trace_create_event(pm_event_type, pm_event_desc, pm_format_type, pm_format_data, 0);
+}
+int trace_create_owned_event(char*            pm_event_type,
+			     char*            pm_event_desc,
+			     int              pm_format_type,
+			     char*            pm_format_data,
+			     pid_t            pm_owner_pid)
+{
+  return _trace_create_event(pm_event_type, pm_event_desc, pm_format_type, pm_format_data, pm_owner_pid);
+}
+
+/*******************************************************
+ * Destroy a created event type
+ * Parameters :
+ *   pm_event_id, the Id returned by trace_create_event()
+ * Return values :
+ *   NONE
+ *******************************************************/
+void trace_destroy_event(int pm_event_id)
+{
+  struct custom_event_desc*   p_event_desc;   /* Generic event description pointer */
+
+  /* Lock the table for writting */
+  write_lock(&custom_list_lock);
+
+  /* Go through the event description list */
+  for(p_event_desc = custom_events->next;
+      p_event_desc != custom_events;
+      p_event_desc = p_event_desc->next)
+    if(p_event_desc->event.id == pm_event_id)
+      break;
+
+  /* If we found something */
+  if(p_event_desc != custom_events)
+    {
+    /* Remove the event fromt the list */
+    p_event_desc->next->prev = p_event_desc->prev;
+    p_event_desc->prev->next = p_event_desc->next;
+
+    /* Free the memory used by this event */
+    kfree(p_event_desc);
+    }
+
+  /* Unlock the table for writting */
+  write_unlock(&custom_list_lock);
+}
+
+/*******************************************************
+ * Destroy an owner's events
+ * Parameters :
+ *   pm_owner_pid, the PID of the owner who's events are to
+ *               be deleted.
+ * Return values :
+ *   NONE
+ *******************************************************/
+void trace_destroy_owners_events(pid_t pm_owner_pid)
+{
+  struct custom_event_desc*   p_temp_event;   /* Temporary event */
+  struct custom_event_desc*   p_event_desc;   /* Generic event description pointer */
+
+  /* Lock the table for writting */
+  write_lock(&custom_list_lock);
+
+  /* Start at the first event in the list */
+  p_event_desc = custom_events->next;
+
+  /* Go through the event description list */
+  while(p_event_desc != custom_events)
+    {
+    /* Keep pointer to next event */
+    p_temp_event = p_event_desc->next;
+
+    /* Does this event belong to the same owner */
+    if(p_event_desc->owner_pid == pm_owner_pid)
+      {
+      /* Remove the event fromt the list */
+      p_event_desc->next->prev = p_event_desc->prev;
+      p_event_desc->prev->next = p_event_desc->next;
+
+      /* Free the memory used by this event */
+      kfree(p_event_desc);
+      }
+
+    /* Go to next event */
+    p_event_desc = p_temp_event;
+    }
+
+  /* Unlock the table for writting */
+  write_unlock(&custom_list_lock);
+}
+
+/*******************************************************
+ * Relog the declarations of custom events. This is
+ * necessary to make sure that even though the event
+ * creation might not have taken place during a trace,
+ * that all custom events be part of all traces. Hence,
+ * if a custom event occurs during a trace, we can be
+ * sure that it's definition is part of the trace.
+ * Parameters :
+ *    NONE
+ * Return values :
+ *    NONE
+ *******************************************************/
+void trace_reregister_custom_events(void)
+{
+  struct custom_event_desc*   p_event_desc;   /* Generic event description pointer */
+
+  /* Lock the table for reading */
+  read_lock(&custom_list_lock);
+
+  /* Go through the event description list */
+  for(p_event_desc = custom_events->next;
+      p_event_desc != custom_events;
+      p_event_desc = p_event_desc->next)
+    /* Log the event creation event */
+    trace_event(TRACE_EV_NEW_EVENT, &(p_event_desc->event));
+
+  /* Unlock the table for reading */
+  read_unlock(&custom_list_lock);
+}
+
+/*******************************************************
+ * Trace a formatted event
+ * Parameters :
+ *   pm_event_id, the event Id provided upon creation
+ *   ..., printf-like data that will be used to fill the
+ *        event string.
+ * Return values :
+ *   0, all is OK
+ *   -ENOMEDIUM, there isn't a registered tracer or this
+ *               event doesn't exist.
+ *   -EBUSY, tracing hasn't started yet
+ *******************************************************/
+int trace_std_formatted_event(int pm_event_id, ...)
+{
+  int                         l_string_size;   /* Size of the string outputed by vsprintf() */
+  char                        l_string[CUSTOM_EVENT_FINAL_STR_LEN];  /* Final formatted string */
+  va_list                     l_var_arg_list;  /* Variable argument list */
+  trace_custom                l_custom;        /* Custom event */
+  struct custom_event_desc*   p_event_desc;    /* Generic event description pointer */
+
+  /* Lock the table for reading */
+  read_lock(&custom_list_lock);
+
+  /* Go through the event description list */
+  for(p_event_desc = custom_events->next;
+      p_event_desc != custom_events;
+      p_event_desc = p_event_desc->next)
+    if(p_event_desc->event.id == pm_event_id)
+      break;
+
+  /* If we haven't found anything */
+  if(p_event_desc == custom_events)
+    {
+    /* Unlock the table for reading */
+    read_unlock(&custom_list_lock);
+
+    /* No such thing */
+    return -ENOMEDIUM;
+    }
+
+  /* Set custom event Id */
+  l_custom.id = pm_event_id;
+
+  /* Initialize variable argument list access */
+  va_start(l_var_arg_list, pm_event_id);
+
+  /* Print the description out to the temporary buffer */
+  l_string_size = vsprintf(l_string, p_event_desc->event.desc, l_var_arg_list);
+
+  /* Unlock the table for reading */
+  read_unlock(&custom_list_lock);
+
+  /* Facilitate return to caller */
+  va_end(l_var_arg_list);
+
+  /* Set the size of the event */
+  l_custom.data_size = (uint32_t) (l_string_size + 1);
+
+  /* Set the pointer to the event data */
+  l_custom.data = l_string;
+
+  /* Log the custom event */
+  return trace_event(TRACE_EV_CUSTOM, &l_custom);
+}
+
+/*******************************************************
+ * Trace a raw event
+ * Parameters :
+ *   pm_event_id, the event Id provided upon creation
+ *   pm_event_size, the size of the data provided
+ *   pm_event_data, data buffer describing event
+ * Return values :
+ *   0, all is OK
+ *   -ENOMEDIUM, there isn't a registered tracer or this
+ *               event doesn't exist.
+ *   -EBUSY, tracing hasn't started yet
+ *******************************************************/
+int trace_raw_event(int pm_event_id, int pm_event_size, void* pm_event_data)
+{
+  trace_custom                l_custom;        /* Custom event */
+  struct custom_event_desc*   p_event_desc;    /* Generic event description pointer */
+
+  /* Lock the table for reading */
+  read_lock(&custom_list_lock);
+
+  /* Go through the event description list */
+  for(p_event_desc = custom_events->next;
+      p_event_desc != custom_events;
+      p_event_desc = p_event_desc->next)
+    if(p_event_desc->event.id == pm_event_id)
+      break;
+
+  /* Unlock the table for reading */
+  read_unlock(&custom_list_lock);
+
+  /* If we haven't found anything */
+  if(p_event_desc == custom_events)
+    /* No such thing */
+    return -ENOMEDIUM;
+
+  /* Set custom event Id */
+  l_custom.id = pm_event_id;
+
+  /* Set the data size */
+  if(pm_event_size <= CUSTOM_EVENT_MAX_SIZE)
+    l_custom.data_size = (uint32_t) pm_event_size;
+  else
+    l_custom.data_size = (uint32_t) CUSTOM_EVENT_MAX_SIZE;
+
+  /* Set the pointer to the event data */
+  l_custom.data = pm_event_data;
+
+  /* Log the custom event */
+  return trace_event(TRACE_EV_CUSTOM, &l_custom);
+}
+
+/*******************************************************
+ * Trace an event
+ * Parameters :
+ *   pm_event_id, the event's ID (check out trace.h)
+ *   pm_event_struct, the structure describing the event
+ * Return values :
+ *   0, all is OK
+ *   -ENOMEDIUM, there isn't a registered tracer
+ *   -EBUSY, tracing hasn't started yet
+ *******************************************************/
+int trace_event(uint8_t  pm_event_id, 
+       	        void*    pm_event_struct)
+{
+  int                                 l_ret_value; /* The return value */
+  struct trace_callback_table_entry*  p_tct_entry; /* Pointer to trace callback table entry */
+
+  /* Lock registration variables */
+  read_lock(&tracer_register_lock);
+
+  /* Is there a tracer registered */
+  if(tracer_registered != 1)
+    l_ret_value = -ENOMEDIUM;
+  else
+    /* Call the tracer */
+    l_ret_value = tracer->trace(pm_event_id, pm_event_struct);
+
+  /* Unlock registration variables */
+  read_unlock(&tracer_register_lock);
+
+  /* Is this a native event */
+  if(pm_event_id <= TRACE_EV_MAX)
+    {
+    /* Are there any callbacks to call */
+    if(trace_callback_table[pm_event_id - 1].next != NULL)
+      {
+      /* Call all the callbacks linked to this event */
+      for(p_tct_entry = trace_callback_table[pm_event_id - 1].next;
+	  p_tct_entry != NULL;
+	  p_tct_entry = p_tct_entry->next)
+	p_tct_entry->callback(pm_event_id, pm_event_struct);
+      }
+    }
+
+  /* Give the return value */
+  return l_ret_value;
+}
+
+/*******************************************************
+ * Initialize trace facility
+ * Parameters :
+ *    NONE
+ * Return values :
+ *    NONE
+ *******************************************************/
+static int __init trace_init(void)
+{
+  int i;  /* Generic index */
+
+  /* Initialize callback table */
+  for(i = 0; i < TRACE_EV_MAX; i++)
+    {
+    trace_callback_table[i].callback = NULL;
+    trace_callback_table[i].next     = NULL;
+    }
+
+  /* Next event ID to be used */
+  next_event_id = TRACE_EV_MAX + 1;
+
+  /* Initialize custom events list */
+  custom_events = &custom_events_head;
+  custom_events->next = custom_events;
+  custom_events->prev = custom_events;
+
+  /* Everything is OK */
+  return 0;
+}
+
+module_init(trace_init);
+
+/* Export symbols so that can be visible from outside this file */
+EXPORT_SYMBOL(register_tracer);
+EXPORT_SYMBOL(unregister_tracer);
+EXPORT_SYMBOL(trace_set_config);
+EXPORT_SYMBOL(trace_get_config);
+EXPORT_SYMBOL(trace_register_callback);
+EXPORT_SYMBOL(trace_unregister_callback);
+EXPORT_SYMBOL(trace_create_event);
+EXPORT_SYMBOL(trace_create_owned_event);
+EXPORT_SYMBOL(trace_destroy_event);
+EXPORT_SYMBOL(trace_destroy_owners_events);
+EXPORT_SYMBOL(trace_reregister_custom_events);
+EXPORT_SYMBOL(trace_std_formatted_event);
+EXPORT_SYMBOL(trace_raw_event);
+EXPORT_SYMBOL(trace_event);
+
+EXPORT_SYMBOL(syscall_entry_trace_active);
+EXPORT_SYMBOL(syscall_exit_trace_active);
diff -rbNu linux-2.4.19/mm/filemap.c linux-2.4.19-ltt/mm/filemap.c
--- linux-2.4.19/mm/filemap.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/mm/filemap.c	2004-12-28 22:39:46.000000000 +0100
@@ -24,6 +24,8 @@
 #include <linux/mm.h>
 #include <linux/iobuf.h>
 
+#include <linux/trace.h>
+
 #include <asm/pgalloc.h>
 #include <asm/uaccess.h>
 #include <asm/mman.h>
@@ -824,10 +826,12 @@
 		set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 		if (!PageLocked(page))
 			break;
+ 		TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_WAIT_START, 0);
 		sync_page(page);
 		schedule();
 	} while (PageLocked(page));
 	__set_task_state(tsk, TASK_RUNNING);
+ 	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_WAIT_END, 0);
 	remove_wait_queue(waitqueue, &wait);
 }
 
diff -rbNu linux-2.4.19/mm/memory.c linux-2.4.19-ltt/mm/memory.c
--- linux-2.4.19/mm/memory.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/mm/memory.c	2004-12-28 22:39:46.000000000 +0100
@@ -46,6 +46,8 @@
 #include <linux/pagemap.h>
 #include <linux/module.h>
 
+#include <linux/trace.h>
+
 #include <asm/pgalloc.h>
 #include <asm/uaccess.h>
 #include <asm/tlb.h>
@@ -1127,6 +1129,7 @@
 	spin_unlock(&mm->page_table_lock);
 	page = lookup_swap_cache(entry);
 	if (!page) {
+	        TRACE_MEMORY(TRACE_EV_MEMORY_SWAP_IN, address);
 		swapin_readahead(entry);
 		page = read_swap_cache_async(entry);
 		if (!page) {
diff -rbNu linux-2.4.19/mm/page_alloc.c linux-2.4.19-ltt/mm/page_alloc.c
--- linux-2.4.19/mm/page_alloc.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/mm/page_alloc.c	2004-12-28 22:39:46.000000000 +0100
@@ -22,6 +22,8 @@
 #include <linux/slab.h>
 #include <linux/module.h>
 
+#include <linux/trace.h>
+
 int nr_swap_pages;
 int nr_active_pages;
 int nr_inactive_pages;
@@ -95,6 +97,9 @@
 		BUG();
 	if (PageActive(page))
 		BUG();
+
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_FREE, order);
+
 	page->flags &= ~((1<<PG_referenced) | (1<<PG_dirty));
 
 	if (current->flags & PF_FREE_PAGES)
@@ -423,6 +428,7 @@
 	page = alloc_pages(gfp_mask, order);
 	if (!page)
 		return 0;
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_ALLOC, order);
 	return (unsigned long) page_address(page);
 }
 
diff -rbNu linux-2.4.19/mm/swap_state.c linux-2.4.19-ltt/mm/swap_state.c
--- linux-2.4.19/mm/swap_state.c	2001-11-01 00:31:03.000000000 +0100
+++ linux-2.4.19-ltt/mm/swap_state.c	2004-12-28 22:39:46.000000000 +0100
@@ -15,6 +15,8 @@
 #include <linux/pagemap.h>
 #include <linux/smp_lock.h>
 
+#include <linux/trace.h>
+
 #include <asm/pgtable.h>
 
 /*
@@ -27,6 +29,9 @@
 		UnlockPage(page);
 		return 0;
 	}
+
+	TRACE_MEMORY(TRACE_EV_MEMORY_SWAP_OUT, (unsigned long) page);
+
 	rw_swap_page(WRITE, page);
 	return 0;
 }
diff -rbNu linux-2.4.19/net/core/dev.c linux-2.4.19-ltt/net/core/dev.c
--- linux-2.4.19/net/core/dev.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/net/core/dev.c	2004-12-28 22:39:46.000000000 +0100
@@ -104,6 +104,9 @@
 #include <linux/wireless.h>		/* Note : will define WIRELESS_EXT */
 #include <net/iw_handler.h>
 #endif	/* CONFIG_NET_RADIO || CONFIG_NET_PCMCIA_RADIO */
+
+#include <linux/trace.h>
+
 #ifdef CONFIG_PLIP
 extern int plip_init(void);
 #endif
@@ -1007,6 +1010,8 @@
 			return -ENOMEM;
 	}
 
+	TRACE_NETWORK(TRACE_EV_NETWORK_PACKET_OUT, skb->protocol);
+
 	/* Grab device queue */
 	spin_lock_bh(&dev->queue_lock);
 	q = dev->qdisc;
@@ -1441,6 +1446,8 @@
 
 		rx_dev = skb->dev;
 
+		TRACE_NETWORK(TRACE_EV_NETWORK_PACKET_IN, skb->protocol);
+
 #ifdef CONFIG_NET_FASTROUTE
 		if (skb->pkt_type == PACKET_FASTROUTE) {
 			netdev_rx_stat[this_cpu].fastroute_deferred_out++;
diff -rbNu linux-2.4.19/net/socket.c linux-2.4.19-ltt/net/socket.c
--- linux-2.4.19/net/socket.c	2002-08-03 02:39:46.000000000 +0200
+++ linux-2.4.19-ltt/net/socket.c	2004-12-28 22:39:46.000000000 +0100
@@ -75,6 +75,8 @@
 #include <linux/module.h>
 #include <linux/highmem.h>
 
+#include <linux/trace.h>
+
 #if defined(CONFIG_KMOD) && defined(CONFIG_NET)
 #include <linux/kmod.h>
 #endif
@@ -503,6 +505,8 @@
 	int err;
 	struct scm_cookie scm;
 
+	TRACE_SOCKET(TRACE_EV_SOCKET_SEND, sock->type, size);
+
 	err = scm_send(sock, msg, &scm);
 	if (err >= 0) {
 		err = sock->ops->sendmsg(sock, msg, size, &scm);
@@ -517,6 +521,8 @@
 
 	memset(&scm, 0, sizeof(scm));
 
+	TRACE_SOCKET(TRACE_EV_SOCKET_RECEIVE, sock->type, size);
+
 	size = sock->ops->recvmsg(sock, msg, size, flags, &scm);
 	if (size >= 0)
 		scm_recv(sock, msg, &scm, flags);
@@ -910,6 +916,8 @@
 	if (retval < 0)
 		goto out_release;
 
+	TRACE_SOCKET(TRACE_EV_SOCKET_CREATE, retval, type);
+
 out:
 	/* It may be already another descriptor 8) Not kernel problem. */
 	return retval;
@@ -1548,6 +1556,8 @@
 	a0=a[0];
 	a1=a[1];
 	
+	TRACE_SOCKET(TRACE_EV_SOCKET_CALL, call, a0);
+	
 	switch(call) 
 	{
 		case SYS_SOCKET:
